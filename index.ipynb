{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the code in this lab taken from the solution at https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab/tree/solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall from the last lab that you had a training accuracy close to 90% and a test set accuracy close to 76%.\n",
    "\n",
    "As with your previous machine learning work, you should be asking a couple of questions:\n",
    "- Is there high bias? yes/no\n",
    "- Is there high variance? yes/no \n",
    "\n",
    "In this lab, you'll use the a train-validate-test partition as well as a validation set to get better insights of how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. However, this time, when you are presented with the `history` dictionary of the model, you will have additional data entries for not only the train and test set but also the validation set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Construct and run a basic model in Keras\n",
    "* Construct a validation set and explain potential benefits\n",
    "* Apply L1 and L2 regularization\n",
    "* Apply dropout regularization\n",
    "* Observe and comment on the effect of using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "As usual, start by importing some of the packages and modules that you intend to use. The first thing you'll be doing is importing the data and taking a random sample, so that should clue you in to what tools to import. If you need more tools down the line, you can always import additional packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; import some packages/modules you plan to use\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "\n",
    "As with the previous lab, the data is stored in a file **Bank_complaints.csv**. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools regarding regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Train - test split\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your models performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "Generate the random sample using seed 123 for consistency of results. Make your new sample have 10,000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "sample = df.sample(10000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "Below, perform an appropriate train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product', 'Consumer complaint narrative'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yyour code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample['Consumer complaint narrative'], sample['Product'], random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, you saw that in deep learning, you generally set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test can then be used to define the final model perforance. \n",
    "\n",
    "In this example, take the first 1000 cases out of the training set to create a validation set. You should do this for both `train` and `label_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this block of code \n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding of the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing and data manipulationg before building the neural network. \n",
    "\n",
    "Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code taken from solution at https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab/tree/solution\n",
    "\n",
    "#Your code here; use one-hot encoding to reformat the complaints into a matrix of vectors.\n",
    "#Only keep the 2000 most common words.\n",
    "\n",
    "# instantiate tokenizer\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "\n",
    "# fit tokenizer\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "# one hot encode X_train_final and X_val\n",
    "X_train_final = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val = tokenizer.texts_to_matrix(X_val, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code taken from the solution at https://github.com/learn-co-curriculum/dsc-tuning-neural-networks-with-regularization-lab/tree/solution\n",
    "#Your code here; transform the product labels to numerical values\n",
    "#Then transform these integer values into a matrix of binary flags\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_final = to_categorical(lb.transform(y_train_final), 7)[:, :, 1]\n",
    "y_val = to_categorical(lb.transform(y_val), 7)[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because you are dealing with a multiclass problem (classifying the complaints into 7 classes), use a softmax classifyer in order to output 7 class probabilities per case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; build a neural network using Keras as described above.\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "In the compiler, you'll be passing the optimizer, loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples. This time, include the argument `validation_data` and assign it `(val, label_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Ok, now for the resource intensive part: time to train your model! Note that this is where you also introduce the validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 1.9475 - accuracy: 0.1651 - val_loss: 1.9295 - val_accuracy: 0.1790\n",
      "Epoch 2/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.9193 - accuracy: 0.2031 - val_loss: 1.9055 - val_accuracy: 0.2100\n",
      "Epoch 3/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8950 - accuracy: 0.2394 - val_loss: 1.8812 - val_accuracy: 0.2350\n",
      "Epoch 4/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8685 - accuracy: 0.2623 - val_loss: 1.8542 - val_accuracy: 0.2670\n",
      "Epoch 5/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.8380 - accuracy: 0.2931 - val_loss: 1.8239 - val_accuracy: 0.2820\n",
      "Epoch 6/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.8038 - accuracy: 0.3175 - val_loss: 1.7912 - val_accuracy: 0.3030\n",
      "Epoch 7/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7669 - accuracy: 0.3440 - val_loss: 1.7560 - val_accuracy: 0.3220\n",
      "Epoch 8/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7273 - accuracy: 0.3640 - val_loss: 1.7184 - val_accuracy: 0.3480\n",
      "Epoch 9/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6845 - accuracy: 0.3872 - val_loss: 1.6796 - val_accuracy: 0.3760\n",
      "Epoch 10/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.6398 - accuracy: 0.4145 - val_loss: 1.6373 - val_accuracy: 0.3960\n",
      "Epoch 11/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5928 - accuracy: 0.4351 - val_loss: 1.5944 - val_accuracy: 0.4220\n",
      "Epoch 12/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.5452 - accuracy: 0.4600 - val_loss: 1.5504 - val_accuracy: 0.4490\n",
      "Epoch 13/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4980 - accuracy: 0.4914 - val_loss: 1.5075 - val_accuracy: 0.4610\n",
      "Epoch 14/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.4525 - accuracy: 0.5108 - val_loss: 1.4668 - val_accuracy: 0.4930\n",
      "Epoch 15/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.4085 - accuracy: 0.5323 - val_loss: 1.4274 - val_accuracy: 0.5070\n",
      "Epoch 16/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.3661 - accuracy: 0.5483 - val_loss: 1.3888 - val_accuracy: 0.5210\n",
      "Epoch 17/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.3260 - accuracy: 0.5666 - val_loss: 1.3528 - val_accuracy: 0.5520\n",
      "Epoch 18/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2875 - accuracy: 0.5820 - val_loss: 1.3190 - val_accuracy: 0.5630\n",
      "Epoch 19/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2507 - accuracy: 0.5978 - val_loss: 1.2863 - val_accuracy: 0.5740\n",
      "Epoch 20/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2158 - accuracy: 0.6122 - val_loss: 1.2545 - val_accuracy: 0.5800\n",
      "Epoch 21/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1818 - accuracy: 0.6203 - val_loss: 1.2252 - val_accuracy: 0.5900\n",
      "Epoch 22/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1502 - accuracy: 0.6315 - val_loss: 1.1966 - val_accuracy: 0.5990\n",
      "Epoch 23/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.1196 - accuracy: 0.6414 - val_loss: 1.1703 - val_accuracy: 0.6050\n",
      "Epoch 24/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0906 - accuracy: 0.6520 - val_loss: 1.1445 - val_accuracy: 0.6120\n",
      "Epoch 25/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0627 - accuracy: 0.6580 - val_loss: 1.1207 - val_accuracy: 0.6200\n",
      "Epoch 26/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0367 - accuracy: 0.6675 - val_loss: 1.0977 - val_accuracy: 0.6280\n",
      "Epoch 27/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0120 - accuracy: 0.6723 - val_loss: 1.0772 - val_accuracy: 0.6370\n",
      "Epoch 28/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9885 - accuracy: 0.6800 - val_loss: 1.0574 - val_accuracy: 0.6390\n",
      "Epoch 29/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9661 - accuracy: 0.6889 - val_loss: 1.0378 - val_accuracy: 0.6440\n",
      "Epoch 30/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9451 - accuracy: 0.6946 - val_loss: 1.0193 - val_accuracy: 0.6500\n",
      "Epoch 31/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9246 - accuracy: 0.6985 - val_loss: 1.0020 - val_accuracy: 0.6580\n",
      "Epoch 32/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9057 - accuracy: 0.7051 - val_loss: 0.9856 - val_accuracy: 0.6550\n",
      "Epoch 33/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8880 - accuracy: 0.7105 - val_loss: 0.9718 - val_accuracy: 0.6660\n",
      "Epoch 34/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8712 - accuracy: 0.7148 - val_loss: 0.9548 - val_accuracy: 0.6690\n",
      "Epoch 35/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8548 - accuracy: 0.7168 - val_loss: 0.9423 - val_accuracy: 0.6790\n",
      "Epoch 36/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8395 - accuracy: 0.7229 - val_loss: 0.9281 - val_accuracy: 0.6820\n",
      "Epoch 37/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8249 - accuracy: 0.7249 - val_loss: 0.9160 - val_accuracy: 0.6850\n",
      "Epoch 38/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8108 - accuracy: 0.7285 - val_loss: 0.9028 - val_accuracy: 0.6920\n",
      "Epoch 39/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7979 - accuracy: 0.7305 - val_loss: 0.8922 - val_accuracy: 0.7030\n",
      "Epoch 40/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7853 - accuracy: 0.7354 - val_loss: 0.8809 - val_accuracy: 0.6940\n",
      "Epoch 41/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7729 - accuracy: 0.7415 - val_loss: 0.8715 - val_accuracy: 0.7140\n",
      "Epoch 42/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7617 - accuracy: 0.7395 - val_loss: 0.8634 - val_accuracy: 0.7040\n",
      "Epoch 43/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7512 - accuracy: 0.7466 - val_loss: 0.8520 - val_accuracy: 0.7050\n",
      "Epoch 44/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.7401 - accuracy: 0.7478 - val_loss: 0.8449 - val_accuracy: 0.7090\n",
      "Epoch 45/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7303 - accuracy: 0.7531 - val_loss: 0.8354 - val_accuracy: 0.7120\n",
      "Epoch 46/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7207 - accuracy: 0.7563 - val_loss: 0.8277 - val_accuracy: 0.7130\n",
      "Epoch 47/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.7114 - accuracy: 0.7597 - val_loss: 0.8194 - val_accuracy: 0.7180\n",
      "Epoch 48/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.7028 - accuracy: 0.7578 - val_loss: 0.8136 - val_accuracy: 0.7190\n",
      "Epoch 49/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.6942 - accuracy: 0.7655 - val_loss: 0.8073 - val_accuracy: 0.7240\n",
      "Epoch 50/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.6862 - accuracy: 0.7643 - val_loss: 0.8004 - val_accuracy: 0.7240\n",
      "Epoch 51/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.6786 - accuracy: 0.7669 - val_loss: 0.7945 - val_accuracy: 0.7260\n",
      "Epoch 52/120\n",
      "6500/6500 [==============================] - 0s 39us/step - loss: 0.6705 - accuracy: 0.7688 - val_loss: 0.7891 - val_accuracy: 0.7330\n",
      "Epoch 53/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6634 - accuracy: 0.7705 - val_loss: 0.7818 - val_accuracy: 0.7340\n",
      "Epoch 54/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.6560 - accuracy: 0.7754 - val_loss: 0.7781 - val_accuracy: 0.7330\n",
      "Epoch 55/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6489 - accuracy: 0.7765 - val_loss: 0.7745 - val_accuracy: 0.7360\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6429 - accuracy: 0.7786 - val_loss: 0.7672 - val_accuracy: 0.7350\n",
      "Epoch 57/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6363 - accuracy: 0.7798 - val_loss: 0.7661 - val_accuracy: 0.7400\n",
      "Epoch 58/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6300 - accuracy: 0.7823 - val_loss: 0.7595 - val_accuracy: 0.7370\n",
      "Epoch 59/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6235 - accuracy: 0.7825 - val_loss: 0.7569 - val_accuracy: 0.7410\n",
      "Epoch 60/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6175 - accuracy: 0.7866 - val_loss: 0.7507 - val_accuracy: 0.7360\n",
      "Epoch 61/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.6122 - accuracy: 0.7854 - val_loss: 0.7474 - val_accuracy: 0.7410\n",
      "Epoch 62/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.6067 - accuracy: 0.7920 - val_loss: 0.7442 - val_accuracy: 0.7430\n",
      "Epoch 63/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.6008 - accuracy: 0.7905 - val_loss: 0.7426 - val_accuracy: 0.7440\n",
      "Epoch 64/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.5953 - accuracy: 0.7926 - val_loss: 0.7381 - val_accuracy: 0.7450\n",
      "Epoch 65/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.5900 - accuracy: 0.7980 - val_loss: 0.7324 - val_accuracy: 0.7430\n",
      "Epoch 66/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.5847 - accuracy: 0.7971 - val_loss: 0.7300 - val_accuracy: 0.7450\n",
      "Epoch 67/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5800 - accuracy: 0.7980 - val_loss: 0.7272 - val_accuracy: 0.7500\n",
      "Epoch 68/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5754 - accuracy: 0.7998 - val_loss: 0.7243 - val_accuracy: 0.7510\n",
      "Epoch 69/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5707 - accuracy: 0.8011 - val_loss: 0.7208 - val_accuracy: 0.7470\n",
      "Epoch 70/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5657 - accuracy: 0.8034 - val_loss: 0.7191 - val_accuracy: 0.7550\n",
      "Epoch 71/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5609 - accuracy: 0.8051 - val_loss: 0.7140 - val_accuracy: 0.7550\n",
      "Epoch 72/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5566 - accuracy: 0.8063 - val_loss: 0.7131 - val_accuracy: 0.7540\n",
      "Epoch 73/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5521 - accuracy: 0.8066 - val_loss: 0.7113 - val_accuracy: 0.7490\n",
      "Epoch 74/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5477 - accuracy: 0.8102 - val_loss: 0.7087 - val_accuracy: 0.7510\n",
      "Epoch 75/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5431 - accuracy: 0.8129 - val_loss: 0.7067 - val_accuracy: 0.7500\n",
      "Epoch 76/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5389 - accuracy: 0.8126 - val_loss: 0.7058 - val_accuracy: 0.7570\n",
      "Epoch 77/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5350 - accuracy: 0.8134 - val_loss: 0.7021 - val_accuracy: 0.7570\n",
      "Epoch 78/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5309 - accuracy: 0.8155 - val_loss: 0.7003 - val_accuracy: 0.7610\n",
      "Epoch 79/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5266 - accuracy: 0.8169 - val_loss: 0.6987 - val_accuracy: 0.7600\n",
      "Epoch 80/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5227 - accuracy: 0.8178 - val_loss: 0.6981 - val_accuracy: 0.7600\n",
      "Epoch 81/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.5189 - accuracy: 0.8194 - val_loss: 0.6957 - val_accuracy: 0.7620\n",
      "Epoch 82/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.5150 - accuracy: 0.8203 - val_loss: 0.6932 - val_accuracy: 0.7680\n",
      "Epoch 83/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.5112 - accuracy: 0.8249 - val_loss: 0.6922 - val_accuracy: 0.7620\n",
      "Epoch 84/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5076 - accuracy: 0.8251 - val_loss: 0.6891 - val_accuracy: 0.7630\n",
      "Epoch 85/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.5036 - accuracy: 0.8260 - val_loss: 0.6903 - val_accuracy: 0.7630\n",
      "Epoch 86/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.5002 - accuracy: 0.8266 - val_loss: 0.6866 - val_accuracy: 0.7590\n",
      "Epoch 87/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4965 - accuracy: 0.8268 - val_loss: 0.6839 - val_accuracy: 0.7620\n",
      "Epoch 88/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4926 - accuracy: 0.8303 - val_loss: 0.6841 - val_accuracy: 0.7640\n",
      "Epoch 89/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4892 - accuracy: 0.8314 - val_loss: 0.6822 - val_accuracy: 0.7620\n",
      "Epoch 90/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4858 - accuracy: 0.8349 - val_loss: 0.6811 - val_accuracy: 0.7650\n",
      "Epoch 91/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4822 - accuracy: 0.8340 - val_loss: 0.6793 - val_accuracy: 0.7640\n",
      "Epoch 92/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4786 - accuracy: 0.8357 - val_loss: 0.6784 - val_accuracy: 0.7670\n",
      "Epoch 93/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4752 - accuracy: 0.8374 - val_loss: 0.6764 - val_accuracy: 0.7660\n",
      "Epoch 94/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.4719 - accuracy: 0.8400 - val_loss: 0.6769 - val_accuracy: 0.7670\n",
      "Epoch 95/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.4687 - accuracy: 0.8405 - val_loss: 0.6730 - val_accuracy: 0.7610\n",
      "Epoch 96/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4654 - accuracy: 0.8432 - val_loss: 0.6739 - val_accuracy: 0.7640\n",
      "Epoch 97/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4622 - accuracy: 0.8417 - val_loss: 0.6704 - val_accuracy: 0.7630\n",
      "Epoch 98/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.4587 - accuracy: 0.8465 - val_loss: 0.6735 - val_accuracy: 0.7700\n",
      "Epoch 99/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4560 - accuracy: 0.8435 - val_loss: 0.6712 - val_accuracy: 0.7720\n",
      "Epoch 100/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.4527 - accuracy: 0.8458 - val_loss: 0.6684 - val_accuracy: 0.7630\n",
      "Epoch 101/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.4492 - accuracy: 0.8465 - val_loss: 0.6669 - val_accuracy: 0.7650\n",
      "Epoch 102/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.4462 - accuracy: 0.8491 - val_loss: 0.6671 - val_accuracy: 0.7670\n",
      "Epoch 103/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4432 - accuracy: 0.8517 - val_loss: 0.6679 - val_accuracy: 0.7660\n",
      "Epoch 104/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4403 - accuracy: 0.8511 - val_loss: 0.6661 - val_accuracy: 0.7670\n",
      "Epoch 105/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4372 - accuracy: 0.8511 - val_loss: 0.6670 - val_accuracy: 0.7710\n",
      "Epoch 106/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.4341 - accuracy: 0.8538 - val_loss: 0.6648 - val_accuracy: 0.7690\n",
      "Epoch 107/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.4311 - accuracy: 0.8545 - val_loss: 0.6641 - val_accuracy: 0.7670\n",
      "Epoch 108/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.4279 - accuracy: 0.8545 - val_loss: 0.6633 - val_accuracy: 0.7710\n",
      "Epoch 109/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.4252 - accuracy: 0.8583 - val_loss: 0.6642 - val_accuracy: 0.7700\n",
      "Epoch 110/120\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.4220 - accuracy: 0.8578 - val_loss: 0.6612 - val_accuracy: 0.7680\n",
      "Epoch 111/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.4198 - accuracy: 0.8620 - val_loss: 0.6627 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.4164 - accuracy: 0.8608 - val_loss: 0.6598 - val_accuracy: 0.7710\n",
      "Epoch 113/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4140 - accuracy: 0.8626 - val_loss: 0.6601 - val_accuracy: 0.7710\n",
      "Epoch 114/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4112 - accuracy: 0.8612 - val_loss: 0.6607 - val_accuracy: 0.7690\n",
      "Epoch 115/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4080 - accuracy: 0.8625 - val_loss: 0.6570 - val_accuracy: 0.7760\n",
      "Epoch 116/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4054 - accuracy: 0.8668 - val_loss: 0.6609 - val_accuracy: 0.7670\n",
      "Epoch 117/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.4026 - accuracy: 0.8663 - val_loss: 0.6578 - val_accuracy: 0.7780\n",
      "Epoch 118/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.4001 - accuracy: 0.8672 - val_loss: 0.6591 - val_accuracy: 0.7750\n",
      "Epoch 119/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.3972 - accuracy: 0.8675 - val_loss: 0.6590 - val_accuracy: 0.7710\n",
      "Epoch 120/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.3945 - accuracy: 0.8703 - val_loss: 0.6564 - val_accuracy: 0.7730\n"
     ]
    }
   ],
   "source": [
    "#Code provided; note the extra validation parameter passed.\n",
    "model_val = model.fit(X_train_final,\n",
    "                    y_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Performance Results: the `history` dictionary\n",
    "\n",
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 23us/step\n",
      "Training Loss: 0.391 Training Accuracy: 0.872\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_final, y_train_final)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess then evaluate our models performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 23us/step\n",
      "Testing Loss: 0.701 Testing Accuracy: 0.736\n"
     ]
    }
   ],
   "source": [
    "X_test_tok = tokenizer.texts_to_matrix(X_test, mode='binary')\n",
    "y_test_cat = to_categorical(lb.transform(y_test))[:, :, 1]\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the list returned by `model.evaluate` is the loss, and the second is the accuracy score. \n",
    "\n",
    "Note that the result you obtained here isn't exactly the same as before. This is because the training set is slightly different! You removed 1000 instances for validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function versus the number of epochs. Be sure to include the training and the validation loss in the same plot. Then, create a second plot comparing training and validation accuracy to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and val set\n",
    "plt.plot(model_val_dict['loss'], label='training loss')\n",
    "plt.plot(model_val_dict['val_loss'], label='validation loss')\n",
    "plt.title('training and validation loss vs no. of epochs'.title())\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and val set\n",
    "plt.plot(model_val_dict['accuracy'], label='training accuracy')\n",
    "plt.plot(model_val_dict['val_accuracy'], label='validation accuracy')\n",
    "plt.title('training and validation accuracy vs no. of epochs'.title())\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a limit around the 60th epoch. This means that you're probably **overfitting** the model to the training data when you train for many epochs past this dropoff point of around 40 epochs. Luckily, you learned how to tackle overfitting in the previous lecture! Since it seems clear that you are training too long, include early stopping at the 60th epoch first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Below, observe how to update the model to include an earlier cutoff point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "6500/6500 [==============================] - 0s 35us/step - loss: 1.9530 - accuracy: 0.1335 - val_loss: 1.9415 - val_accuracy: 0.1500\n",
      "Epoch 2/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.9354 - accuracy: 0.1606 - val_loss: 1.9271 - val_accuracy: 0.1620\n",
      "Epoch 3/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.9200 - accuracy: 0.1851 - val_loss: 1.9125 - val_accuracy: 0.1980\n",
      "Epoch 4/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.9044 - accuracy: 0.1974 - val_loss: 1.8973 - val_accuracy: 0.2160\n",
      "Epoch 5/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8876 - accuracy: 0.2157 - val_loss: 1.8804 - val_accuracy: 0.2490\n",
      "Epoch 6/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8698 - accuracy: 0.2263 - val_loss: 1.8629 - val_accuracy: 0.2570\n",
      "Epoch 7/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8512 - accuracy: 0.2418 - val_loss: 1.8444 - val_accuracy: 0.2750\n",
      "Epoch 8/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.8308 - accuracy: 0.2555 - val_loss: 1.8241 - val_accuracy: 0.2870\n",
      "Epoch 9/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8081 - accuracy: 0.2755 - val_loss: 1.8016 - val_accuracy: 0.3010\n",
      "Epoch 10/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.7821 - accuracy: 0.2971 - val_loss: 1.7763 - val_accuracy: 0.3200\n",
      "Epoch 11/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.7530 - accuracy: 0.3254 - val_loss: 1.7478 - val_accuracy: 0.3390\n",
      "Epoch 12/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.7197 - accuracy: 0.3577 - val_loss: 1.7153 - val_accuracy: 0.3670\n",
      "Epoch 13/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6821 - accuracy: 0.3920 - val_loss: 1.6784 - val_accuracy: 0.3840\n",
      "Epoch 14/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.6404 - accuracy: 0.4314 - val_loss: 1.6374 - val_accuracy: 0.4150\n",
      "Epoch 15/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.5959 - accuracy: 0.4585 - val_loss: 1.5951 - val_accuracy: 0.4520\n",
      "Epoch 16/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.5499 - accuracy: 0.4926 - val_loss: 1.5510 - val_accuracy: 0.4750\n",
      "Epoch 17/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.5030 - accuracy: 0.5208 - val_loss: 1.5061 - val_accuracy: 0.5040\n",
      "Epoch 18/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4552 - accuracy: 0.5469 - val_loss: 1.4614 - val_accuracy: 0.5230\n",
      "Epoch 19/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.4083 - accuracy: 0.5675 - val_loss: 1.4174 - val_accuracy: 0.5500\n",
      "Epoch 20/60\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.3622 - accuracy: 0.5900 - val_loss: 1.3743 - val_accuracy: 0.5630\n",
      "Epoch 21/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.3175 - accuracy: 0.6082 - val_loss: 1.3329 - val_accuracy: 0.5670\n",
      "Epoch 22/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2739 - accuracy: 0.6215 - val_loss: 1.2910 - val_accuracy: 0.5880\n",
      "Epoch 23/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2316 - accuracy: 0.6352 - val_loss: 1.2520 - val_accuracy: 0.6030\n",
      "Epoch 24/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1912 - accuracy: 0.6483 - val_loss: 1.2139 - val_accuracy: 0.6260\n",
      "Epoch 25/60\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.1530 - accuracy: 0.6591 - val_loss: 1.1789 - val_accuracy: 0.6420\n",
      "Epoch 26/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1168 - accuracy: 0.6697 - val_loss: 1.1449 - val_accuracy: 0.6440\n",
      "Epoch 27/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0827 - accuracy: 0.6789 - val_loss: 1.1131 - val_accuracy: 0.6520\n",
      "Epoch 28/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0506 - accuracy: 0.6838 - val_loss: 1.0845 - val_accuracy: 0.6620\n",
      "Epoch 29/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0205 - accuracy: 0.6909 - val_loss: 1.0555 - val_accuracy: 0.6740\n",
      "Epoch 30/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9923 - accuracy: 0.7005 - val_loss: 1.0302 - val_accuracy: 0.6780\n",
      "Epoch 31/60\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9658 - accuracy: 0.7029 - val_loss: 1.0052 - val_accuracy: 0.6780\n",
      "Epoch 32/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9411 - accuracy: 0.7069 - val_loss: 0.9829 - val_accuracy: 0.6830\n",
      "Epoch 33/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9180 - accuracy: 0.7140 - val_loss: 0.9607 - val_accuracy: 0.6880\n",
      "Epoch 34/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8958 - accuracy: 0.7205 - val_loss: 0.9405 - val_accuracy: 0.6910\n",
      "Epoch 35/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8754 - accuracy: 0.7245 - val_loss: 0.9234 - val_accuracy: 0.6950\n",
      "Epoch 36/60\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8564 - accuracy: 0.7269 - val_loss: 0.9060 - val_accuracy: 0.7010\n",
      "Epoch 37/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8389 - accuracy: 0.7328 - val_loss: 0.8896 - val_accuracy: 0.7020\n",
      "Epoch 38/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8216 - accuracy: 0.7348 - val_loss: 0.8741 - val_accuracy: 0.7050\n",
      "Epoch 39/60\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.8061 - accuracy: 0.7386 - val_loss: 0.8609 - val_accuracy: 0.7110\n",
      "Epoch 40/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7910 - accuracy: 0.7405 - val_loss: 0.8467 - val_accuracy: 0.7110\n",
      "Epoch 41/60\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.7770 - accuracy: 0.7432 - val_loss: 0.8356 - val_accuracy: 0.7120\n",
      "Epoch 42/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7643 - accuracy: 0.7506 - val_loss: 0.8239 - val_accuracy: 0.7140\n",
      "Epoch 43/60\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.7518 - accuracy: 0.7485 - val_loss: 0.8131 - val_accuracy: 0.7170\n",
      "Epoch 44/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7399 - accuracy: 0.7532 - val_loss: 0.8020 - val_accuracy: 0.7250\n",
      "Epoch 45/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7285 - accuracy: 0.7578 - val_loss: 0.7935 - val_accuracy: 0.7210\n",
      "Epoch 46/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.7178 - accuracy: 0.7614 - val_loss: 0.7842 - val_accuracy: 0.7280\n",
      "Epoch 47/60\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.7080 - accuracy: 0.7597 - val_loss: 0.7752 - val_accuracy: 0.7270\n",
      "Epoch 48/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.6985 - accuracy: 0.7628 - val_loss: 0.7673 - val_accuracy: 0.7310\n",
      "Epoch 49/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6892 - accuracy: 0.7678 - val_loss: 0.7621 - val_accuracy: 0.7330\n",
      "Epoch 50/60\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.6803 - accuracy: 0.7694 - val_loss: 0.7530 - val_accuracy: 0.7330\n",
      "Epoch 51/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6720 - accuracy: 0.7717 - val_loss: 0.7475 - val_accuracy: 0.7320\n",
      "Epoch 52/60\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.6638 - accuracy: 0.7729 - val_loss: 0.7406 - val_accuracy: 0.7390\n",
      "Epoch 53/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6562 - accuracy: 0.7749 - val_loss: 0.7340 - val_accuracy: 0.7400\n",
      "Epoch 54/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6488 - accuracy: 0.7786 - val_loss: 0.7289 - val_accuracy: 0.7400\n",
      "Epoch 55/60\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.6412 - accuracy: 0.7780 - val_loss: 0.7237 - val_accuracy: 0.7420\n",
      "Epoch 56/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6342 - accuracy: 0.7822 - val_loss: 0.7223 - val_accuracy: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6279 - accuracy: 0.7832 - val_loss: 0.7157 - val_accuracy: 0.7450\n",
      "Epoch 58/60\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.6213 - accuracy: 0.7835 - val_loss: 0.7097 - val_accuracy: 0.7440\n",
      "Epoch 59/60\n",
      "6500/6500 [==============================] - 0s 26us/step - loss: 0.6152 - accuracy: 0.7866 - val_loss: 0.7049 - val_accuracy: 0.7470\n",
      "Epoch 60/60\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.6090 - accuracy: 0.7883 - val_loss: 0.6999 - val_accuracy: 0.7490\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model = model.fit(X_train_final,\n",
    "                    y_train_final,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the test set to make label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 23us/step\n",
      "Training Loss: 0.604 Training Accuracy: 0.791\n",
      "2500/2500 [==============================] - 0s 22us/step\n",
      "Testing Loss: 0.729 Testing Accuracy: 0.727\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_final, y_train_final)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! your test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs model you originally fit.\n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "6500/6500 [==============================] - 0s 37us/step - loss: 2.5850 - accuracy: 0.1971 - val_loss: 2.5683 - val_accuracy: 0.2150\n",
      "Epoch 2/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.5671 - accuracy: 0.2149 - val_loss: 2.5507 - val_accuracy: 0.2270\n",
      "Epoch 3/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.5491 - accuracy: 0.2343 - val_loss: 2.5324 - val_accuracy: 0.2440\n",
      "Epoch 4/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.5299 - accuracy: 0.2478 - val_loss: 2.5126 - val_accuracy: 0.2600\n",
      "Epoch 5/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.5084 - accuracy: 0.2663 - val_loss: 2.4905 - val_accuracy: 0.2830\n",
      "Epoch 6/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.4843 - accuracy: 0.2840 - val_loss: 2.4656 - val_accuracy: 0.3010\n",
      "Epoch 7/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.4574 - accuracy: 0.2997 - val_loss: 2.4382 - val_accuracy: 0.3210\n",
      "Epoch 8/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.4281 - accuracy: 0.3177 - val_loss: 2.4085 - val_accuracy: 0.3300\n",
      "Epoch 9/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.3967 - accuracy: 0.3303 - val_loss: 2.3769 - val_accuracy: 0.3430\n",
      "Epoch 10/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.3632 - accuracy: 0.3471 - val_loss: 2.3437 - val_accuracy: 0.3540\n",
      "Epoch 11/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.3279 - accuracy: 0.3625 - val_loss: 2.3096 - val_accuracy: 0.3680\n",
      "Epoch 12/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.2914 - accuracy: 0.3738 - val_loss: 2.2748 - val_accuracy: 0.3950\n",
      "Epoch 13/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.2537 - accuracy: 0.3952 - val_loss: 2.2390 - val_accuracy: 0.4100\n",
      "Epoch 14/120\n",
      "6500/6500 [==============================] - 0s 37us/step - loss: 2.2152 - accuracy: 0.4146 - val_loss: 2.2026 - val_accuracy: 0.4350\n",
      "Epoch 15/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.1761 - accuracy: 0.4302 - val_loss: 2.1664 - val_accuracy: 0.4620\n",
      "Epoch 16/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.1371 - accuracy: 0.4589 - val_loss: 2.1296 - val_accuracy: 0.4720\n",
      "Epoch 17/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.0980 - accuracy: 0.4775 - val_loss: 2.0932 - val_accuracy: 0.4880\n",
      "Epoch 18/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.0594 - accuracy: 0.4980 - val_loss: 2.0579 - val_accuracy: 0.5160\n",
      "Epoch 19/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.0209 - accuracy: 0.5195 - val_loss: 2.0226 - val_accuracy: 0.5260\n",
      "Epoch 20/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.9836 - accuracy: 0.5392 - val_loss: 1.9888 - val_accuracy: 0.5390\n",
      "Epoch 21/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.9472 - accuracy: 0.5586 - val_loss: 1.9561 - val_accuracy: 0.5580\n",
      "Epoch 22/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.9122 - accuracy: 0.5760 - val_loss: 1.9244 - val_accuracy: 0.5640\n",
      "Epoch 23/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.8782 - accuracy: 0.5915 - val_loss: 1.8939 - val_accuracy: 0.5820\n",
      "Epoch 24/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.8461 - accuracy: 0.6052 - val_loss: 1.8651 - val_accuracy: 0.5870\n",
      "Epoch 25/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.8150 - accuracy: 0.6195 - val_loss: 1.8378 - val_accuracy: 0.5970\n",
      "Epoch 26/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.7855 - accuracy: 0.6326 - val_loss: 1.8102 - val_accuracy: 0.6050\n",
      "Epoch 27/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.7572 - accuracy: 0.6374 - val_loss: 1.7861 - val_accuracy: 0.6160\n",
      "Epoch 28/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.7301 - accuracy: 0.6475 - val_loss: 1.7617 - val_accuracy: 0.6300\n",
      "Epoch 29/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.7040 - accuracy: 0.6591 - val_loss: 1.7380 - val_accuracy: 0.6330\n",
      "Epoch 30/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6792 - accuracy: 0.6665 - val_loss: 1.7155 - val_accuracy: 0.6420\n",
      "Epoch 31/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 1.6552 - accuracy: 0.6760 - val_loss: 1.6938 - val_accuracy: 0.6400\n",
      "Epoch 32/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6329 - accuracy: 0.6846 - val_loss: 1.6735 - val_accuracy: 0.6550\n",
      "Epoch 33/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.6110 - accuracy: 0.6885 - val_loss: 1.6554 - val_accuracy: 0.6670\n",
      "Epoch 34/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5898 - accuracy: 0.6968 - val_loss: 1.6355 - val_accuracy: 0.6690\n",
      "Epoch 35/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5697 - accuracy: 0.6985 - val_loss: 1.6177 - val_accuracy: 0.6790\n",
      "Epoch 36/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5508 - accuracy: 0.7034 - val_loss: 1.5999 - val_accuracy: 0.6800\n",
      "Epoch 37/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5319 - accuracy: 0.7054 - val_loss: 1.5843 - val_accuracy: 0.6880\n",
      "Epoch 38/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.5141 - accuracy: 0.7131 - val_loss: 1.5683 - val_accuracy: 0.6860\n",
      "Epoch 39/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4965 - accuracy: 0.7166 - val_loss: 1.5540 - val_accuracy: 0.6940\n",
      "Epoch 40/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4805 - accuracy: 0.7202 - val_loss: 1.5405 - val_accuracy: 0.6950\n",
      "Epoch 41/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4641 - accuracy: 0.7251 - val_loss: 1.5244 - val_accuracy: 0.6940\n",
      "Epoch 42/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4486 - accuracy: 0.7246 - val_loss: 1.5116 - val_accuracy: 0.6990\n",
      "Epoch 43/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.4338 - accuracy: 0.7303 - val_loss: 1.4977 - val_accuracy: 0.6980\n",
      "Epoch 44/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4189 - accuracy: 0.7317 - val_loss: 1.4858 - val_accuracy: 0.7090\n",
      "Epoch 45/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4051 - accuracy: 0.7345 - val_loss: 1.4724 - val_accuracy: 0.7040\n",
      "Epoch 46/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.3914 - accuracy: 0.7412 - val_loss: 1.4620 - val_accuracy: 0.7060\n",
      "Epoch 47/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.3787 - accuracy: 0.7432 - val_loss: 1.4503 - val_accuracy: 0.7110\n",
      "Epoch 48/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.3660 - accuracy: 0.7446 - val_loss: 1.4399 - val_accuracy: 0.7160\n",
      "Epoch 49/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.3537 - accuracy: 0.7488 - val_loss: 1.4288 - val_accuracy: 0.7230\n",
      "Epoch 50/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.3418 - accuracy: 0.7508 - val_loss: 1.4191 - val_accuracy: 0.7240\n",
      "Epoch 51/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.3301 - accuracy: 0.7534 - val_loss: 1.4082 - val_accuracy: 0.7270\n",
      "Epoch 52/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3192 - accuracy: 0.7552 - val_loss: 1.4001 - val_accuracy: 0.7260\n",
      "Epoch 53/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.3079 - accuracy: 0.7594 - val_loss: 1.3914 - val_accuracy: 0.7270\n",
      "Epoch 54/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2976 - accuracy: 0.7618 - val_loss: 1.3822 - val_accuracy: 0.7280\n",
      "Epoch 55/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2876 - accuracy: 0.7648 - val_loss: 1.3740 - val_accuracy: 0.7310\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2772 - accuracy: 0.7682 - val_loss: 1.3637 - val_accuracy: 0.7270\n",
      "Epoch 57/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2676 - accuracy: 0.7682 - val_loss: 1.3567 - val_accuracy: 0.7340\n",
      "Epoch 58/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.2579 - accuracy: 0.7717 - val_loss: 1.3510 - val_accuracy: 0.7340\n",
      "Epoch 59/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2493 - accuracy: 0.7725 - val_loss: 1.3424 - val_accuracy: 0.7350\n",
      "Epoch 60/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2402 - accuracy: 0.7749 - val_loss: 1.3334 - val_accuracy: 0.7370\n",
      "Epoch 61/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2311 - accuracy: 0.7760 - val_loss: 1.3268 - val_accuracy: 0.7380\n",
      "Epoch 62/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2226 - accuracy: 0.7812 - val_loss: 1.3201 - val_accuracy: 0.7440\n",
      "Epoch 63/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2147 - accuracy: 0.7814 - val_loss: 1.3133 - val_accuracy: 0.7450\n",
      "Epoch 64/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.2064 - accuracy: 0.7835 - val_loss: 1.3067 - val_accuracy: 0.7410\n",
      "Epoch 65/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1984 - accuracy: 0.7845 - val_loss: 1.3012 - val_accuracy: 0.7410\n",
      "Epoch 66/120\n",
      "6500/6500 [==============================] - 0s 33us/step - loss: 1.1909 - accuracy: 0.7878 - val_loss: 1.2949 - val_accuracy: 0.7470\n",
      "Epoch 67/120\n",
      "6500/6500 [==============================] - 0s 33us/step - loss: 1.1833 - accuracy: 0.7915 - val_loss: 1.2889 - val_accuracy: 0.7450\n",
      "Epoch 68/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.1760 - accuracy: 0.7911 - val_loss: 1.2828 - val_accuracy: 0.7510\n",
      "Epoch 69/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.1685 - accuracy: 0.7965 - val_loss: 1.2767 - val_accuracy: 0.7480\n",
      "Epoch 70/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.1611 - accuracy: 0.7952 - val_loss: 1.2726 - val_accuracy: 0.7500\n",
      "Epoch 71/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1539 - accuracy: 0.7971 - val_loss: 1.2679 - val_accuracy: 0.7520\n",
      "Epoch 72/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1478 - accuracy: 0.7958 - val_loss: 1.2616 - val_accuracy: 0.7510\n",
      "Epoch 73/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1406 - accuracy: 0.8017 - val_loss: 1.2566 - val_accuracy: 0.7530\n",
      "Epoch 74/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1338 - accuracy: 0.8035 - val_loss: 1.2525 - val_accuracy: 0.7540\n",
      "Epoch 75/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1272 - accuracy: 0.8057 - val_loss: 1.2471 - val_accuracy: 0.7530\n",
      "Epoch 76/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1207 - accuracy: 0.8063 - val_loss: 1.2424 - val_accuracy: 0.7570\n",
      "Epoch 77/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1147 - accuracy: 0.8097 - val_loss: 1.2384 - val_accuracy: 0.7550\n",
      "Epoch 78/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.1084 - accuracy: 0.8120 - val_loss: 1.2332 - val_accuracy: 0.7590\n",
      "Epoch 79/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.1025 - accuracy: 0.8108 - val_loss: 1.2289 - val_accuracy: 0.7520\n",
      "Epoch 80/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 1.0961 - accuracy: 0.8128 - val_loss: 1.2256 - val_accuracy: 0.7550\n",
      "Epoch 81/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0908 - accuracy: 0.8174 - val_loss: 1.2202 - val_accuracy: 0.7540\n",
      "Epoch 82/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0842 - accuracy: 0.8162 - val_loss: 1.2175 - val_accuracy: 0.7550\n",
      "Epoch 83/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0788 - accuracy: 0.8198 - val_loss: 1.2125 - val_accuracy: 0.7540\n",
      "Epoch 84/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0731 - accuracy: 0.8214 - val_loss: 1.2100 - val_accuracy: 0.7620\n",
      "Epoch 85/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0680 - accuracy: 0.8218 - val_loss: 1.2045 - val_accuracy: 0.7600\n",
      "Epoch 86/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0621 - accuracy: 0.8243 - val_loss: 1.2003 - val_accuracy: 0.7590\n",
      "Epoch 87/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0568 - accuracy: 0.8257 - val_loss: 1.1966 - val_accuracy: 0.7600\n",
      "Epoch 88/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0516 - accuracy: 0.8258 - val_loss: 1.1936 - val_accuracy: 0.7590\n",
      "Epoch 89/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0464 - accuracy: 0.8285 - val_loss: 1.1894 - val_accuracy: 0.7590\n",
      "Epoch 90/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0411 - accuracy: 0.8308 - val_loss: 1.1866 - val_accuracy: 0.7590\n",
      "Epoch 91/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0361 - accuracy: 0.8325 - val_loss: 1.1832 - val_accuracy: 0.7640\n",
      "Epoch 92/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0303 - accuracy: 0.8325 - val_loss: 1.1802 - val_accuracy: 0.7600\n",
      "Epoch 93/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0257 - accuracy: 0.8331 - val_loss: 1.1767 - val_accuracy: 0.7580\n",
      "Epoch 94/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0211 - accuracy: 0.8355 - val_loss: 1.1729 - val_accuracy: 0.7600\n",
      "Epoch 95/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0157 - accuracy: 0.8386 - val_loss: 1.1701 - val_accuracy: 0.7580\n",
      "Epoch 96/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0110 - accuracy: 0.8400 - val_loss: 1.1687 - val_accuracy: 0.7610\n",
      "Epoch 97/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0063 - accuracy: 0.8415 - val_loss: 1.1652 - val_accuracy: 0.7670\n",
      "Epoch 98/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0018 - accuracy: 0.8422 - val_loss: 1.1610 - val_accuracy: 0.7610\n",
      "Epoch 99/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9970 - accuracy: 0.8431 - val_loss: 1.1588 - val_accuracy: 0.7580\n",
      "Epoch 100/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9925 - accuracy: 0.8451 - val_loss: 1.1552 - val_accuracy: 0.7610\n",
      "Epoch 101/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9877 - accuracy: 0.8460 - val_loss: 1.1522 - val_accuracy: 0.7680\n",
      "Epoch 102/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9830 - accuracy: 0.8469 - val_loss: 1.1507 - val_accuracy: 0.7630\n",
      "Epoch 103/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9789 - accuracy: 0.8471 - val_loss: 1.1474 - val_accuracy: 0.7680\n",
      "Epoch 104/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9742 - accuracy: 0.8494 - val_loss: 1.1454 - val_accuracy: 0.7670\n",
      "Epoch 105/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9699 - accuracy: 0.8497 - val_loss: 1.1423 - val_accuracy: 0.7690\n",
      "Epoch 106/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9651 - accuracy: 0.8517 - val_loss: 1.1396 - val_accuracy: 0.7680\n",
      "Epoch 107/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9610 - accuracy: 0.8534 - val_loss: 1.1374 - val_accuracy: 0.7680\n",
      "Epoch 108/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9569 - accuracy: 0.8537 - val_loss: 1.1350 - val_accuracy: 0.7700\n",
      "Epoch 109/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9524 - accuracy: 0.8554 - val_loss: 1.1312 - val_accuracy: 0.7640\n",
      "Epoch 110/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9485 - accuracy: 0.8577 - val_loss: 1.1298 - val_accuracy: 0.7700\n",
      "Epoch 111/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9446 - accuracy: 0.8578 - val_loss: 1.1261 - val_accuracy: 0.7670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.9397 - accuracy: 0.8591 - val_loss: 1.1242 - val_accuracy: 0.7700\n",
      "Epoch 113/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9361 - accuracy: 0.8606 - val_loss: 1.1216 - val_accuracy: 0.7690\n",
      "Epoch 114/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9318 - accuracy: 0.8632 - val_loss: 1.1233 - val_accuracy: 0.7700\n",
      "Epoch 115/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9282 - accuracy: 0.8615 - val_loss: 1.1163 - val_accuracy: 0.7680\n",
      "Epoch 116/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9240 - accuracy: 0.8646 - val_loss: 1.1160 - val_accuracy: 0.7710\n",
      "Epoch 117/120\n",
      "6500/6500 [==============================] - 0s 36us/step - loss: 0.9199 - accuracy: 0.8655 - val_loss: 1.1154 - val_accuracy: 0.7730\n",
      "Epoch 118/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.9162 - accuracy: 0.8655 - val_loss: 1.1114 - val_accuracy: 0.7690\n",
      "Epoch 119/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9122 - accuracy: 0.8654 - val_loss: 1.1099 - val_accuracy: 0.7710\n",
      "Epoch 120/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9084 - accuracy: 0.8694 - val_loss: 1.1074 - val_accuracy: 0.7740\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model.fit(X_train_final,\n",
    "                    y_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = L2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = L2_model_dict['accuracy'] \n",
    "val_acc_values = L2_model_dict['val_accuracy']\n",
    "\n",
    "model_acc = model_val_dict['accuracy']\n",
    "model_val_acc = model_val_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, model_acc, label='Training acc')\n",
    "ax.plot(epochs, model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at L1 regularization. Will this work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 16.0355 - accuracy: 0.1535 - val_loss: 15.6702 - val_accuracy: 0.1890\n",
      "Epoch 2/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 15.3720 - accuracy: 0.1834 - val_loss: 15.0207 - val_accuracy: 0.2120\n",
      "Epoch 3/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 14.7301 - accuracy: 0.1988 - val_loss: 14.3891 - val_accuracy: 0.2180\n",
      "Epoch 4/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 14.1060 - accuracy: 0.2043 - val_loss: 13.7746 - val_accuracy: 0.2170\n",
      "Epoch 5/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 13.4985 - accuracy: 0.2058 - val_loss: 13.1770 - val_accuracy: 0.2200\n",
      "Epoch 6/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 12.9075 - accuracy: 0.2118 - val_loss: 12.5951 - val_accuracy: 0.2240\n",
      "Epoch 7/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 12.3319 - accuracy: 0.2205 - val_loss: 12.0289 - val_accuracy: 0.2290\n",
      "Epoch 8/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 11.7715 - accuracy: 0.2302 - val_loss: 11.4780 - val_accuracy: 0.2520\n",
      "Epoch 9/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 11.2262 - accuracy: 0.2458 - val_loss: 10.9422 - val_accuracy: 0.2710\n",
      "Epoch 10/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 10.6958 - accuracy: 0.2672 - val_loss: 10.4209 - val_accuracy: 0.2900\n",
      "Epoch 11/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 10.1795 - accuracy: 0.2963 - val_loss: 9.9127 - val_accuracy: 0.3020\n",
      "Epoch 12/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 9.6774 - accuracy: 0.3148 - val_loss: 9.4196 - val_accuracy: 0.3230\n",
      "Epoch 13/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 9.1902 - accuracy: 0.3420 - val_loss: 8.9419 - val_accuracy: 0.3580\n",
      "Epoch 14/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 8.7181 - accuracy: 0.3697 - val_loss: 8.4789 - val_accuracy: 0.3680\n",
      "Epoch 15/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 8.2612 - accuracy: 0.3897 - val_loss: 8.0321 - val_accuracy: 0.3840\n",
      "Epoch 16/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 7.8205 - accuracy: 0.4045 - val_loss: 7.6016 - val_accuracy: 0.4010\n",
      "Epoch 17/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 7.3962 - accuracy: 0.4205 - val_loss: 7.1870 - val_accuracy: 0.4220\n",
      "Epoch 18/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 6.9879 - accuracy: 0.4300 - val_loss: 6.7883 - val_accuracy: 0.4280\n",
      "Epoch 19/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 6.5965 - accuracy: 0.4428 - val_loss: 6.4063 - val_accuracy: 0.4310\n",
      "Epoch 20/120\n",
      "6500/6500 [==============================] - 0s 34us/step - loss: 6.2223 - accuracy: 0.4526 - val_loss: 6.0443 - val_accuracy: 0.4600\n",
      "Epoch 21/120\n",
      "6500/6500 [==============================] - 0s 34us/step - loss: 5.8655 - accuracy: 0.4662 - val_loss: 5.6964 - val_accuracy: 0.4710\n",
      "Epoch 22/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 5.5252 - accuracy: 0.4789 - val_loss: 5.3650 - val_accuracy: 0.4720\n",
      "Epoch 23/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 5.2014 - accuracy: 0.4942 - val_loss: 5.0506 - val_accuracy: 0.4830\n",
      "Epoch 24/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 4.8939 - accuracy: 0.5048 - val_loss: 4.7534 - val_accuracy: 0.5050\n",
      "Epoch 25/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 4.6039 - accuracy: 0.5234 - val_loss: 4.4728 - val_accuracy: 0.5200\n",
      "Epoch 26/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 4.3303 - accuracy: 0.5386 - val_loss: 4.2089 - val_accuracy: 0.5290\n",
      "Epoch 27/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 4.0736 - accuracy: 0.5545 - val_loss: 3.9619 - val_accuracy: 0.5310\n",
      "Epoch 28/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 3.8334 - accuracy: 0.5632 - val_loss: 3.7325 - val_accuracy: 0.5460\n",
      "Epoch 29/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 3.6099 - accuracy: 0.5766 - val_loss: 3.5176 - val_accuracy: 0.5490\n",
      "Epoch 30/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 3.4026 - accuracy: 0.5886 - val_loss: 3.3211 - val_accuracy: 0.5580\n",
      "Epoch 31/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 3.2110 - accuracy: 0.5965 - val_loss: 3.1377 - val_accuracy: 0.5750\n",
      "Epoch 32/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 3.0355 - accuracy: 0.6054 - val_loss: 2.9714 - val_accuracy: 0.5830\n",
      "Epoch 33/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.8759 - accuracy: 0.6111 - val_loss: 2.8218 - val_accuracy: 0.5960\n",
      "Epoch 34/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 2.7321 - accuracy: 0.6178 - val_loss: 2.6871 - val_accuracy: 0.5910\n",
      "Epoch 35/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.6032 - accuracy: 0.6205 - val_loss: 2.5650 - val_accuracy: 0.6070\n",
      "Epoch 36/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 2.4897 - accuracy: 0.6289 - val_loss: 2.4598 - val_accuracy: 0.6120\n",
      "Epoch 37/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.3914 - accuracy: 0.6297 - val_loss: 2.3698 - val_accuracy: 0.6110\n",
      "Epoch 38/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.3075 - accuracy: 0.6329 - val_loss: 2.2944 - val_accuracy: 0.6280\n",
      "Epoch 39/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 2.2380 - accuracy: 0.6349 - val_loss: 2.2322 - val_accuracy: 0.6270\n",
      "Epoch 40/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 2.1811 - accuracy: 0.6365 - val_loss: 2.1820 - val_accuracy: 0.6250\n",
      "Epoch 41/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.1364 - accuracy: 0.6409 - val_loss: 2.1451 - val_accuracy: 0.6220\n",
      "Epoch 42/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.1018 - accuracy: 0.6400 - val_loss: 2.1138 - val_accuracy: 0.6330\n",
      "Epoch 43/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 2.0739 - accuracy: 0.6429 - val_loss: 2.0878 - val_accuracy: 0.6250\n",
      "Epoch 44/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.0498 - accuracy: 0.6449 - val_loss: 2.0657 - val_accuracy: 0.6310\n",
      "Epoch 45/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 2.0280 - accuracy: 0.6458 - val_loss: 2.0453 - val_accuracy: 0.6320\n",
      "Epoch 46/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 2.0081 - accuracy: 0.6469 - val_loss: 2.0261 - val_accuracy: 0.6310\n",
      "Epoch 47/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.9895 - accuracy: 0.6452 - val_loss: 2.0091 - val_accuracy: 0.6290\n",
      "Epoch 48/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.9718 - accuracy: 0.6463 - val_loss: 1.9907 - val_accuracy: 0.6300\n",
      "Epoch 49/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.9546 - accuracy: 0.6500 - val_loss: 1.9762 - val_accuracy: 0.6400\n",
      "Epoch 50/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.9390 - accuracy: 0.6500 - val_loss: 1.9587 - val_accuracy: 0.6380\n",
      "Epoch 51/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.9235 - accuracy: 0.6517 - val_loss: 1.9444 - val_accuracy: 0.6420\n",
      "Epoch 52/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.9084 - accuracy: 0.6517 - val_loss: 1.9307 - val_accuracy: 0.6410\n",
      "Epoch 53/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.8944 - accuracy: 0.6526 - val_loss: 1.9190 - val_accuracy: 0.6410\n",
      "Epoch 54/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.8807 - accuracy: 0.6545 - val_loss: 1.9037 - val_accuracy: 0.6430\n",
      "Epoch 55/120\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 1.8711 - accuracy: 0.65 - 0s 30us/step - loss: 1.8678 - accuracy: 0.6546 - val_loss: 1.8920 - val_accuracy: 0.6380\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8553 - accuracy: 0.6569 - val_loss: 1.8787 - val_accuracy: 0.6450\n",
      "Epoch 57/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8431 - accuracy: 0.6562 - val_loss: 1.8654 - val_accuracy: 0.6500\n",
      "Epoch 58/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.8314 - accuracy: 0.6578 - val_loss: 1.8534 - val_accuracy: 0.6490\n",
      "Epoch 59/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.8199 - accuracy: 0.6578 - val_loss: 1.8409 - val_accuracy: 0.6490\n",
      "Epoch 60/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.8082 - accuracy: 0.6588 - val_loss: 1.8345 - val_accuracy: 0.6570\n",
      "Epoch 61/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.7982 - accuracy: 0.6589 - val_loss: 1.8219 - val_accuracy: 0.6550\n",
      "Epoch 62/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.7875 - accuracy: 0.6623 - val_loss: 1.8101 - val_accuracy: 0.6510\n",
      "Epoch 63/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.7777 - accuracy: 0.6623 - val_loss: 1.7986 - val_accuracy: 0.6510\n",
      "Epoch 64/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.7672 - accuracy: 0.6625 - val_loss: 1.7886 - val_accuracy: 0.6540\n",
      "Epoch 65/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.7573 - accuracy: 0.6620 - val_loss: 1.7794 - val_accuracy: 0.6570\n",
      "Epoch 66/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.7480 - accuracy: 0.6640 - val_loss: 1.7698 - val_accuracy: 0.6590\n",
      "Epoch 67/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.7387 - accuracy: 0.6671 - val_loss: 1.7604 - val_accuracy: 0.6550\n",
      "Epoch 68/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.7295 - accuracy: 0.6626 - val_loss: 1.7495 - val_accuracy: 0.6530\n",
      "Epoch 69/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.7205 - accuracy: 0.6665 - val_loss: 1.7415 - val_accuracy: 0.6550\n",
      "Epoch 70/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.7119 - accuracy: 0.6658 - val_loss: 1.7335 - val_accuracy: 0.6590\n",
      "Epoch 71/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.7033 - accuracy: 0.6674 - val_loss: 1.7241 - val_accuracy: 0.6630\n",
      "Epoch 72/120\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 1.6939 - accuracy: 0.67 - 0s 37us/step - loss: 1.6950 - accuracy: 0.6683 - val_loss: 1.7152 - val_accuracy: 0.6600\n",
      "Epoch 73/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.6866 - accuracy: 0.6665 - val_loss: 1.7068 - val_accuracy: 0.6660\n",
      "Epoch 74/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.6786 - accuracy: 0.6692 - val_loss: 1.6985 - val_accuracy: 0.6630\n",
      "Epoch 75/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6706 - accuracy: 0.6700 - val_loss: 1.6925 - val_accuracy: 0.6690\n",
      "Epoch 76/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6629 - accuracy: 0.6720 - val_loss: 1.6813 - val_accuracy: 0.6680\n",
      "Epoch 77/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6548 - accuracy: 0.6734 - val_loss: 1.6732 - val_accuracy: 0.6670\n",
      "Epoch 78/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6472 - accuracy: 0.6728 - val_loss: 1.6684 - val_accuracy: 0.6750\n",
      "Epoch 79/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.6399 - accuracy: 0.6735 - val_loss: 1.6589 - val_accuracy: 0.6630\n",
      "Epoch 80/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.6322 - accuracy: 0.6746 - val_loss: 1.6504 - val_accuracy: 0.6690\n",
      "Epoch 81/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6246 - accuracy: 0.6751 - val_loss: 1.6438 - val_accuracy: 0.6720\n",
      "Epoch 82/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.6175 - accuracy: 0.6746 - val_loss: 1.6357 - val_accuracy: 0.6750\n",
      "Epoch 83/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6101 - accuracy: 0.6775 - val_loss: 1.6278 - val_accuracy: 0.6750\n",
      "Epoch 84/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.6029 - accuracy: 0.6777 - val_loss: 1.6209 - val_accuracy: 0.6790\n",
      "Epoch 85/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5962 - accuracy: 0.6798 - val_loss: 1.6191 - val_accuracy: 0.6780\n",
      "Epoch 86/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5894 - accuracy: 0.6815 - val_loss: 1.6058 - val_accuracy: 0.6790\n",
      "Epoch 87/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5824 - accuracy: 0.6803 - val_loss: 1.5991 - val_accuracy: 0.6750\n",
      "Epoch 88/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.5760 - accuracy: 0.6817 - val_loss: 1.5918 - val_accuracy: 0.6780\n",
      "Epoch 89/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5685 - accuracy: 0.6820 - val_loss: 1.5850 - val_accuracy: 0.6760\n",
      "Epoch 90/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.5621 - accuracy: 0.6849 - val_loss: 1.5787 - val_accuracy: 0.6770\n",
      "Epoch 91/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.5554 - accuracy: 0.6852 - val_loss: 1.5704 - val_accuracy: 0.6810\n",
      "Epoch 92/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5491 - accuracy: 0.6835 - val_loss: 1.5627 - val_accuracy: 0.6830\n",
      "Epoch 93/120\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 1.5429 - accuracy: 0.6858 - val_loss: 1.5578 - val_accuracy: 0.6770\n",
      "Epoch 94/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.5361 - accuracy: 0.6858 - val_loss: 1.5511 - val_accuracy: 0.6790\n",
      "Epoch 95/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5297 - accuracy: 0.6863 - val_loss: 1.5468 - val_accuracy: 0.6850\n",
      "Epoch 96/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5233 - accuracy: 0.6862 - val_loss: 1.5382 - val_accuracy: 0.6810\n",
      "Epoch 97/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.5171 - accuracy: 0.6868 - val_loss: 1.5308 - val_accuracy: 0.6790\n",
      "Epoch 98/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.5112 - accuracy: 0.6882 - val_loss: 1.5260 - val_accuracy: 0.6830\n",
      "Epoch 99/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.5051 - accuracy: 0.6882 - val_loss: 1.5194 - val_accuracy: 0.6850\n",
      "Epoch 100/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4994 - accuracy: 0.6885 - val_loss: 1.5124 - val_accuracy: 0.6850\n",
      "Epoch 101/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4931 - accuracy: 0.6911 - val_loss: 1.5059 - val_accuracy: 0.6830\n",
      "Epoch 102/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4877 - accuracy: 0.6868 - val_loss: 1.4996 - val_accuracy: 0.6840\n",
      "Epoch 103/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4816 - accuracy: 0.6900 - val_loss: 1.4961 - val_accuracy: 0.6880\n",
      "Epoch 104/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4761 - accuracy: 0.6949 - val_loss: 1.4883 - val_accuracy: 0.6890\n",
      "Epoch 105/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4699 - accuracy: 0.6931 - val_loss: 1.4831 - val_accuracy: 0.6880\n",
      "Epoch 106/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4645 - accuracy: 0.6931 - val_loss: 1.4761 - val_accuracy: 0.6920\n",
      "Epoch 107/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4591 - accuracy: 0.6946 - val_loss: 1.4692 - val_accuracy: 0.6910\n",
      "Epoch 108/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.4531 - accuracy: 0.6942 - val_loss: 1.4640 - val_accuracy: 0.6890\n",
      "Epoch 109/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4477 - accuracy: 0.6943 - val_loss: 1.4584 - val_accuracy: 0.6940\n",
      "Epoch 110/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4425 - accuracy: 0.6934 - val_loss: 1.4555 - val_accuracy: 0.6990\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4375 - accuracy: 0.6955 - val_loss: 1.4522 - val_accuracy: 0.7010\n",
      "Epoch 112/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4317 - accuracy: 0.6963 - val_loss: 1.4397 - val_accuracy: 0.6980\n",
      "Epoch 113/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4268 - accuracy: 0.6968 - val_loss: 1.4378 - val_accuracy: 0.6970\n",
      "Epoch 114/120\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4218 - accuracy: 0.6966 - val_loss: 1.4310 - val_accuracy: 0.6990\n",
      "Epoch 115/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.4161 - accuracy: 0.6969 - val_loss: 1.4271 - val_accuracy: 0.6990\n",
      "Epoch 116/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4112 - accuracy: 0.6991 - val_loss: 1.4203 - val_accuracy: 0.6960\n",
      "Epoch 117/120\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.4064 - accuracy: 0.6977 - val_loss: 1.4162 - val_accuracy: 0.7020\n",
      "Epoch 118/120\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.4007 - accuracy: 0.6974 - val_loss: 1.4108 - val_accuracy: 0.7010\n",
      "Epoch 119/120\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3958 - accuracy: 0.6989 - val_loss: 1.4051 - val_accuracy: 0.7060\n",
      "Epoch 120/120\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.3911 - accuracy: 0.6995 - val_loss: 1.3981 - val_accuracy: 0.7030\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_final,\n",
    "                    y_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAHwCAYAAACG+PhNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8VUX6+PHPpPceCCSBhN5DCQEEBESaBRQr2BGxYFvd3S/rugu6ruvPtfe1u4qgYgMXUEGKiAih95YEElJII73de+f3x9z0kISQBIjP+/W6L3LvmTNnzrk35LlznplRWmuEEEIIIYQQTeNwrhsghBBCCCHEhUwCaiGEEEIIIc6CBNRCCCGEEEKcBQmohRBCCCGEOAsSUAshhBBCCHEWJKAWQgghhBDiLEhALcQFSinlqJTKV0p1as6y5zul1CdKqQX2n8cqpfY2pmwTjtNmrtn5Til1UCk1up7tG5RSt7dik1qdUuoppdSHZ7H/u0qpx5qxSeX1/qCUuqm56xWirZGAWohWYg/Oyh82pVRRledn/AdLa23VWntprY83Z9mmUEoNVUptU0rlKaUOKKUubYnj1KS1Xqu17tscddUM2lr6molKWuueWuufoVkCy0uVUgmn2TZeKbVWKZWrlDrS1GOcj7TWs7XWT59NHXVde631RK31wrNqnBC/AxJQC9FK7MGZl9baCzgOXFnltVp/sJRSTq3fyiZ7A1gK+ACXASfObXPE6SilHJRSv9f/+wuAd4H/O9Mdz+ffR6WU47lugxC/d7/X/1SFOO/Ye4c+U0otUkrlATcrpUYopTYppU4ppVKUUq8opZzt5Z2UUlopFWF//ol9+wp7T/GvSqnIMy1r3z5FKXVIKZWjlHpVKfVLA7fcLcAxbcRprfc3cK6HlVKTqzx3UUplKaUG2AO+JUqpVPt5r1VK9T5NPdV6I5VSQ5RSO+zntAhwrbItUCm1XCmVrpTKVkotU0qF2rf9P2AE8Jb9jsFLdVwzP/t1S1dKJSil/qKUUvZts5VS65RSL9rbHKeUmljP+T9uL5OnlNqrlJpaY/vd9p7+PKXUHqVUlP31zkqpb+xtyFBKvWx/vVrPolKqm1JKV3m+QSn1D6XUr5igspO9zfvtxziqlJpdow3T7dcyVyl1RCk1USk1Qyn1W41y/6eUWlLHOU5QSm2v8nytUmpjleeblFJX2H9OUiZ95wrgz8BN9vdha5UqI5VSG+3tXamUCjjd9T0drfUmrfUnQHxDZcuvoVLqDqXUceAH++sjVeXv5A6l1MVV9ulqv9Z5yqRKvFn+vtT8rFY97zqOXe/vgP1z+Lr9OhQAo1X1VKgVqvYdsZvt216zHzdXKbVFKXWR/fU6r72qcufG3q6/K6WOKaVOKqU+VEr51Lhet9rrT1dKzWvcOyPEhU8CaiHOL1cDnwK+wGeYQPUhIAgYCUwG7q5n/5nA34AATC/4P860rFKqHfA58Cf7ceOBmAbavRl4vjzwa4RFwIwqz6cAyVrrXfbn3wHdgRBgD/BxQxUqpVyBb4H3Mef0LXBVlSIOwDtAJ6AzUAa8DKC1/j/gV+Ae+x2Dh+s4xBuAB9AFuAS4E7i1yvaLgN1AIPAi8F49zT2EeT99gX8Cnyql2tvPYwbwOHATpsd/OpClTA/p/4AjQAQQjnmfGusWYJa9ziQgDbjc/vwu4FWl1AB7Gy7CXMdHAT9gHHAM+AboqZTqXqXem6n7/dkI9FZK+SulXIBemKDYUynlCQwENlTdQWv9HfAssND+PgypsnkmcBvQHvAEHjmDcz8bF2PafrlSKhxzJ2Y+5jM2D/hKKRVoL7sI+AXzGXgKc22aqqHfgZnAE4A35rNbQWs9pcrdsBuBFGCNffNvwAB7+5cAXyilXBu49uVm289pLNAV8Mf+O1TFRUA3YBLwRI3PihBtlgTUQpxfNmitl2mtbVrrIq31Fq31b1pri9Y6DngbGFPP/ku01rFa6zJgISZoOdOyVwA7tNbf2re9CGScrhJ7z9dIzB/a/1UJyqbU7M2s4lPgKqWUm/35TPtr2M/9Q611nta6GFgADLEHYfUZCWjgVa11mdZ6MVDRQ6q1Ttdaf22/rrnA09R/LaueozNwPTDP3q44zHW5pUqxo1rr97XWVuAjIEwpFVRXfVrrz7XWKfZz/RRIAKLtm2cDz2itt9p7/A9prRMxPehBwP9prQvs5/FLY9pv977Wer/92ljsn7M4+zF+AlYD5QMD7wTe0VqvtrcxUWt9UGtdBHyBPVBUSg0EOgDL6zjHAsz1H435QrYNE/iNwARd+7TWp86g/e9prQ9rrQvtbajvs92c5mutC+3nfiuwVGv9vf26rAR2ApOVUl2AKGCB1rpUa70e8wXojDXyd+BrrfWv9rIlddWjlOqF+WJ0ndb6hL3uj7XWWVprCyaA9sEEwI1xE/Cc1jpea50HPAbMVNVTiBZorYu11tuAvZhrIkSbJwG1EOeXxKpPlFK9lFL/s9/6zQWexARVp5Na5edCwKsJZTtWbYfWWmN6NE/nIeAVrfVyYC7wgz2ovghYVdcOWusDwFFMr58XJoj/FCpm13hWmZSIXEyPLNR/3uXtTrK3t9yx8h/sPaPvKqWO2+v9qRF1lmsHOFatz/5zaJXnNa8nnOb6K6VuV0rttN/OP4XpAS1vSzjm2tQUDiTYA/amqPnZukIp9ZsyqTangImNaAOYLwvlg2hvBj6zf/GqyzpMb+bF9p/XYr7EjLE/PxNn8tluTlWvW2dgRvn7Zr9uwzGfvY5Apj3wrmvfRmvk70C9dSul/DC96X/RWldNtfmzMulEOUA2pre/sb8HHan9O+ACBJe/oLU+V++TEOeUBNRCnF90jef/wdzu7aa19gH+DqgWbkMKEFb+RCmlqB441uSESU1Ba/0tZsDXKkyw9VI9+5WnfVyN6RFPsL9+K2Zg4yWYlIjy3rOGzrtau+2qTnn3ZyASiLFfy0tqlK157as6CVgxAVXVus948KW9J/NN4F4gUGvtBxyg8vwSMbfTa0oEOqu6B6AVYNJRyoXUUaZqTrU75nb/v4D29jb80Ig2oLXeYK9jJOb9qy8dp2ZAvY6GA+r63odWV+MLWiLwgdbar8rDU2v9b8znL7DKXRcwX0zKVXuP7Ck8gdStMb8Dp71O9s/IYmCl1vq9Kq+Pw6TKXINJ5fEH8qvU29C1T6b270ApkN7AfkK0eRJQC3F+8wZygAL7oKT68qeby3fAYKXUlfY/+g9RpQeqDl8AC5RS/e23fg9g/si6A2717LcIkzs9B3vvtJ03UAJkYgKQfzay3RsAB6XU/coMKLwOGFyj3kIg257z+vca+6dh8qNrsffALgGeVkp5KTOA8w/AJ41sW1VemMAlHfN9ZTamh7rcu8CflVKDlNHdnrv7K+aaPK2U8lBKuduDWoAdwBilVLi9Z7KhwWCumJ7FdMBqH5A2vsr294DZSqlx9oFoYUqpnlW2f4z5UlCgtd5Uz3E2AH2BQcBWYBcmOIwGfj7NPmlAhP2LXFMppZRbjYeyn4sb4FyljPMZ1PsxcLUyAy4d7fuPU0p11FofxeTQz1dmkO0oTI56uQOAt1Jqkv2Y8+3tqEtTfwfKPWOvu2aeuTfmy2+GffsCTA91uYau/SLgEaVUhFLK296uRVpr2xm2T4g2RwJqIc5vj2IGYuVheqs/a+kDaq3TgBuAFzB/0LticmHrzNME/h/wX8zt5SxMr/RszB/f/yn7LAB1HCcJiMXcMq86uO4DTE9YMiYHc2PtveusrwTT230X5lb2dMwgunIvYHr7Mu11rqhRxUtU3s5/oY5D3If5ohCP6V39yH7eZ0SbgZevYAZypmCC6d+qbF+EuaafAbnAV4C/Pef1CqA3pqf0OHCtfbeVwNeYgG4z5r2orw2nMF8Ivsa8Z9divkiVb9+IuY6vYL7QraF6b+t/gX40MFjUnme7C9hlz93W9vYd0Vpnnma3zzDBfpZSanN99dejE1BU49EZ0+NbhLk+Xew/1/wcnJb9LsrVmMG86Zj34FEq/5bOwPTGZ2IC5s+w/95orbOBBzCfmxOY6141PaKqJv0OVDEDk3J1SlXO9HEDJtd9FXAYk7efi/kMlmvo2r9jL/MzEIf5f+mhM2ybEG2Sqn43SwghqrPfPk4GrtX2xTfE75t9cNxJoJ/WusEp6H6vlFJfYtKZ6pttRwjRBkgPtRCiFqXUZKWUrzJT0f0Nc5u4qb2Fou2ZC/wiwXR1SqkYpVSkPbXkMswdhW/PdbuEEC3vvF35SQhxTo3CTKXngrnlfNXppuYSvy9KqSTMHN7TznVbzkMdgS8xczwnAXfpyrnVhRBtmKR8CCGEEEIIcRYk5UMIIYQQQoizIAG1EEIIIYQQZ+GCy6EOCgrSERER57oZQgghhBCijdu6dWuG1rq+tRiACzCgjoiIIDY29lw3QwghhBBCtHFKqWONKScpH0IIIYQQQpwFCaiFEEIIIYQ4CxJQCyGEEEIIcRYuuBzqupSVlZGUlERxcfG5bopoIW5uboSFheHs7HyumyKEEEIIUU2bCKiTkpLw9vYmIiICpdS5bo5oZlprMjMzSUpKIjIy8lw3RwghhBCimjaR8lFcXExgYKAE022UUorAwEC5AyGEEEKI81KbCKgBCabbOHl/hRBCCHG+ajMB9bmUmZnJwIEDGThwICEhIYSGhlY8Ly0tbVQdd9xxBwcPHqy3zOuvv87ChQubo8nN7vHHH+ell16q9fptt91GcHAwAwcOPAetEkIIIYRoeW0ih/pcCwwMZMeOHQAsWLAALy8v/vjHP1Yro7VGa42DQ93fYT744IMGjzN37tyzb2wrmzVrFnPnzmXOnDnnuilCCCGEEC1Ceqhb0JEjR+jXrx/33HMPgwcPJiUlhTlz5hAdHU3fvn158sknK8qOGjWKHTt2YLFY8PPzY968eURFRTFixAhOnjwJVO8FHjVqFPPmzSMmJoaePXuyceNGAAoKCrjmmmuIiopixowZREdHVwT7Vc2fP5+hQ4dWtE9rDcChQ4e45JJLiIqKYvDgwSQkJADw9NNP079/f6KiovjrX//a6GswZswYAgICmnT9hBBCCCEuBG2uh/qJZXvZl5zbrHX26ejD/Cv7Nmnfffv28cEHH/DWW28B8MwzzxAQEIDFYmHcuHFce+219OnTp9o+OTk5jBkzhmeeeYZHHnmE999/n3nz5tWqW2vN5s2bWbp0KU8++SQrV67k1VdfJSQkhC+//JKdO3cyePDgOtv10EMP8cQTT6C1ZubMmaxcuZIpU6YwY8YMFixYwJVXXklxcTE2m41ly5axYsUKNm/ejLu7O1lZWU26FkIIIYQQbZH0ULewrl27MnTo0IrnixYtYvDgwQwePJj9+/ezb9++Wvu4u7szZcoUAIYMGVLRS1zT9OnTa5XZsGEDN954IwBRUVH07Vv3F4HVq1cTExNDVFQU69atY+/evWRnZ5ORkcGVV14JmLmfPTw8WLVqFbNmzcLd3R1AepyFEEIIIapocz3UTe1Jbimenp4VPx8+fJiXX36ZzZs34+fnx80331znVHAuLi4VPzs6OmKxWOqs29XVtVaZ8tSN+hQWFnL//fezbds2QkNDefzxxyvaUddsGlprmWVDCCGEEOI0pIe6FeXm5uLt7Y2Pjw8pKSl8//33zX6MUaNG8fnnnwOwe/fuOnvAi4qKcHBwICgoiLy8PL788ksA/P39CQoKYtmyZYCZ37uwsJCJEyfy3nvvUVRUBCApH0IIIYQQVUhA3YoGDx5Mnz596NevH3fddRcjR45s9mM88MADnDhxggEDBvD888/Tr18/fH19q5UJDAzktttuo1+/flx99dUMGzasYtvChQt5/vnnGTBgAKNGjSI9PZ0rrriCyZMnEx0dzcCBA3nxxRfrPPaCBQsICwsjLCyMiIgIAK677jpGjx7Nvn37CAsL48MPP2z2cxZCCCGEOJdUY1IEzifR0dE6Nja22mv79++nd+/e56hF5xeLxYLFYsHNzY3Dhw8zceJEDh8+jJPThZ/dI++zEEIIIVqTUmqr1jq6oXIXfpQlqsnPz2f8+PFYLBa01vznP/9pE8G0EEIIIX4HtIYLcNyWRFptjJ+fH1u3bj3XzRBCCCGEaLzMo/DNfZBxEAbeBNGzILDruW5Vo7VoDrVSarJS6qBS6ohSqtZEykqpF5VSO+yPQ0qpUy3ZHiGEEEIIcR7RGmI/gLdGQfp+6HQR/PYWvDoEPrkWDv0ANtu5bmWDWqyHWinlCLwOTACSgC1KqaVa64ppJ7TWf6hS/gFgUEu1RwghhBBCnANF2VCcC75h4OBY+Xp+Oix9AA6tgMgxcNWb4BsKuSmw7SMTaH96HfhHwF1rwOP8XQejJVM+YoAjWus4AKXUYmAaUHseN2MGML8F2yOEEEII8ftTnANx68y/faaBm0/rHfvwKlhyB5TkgoOzCY4DIsGvE+z9BkryYPIzEHM3ONgTJ3w6wNh5MPpR2L8Mjm08r4NpaNmAOhRIrPI8CRhWV0GlVGcgEvipBdsjhBBCCNH22WyQsgOOroYjqyFxM2ir2bZyHgy4AWLugnZnMHNWWRFYy6q/phzA1avaS/klFtycHHByULD5bXO8dn1h6CzIPgZZcZAVb4LkoO6mV7pKO4rLrGTkl5CZX0pmQQkZxUPJ8x3EnU29Fq2kJQPquoZonm6OvhuBJVqXv9s1KlJqDjAHoFOnTs3TumY0duxY/vKXvzBp0qSK11566SUOHTrEG2+8cdr9vLy8yM/PJzk5mQcffJAlS5bUWfdzzz1HdPTpZ2x56aWXmDNnDh4eHgBcdtllfPrpp/j5+Z3FWTW/tWvX8txzz/Hdd99Ve/21117jpZde4ujRo6SnpxMUFHSOWiiEEEJc4DIOw1d3QfJ287zDQBj1MHS7FBxdYMt7sP0TiH0PIkbDoFugfV/Ta+xSubozVgskbbEH5asgeQd1hXE6fBhpvW5haelQfjyYxdZj2bg52njO61MuK15OYruxZE96g5DgQDxcnHB3dsTRQYHWFJZZ2Z2Uw84DR9mReIodx0+RnFN7BWmA20Z0xsnx/F0+pSUD6iQgvMrzMCD5NGVvBOaeriKt9dvA22DmoW6uBjaXGTNmsHjx4moB9eLFi/n3v//dqP07duxYZzDdWC+99BI333xzRUC9fPnyJtd1LowcOZIrrriCsWPHnuumCCGEEBcmrWHLu/DD38DZHa58GXpeDl7B1cuFRcPEp2D7f7FteQ+Hr+dUbCp2DSLXI5xiBy/a52zH1ZKPDQey/KNI73kPRcqTMqumzGql1KqxFefRK2kFYYn3c7X2xct9ClNipjE2/mW65G7hfaby1PHrsb29o1oTXJwc8HBxJK/YgtVmwrrwAHeGRARwU4g3QV4uBHm5EujlSqCnC4FeLud1MA0tG1BvAborpSKBE5igeWbNQkqpnoA/8GsLtqVFXXvttTz++OOUlJTg6upKQkICycnJjBo1ivz8fKZNm0Z2djZlZWU89dRTTJs2rdr+CQkJXHHFFezZs4eioiLuuOMO9u3bR+/evSuW+wa499572bJlC0VFRVx77bU88cQTvPLKKyQnJzNu3DiCgoJYs2YNERERxMbGEhQUxAsvvMD7778PwOzZs3n44YdJSEhgypQpjBo1io0bNxIaGsq3336Lu7t7tXYtW7aMp556itLSUgIDA1m4cCHt27cnPz+fBx54gNjYWJRSzJ8/n2uuuYaVK1fy2GOPYbVaCQoKYvXq1Y26foMGyVhUIYQQbYvWmtxiCz5uTqiWnlc5LxW+nWt6krtdCtNeB++Qis2pOcWsPpDGzsRTpOQUk5pTTGpuHwqK/0VvdYwIlUZnlUZnSxoRRakEcJKvbENZZ4tio60vuSmekFL9kI4OCg8XR4aE38AtwUe5KPtrZsZ/BjsXm1zpaW9wx8CZTMguYm9yLun5JRSVWigstVJUaqWw1IqfhzMDw/2ICvcjyMu1Za9RC2uxgFprbVFK3Q98DzgC72ut9yqlngRitdZL7UVnAIt1cy3ZuGIepO5ulqoqhPSHKc+cdnNgYCAxMTGsXLmSadOmsXjxYm644QaUUri5ufH111/j4+NDRkYGw4cPZ+rUqaf95XrzzTfx8PBg165d7Nq1i8GDB1ds++c//0lAQABWq5Xx48eza9cuHnzwQV544QXWrFlTK1Vi69atfPDBB/z2229orRk2bBhjxozB39+fw4cPs2jRIt555x2uv/56vvzyS26++eZq+48aNYpNmzahlOLdd9/l2Wef5fnnn+cf//gHvr6+7N5trnN2djbp6encddddrF+/nsjISLKyspp6tYUQQogLWkZ+CY99tZsf9qUR6ufOiK6BXNQ1kIu6BhHi61bnPoWlFnYn5ZjUh8RT7EnOQWvwdXfGx83Z/OvuhKODotSisdhslFlt9Mv9mVsznsdVl7C7318pGTiLcIsH2Uk5rNqfxuoDaew5kQtAkJcrof7udAn2ZGS3INr7uNHOexB+Hs74uDtXHMvT1ZHLbDDBZsNi1ZRZbVhsGld7z7K7iyMujg5VYpnhwE0mN3rnYuh6CXQahgLCAzwID/Bolet+LrXowi5a6+XA8hqv/b3G8wUt2YbWUp72UR5Ql/cKa6157LHHWL9+PQ4ODpw4cYK0tDRCQkLqrGf9+vU8+OCDAAwYMIABAwZUbPv88895++23sVgspKSksG/fvmrba9qwYQNXX301np4mJ2r69On8/PPPTJ06lcjISAYOHAjAkCFDSEhIqLV/UlISN9xwAykpKZSWlhIZGQnAqlWrWLx4cUU5f39/li1bxsUXX1xRJiDg/B6NK4QQQrSEH/am8pevdpNXbOHOUZEknypi1f40lmxNAkxqg6dL9fDLaikjLqukWvrDgDA/XB0dyCkqI7e4jLiMfHKKytAanB0d8HEo5qGyd5lctpoDqgv3l9zLkdhQiP2tol6lYHAnf/48uScTerenWzuvlu0tD4iEcX9pufrPY21vpcR6epJb0lVXXcUjjzzCtm3bKCoqquhZXrhwIenp6WzduhVnZ2ciIiIoLq474b5cXR/2+Ph4nnvuObZs2YK/vz+33357g/XU1+nv6lp5a8XR0bFaakm5Bx54gEceeYSpU6eydu1aFixYUFFvzTbW9ZoQQghxodJas+14Nq5OjvQL9W2wfG5xGU8u28eSrUn07ejDp3cNpGeINwA2m2Z/ai6/Hs1ke+IpyixmoRJ3Wz6TsxcxvuArrB5ulPp0xrVdd9zadYWALhAWY1YLrPn39fgm+OphKEqE0Y/Sa8w8luNESk4RiVlFJGYX4urkwMU9gi/4VIoLRdsLqM8RLy8vxo4dy6xZs5gxY0bF6zk5ObRr1w5nZ2fWrFnDsWPH6q3n4osvZuHChYwbN449e/awa9cuAHJzc/H09MTX15e0tDRWrFhRMYjP29ubvLy8WikfF198Mbfffjvz5s1Da83XX3/Nxx9/3OhzysnJITQ0FICPPvqo4vWJEydWzMwBJuVjxIgRzJ07l/j4+IqUD+mlFkIIcaFJyCjgq+0n+Hp7EolZprPp6kGh/OWyXrTzrp2uYbHaWLEnlWdWHCAlp4j7x3XjwfHdcXGqHETn4KDo29GXvh3tgbnVAts+hDX/gsIM6Dsd3P1xz46HtG1w8BvQ9tUB/TqbvOhu46HTCPj1NdjwIviGwx0roNNwAFyAzoGedA70RLQ+Caib0YwZM5g+fXq1dIibbrqJK6+8kujoaAYOHEivXr3qrePee+/ljjvuYMCAAQwcOJCYmBgAoqKiGDRoEH379qVLly6MHDmyYp85c+YwZcoUOnTowJo1aypeHzx4MLfffntFHbNnz2bQoEF1pnfUZcGCBVx33XWEhoYyfPhw4uPjAXj88ceZO3cu/fr1w9HRkfnz5zN9+nTefvttpk+fjs1mo127dvz444+16ly9ejVhYWEVz7/44gu2bNnCs88+S2pqKgMGDOCyyy7j3XffbVQbhRBCiNPJKijlQGouxWXVZ+XVGkosNvsAOTNQrqDEwoYjGWw7fgqlYGTXIB4e34P4jALeXh/Hqn1pPDKxB7cMN9O35ZdY+GxLIu9viCftVB5TAlJ5dIITEWonfGufa7ngpAl8AyJNj3NAF3Pwtc9AxkHoPBImfgGhg6s33FIK2QmQsN7MI71zsZnmrtzAm2Hyv1p3gRZRL9VcYwFbS3R0tI6Nja322v79++nd+wwmJxcXJHmfhRBC1FRYaiEzv5SM/BLScks4kJrLnhO57EvOOe2cxqfTs703Vw8OZdrAjnTwrZz5Ki49n/lL9/Lz4Qx6hXgzslsQn8cmkldcxj0hh3jA+l888+LtpVVlEO0ZDLknzGIm+WmVBwroChOehF6X107nqIulFBJ/g/j1JvjuOeWMzks0nVJqq9b69IuB2EkPtRBCCCGazGK1UVhWORVaUamV9j5mDuHTOXIyj5V7UjlyMr/WtjKrJre4zAzGKzL/FpRacHZwwMnRAWdHB5wdFQrILiyjqEbvs1LQJciToZEB9O3oQ58Ovni71Qh3bFZcHSx4uDji5uxYueCIi3udAW6XYC/+OyuGlXtSefK7fXzwSzyzu+XxgOVDvFN+hcBuMP1d6DjQLKntVMe5l+RDdjwUZJieaSeXRl1fwJSNHG0e4rwkAbUQQgghzkhiViGLNh/ni61JpOeV1FmmS7AnMREBDLU/8krKWLknlRVVAukwf3ezal4Vjg4KX3dn/D1ciAxw47rsdxiauZTf2t/Az8Ezyccdi9WGVWsCPFzM4h9eLhWLgXQN9sLTtY7wJivOpE8cWWV6essKa5fxam+mfOt2KXQZB56BFZsUMCVCccn1rrD9c1z3fAbu/jDl3xB9Bzg613/RXL3MNLyiTZKAWgghhBANsto0aw+e5JNNx1h7KB0FjOvZjgFhfhVzE3u4OOLu7EhCZiFbErJYufsE+2PXEO+wm+O6Pd/pEcREBnLL8L5M6hty2jmZASjOhS9nQ/r30HEQFyd/wMV5y+GSx2HgTeDg2HCj89Jg4ytwcLkJqAH8I2DgTPANq15W2yBtLxxaCTsXAcqkV3h3MPnMWfFQVoArmCVTYVzNAAAgAElEQVS8L3oARj8K7n5NuZyijWkzAbVM29a2XWi5/kIIcb7QWhOXUcCW+CwSswvpEuRFzxBvurXzws25Mig9mVvM3uRc9pzI4WBaHnnFFpPGUWYG7WUXlJJdWEawtyv3j+vGjTGdCPVzr33A/HSwbOJer9Vo959QZFdsejYqH7epzzXcm5t9DBbdCOkH4fLnYehsSNwC3z8GSx+A3/4DE56ALpeAQx1LUpcWwq+vm9kwrKVmhozh95ne58Cu9R/bZoXkHaYn++hqyDhkBhNGXmwfWBgJ7fuDd/v66xG/K21iUGJ8fDze3t4EBgZKUN0Gaa3JzMwkLy+vYuEYIYQQddNacygtn58Pp7MlIYvYhGwyC0oBkx5c/mdfKYgI9CTEx40j6fnVUjc6BXjg7+Fs73V2wt3FES8XJ8b0DGZCn/Y4O9YRxJbkwy8vw8ZXwVIEnu0qp3uLHGN6ije+Al3GwnUfmnSJuhz/DT67yQzEu/5DEwRXnhzs+wZ+nA+njplBf+UpGl0vAfcA2PUZrH4S8pKh95Vw6RMNB9FCnEZjByW2iYC6rKyMpKSkBhc6ERcuNzc3wsLCcHZuoFdDCCF+T4pzYeMr2FL3kuzQnp0FAaxK8yI2z48C7c5Q3xxGB+UR5ZFFZ5WKl5PmRN+72W2L4GBqHofS8kjOKaZrsCf9OvqaQXwdffB2O4P/a21W2LEQfnrKzGTRdzqMfAhCBtTuPd72MXz3B5N2MfOzykC3tBASNphe4a0fgE8ozPwcgnvUfUxLCez9Bo78CEd/gsJMQJkc6PxU6DgIJj0NnS9qylUVosLvKqAWQggh2rojJ/P49LdE4jLysVksjM5bzvV5/8VX5xCnO9KBDNxV6Wn2ViZnuDQfik5B1I1wyd/AN7SyiNZmBb4t78CB5dCud2UPc2g0OFbJErWWwanjkLob1v8b0vaYVf0mPQ3hQ+s/kYQN8NnN5njD7jHTwR3bCNYScHKDHpPhihfBo5GLg9lskLLDDDhM3g59r4J+19adCiLEGZKAWgghhLjAlVpsfL83lU82HeO3+CycHeGmgEPcWfg+4dbj7HcdwGf+d1PSLorxPYMZGWLBPe+YGYBXmm96ggO6mNX2nN2gOMfkFf/6BigHuOh+iJljBu1tfhfSdoOrL/S5EjKOQNJmM1jP1RciRplUjqw4OJUI2j5dnV9nk8/c56rGzakMpo5PbzD5ycG9KlM2Ol8EznXkZQtxjkhALYQQQrSWQz+Y/ODp74BPh2qbyqw2krKLiEvPJy69gITMArILS8ktspi5lovLyCu24OLogK+7M0FuVsZbf2Fc/nLcitOwanByUHi6OOLhDI75qWe+MEhN2cdMnvGeJZWvte8PMbOh/3XgYl++uigb4taZVIxjv4CbL/hXWfUvIBJCh9Q973JDrGWmfq92Z76vEK1EAmohhBCimRSXWTmUllcxC0ZqTjH+ni4EernQx3KQy3fcjZO1mPgOl/NlxHxScopJyy0m+VQRx7MKsdgq/9b6ujsT6OWCr7tzxcPbzQnPwhMMPvkVF+Usx1vnEa/CSfbsQ5dgM3CwYtB9x0Ew+LYzWxjkdJJiYf8yk2bRaXjTgnMh2jBZKVEIIYRoooISC5viMll/KJ3NCdkcTsurCIq9XZ0I9XdnX0ouPvkJ3O30d5K0L+tto7k15X/EHh/CMa+BhPi60auDN5P7hRAZ5EmXYC+6BHni71klELbZIO4nk25xaKVJw+h1OcTcRWTEaCJbOsANizYPIcRZkYBaCCHE71pxmZXUnGJScorZlXSKdYfSiU3IptRqw93ZkegIf8b17EK/UDMLRri/Bw4OCvJS0e89jC51o/CarxniFIh1yXgWuS9B3f1Q9UF8NRWdgh2fmgGAWXFm+rfRj0L0rOoDBYUQFwQJqIUQQrQJWmvySyx4uTqddk0Cm02zKT6TJVuT2JecS2puMacKywCY4BDLIIcjxHh34vL+venRewAD+vTGta7pOotzYeG1qIJM1O3fERbalzCAKf+Cz2+BLe/C8Hvq3m/VArMSX1khhA+DsY9Bn6lNy0MWQpwXJKAWQgjR4vJLLFisNvw8zj7vt8RiZV9yLrtP5HAss5DErEISs4tIyiokr8RCkJcLI7oGcVHXQEZ2DSI8wJ203BKWbE3k89gkjmcV4u3mxLDIAKIj/Ong48r45LfpdeQdNApVpOEA5rHU1Qy8C+hiH4xn/3njK3ByP8z4zCxPXa73ldBlHKz5J/SbXn3AXdXV/wbOMLNrdIg66+shhDj3JKAWQgjRYo6czOe/vyawZGsSFpvmgXHdmDOmC65OjrXKllltLN58nJV7U/F2NQP3Ar1cCfJywc3JkX0puWxPPMX+5FxKrTYA3J0dCQ9wJ9zfg2GRAbT3ceNgai4bj2aybGcyANO99hBf6MZ2W1dGdAnikQk9mNwvxCy7XVoAX98NR5bB4NtQU541i5NkxZlHdjxk2v89usZMG1fuqjeh+6XVT0IpuOzf8MYI0xN91Rvm9eO/weKZYCuDm7+EruNa4GoLIc4VmeVDCCFEs7LZNOsOpfPBxgTWH0rHxdGBK6M6Ulxm5X+7U+ga7MnTV/dnWJfAivLL96Tw3PcHScgspEd7LwAy80vJKiytWCrb3dmRAWG+DOzkx6BwP6LC/arPflGF1pqjaTmULX+M3scXAlDSbgCuI+4xPcfO7pCbbHqMU3fDxH/C8Hvrn+XCZjOr8GXFmzmdQ4ecvuyPfzfLcN/5oym/9H6zsMrMzyGoe9MurBCi1cm0eUIIIVrNqcJSNhzJYN3BdNYfTictt4R23q7cPLwzM2I6Eext8oPXHDzJ377ZQ1J2EdcNCWNS3xBe+ekwu5Jy6BXizf9N7sXYnsEVQbLVpskqKKWgxEKYvztOjvbV72w2SN0JQT0q50yuqjgHltxplqYefp9Z4nrzu5C+H9z9YcCNsPdr00N97XvQY1LzXpCSfHgt2sy1XJgBEaPh+v82fvU/IcR5QQJqIYQQ9Sq12Phm+wmWbE2iqMxabZtGY7Fqyqw2LDZNmcVGmU3j7uyIj7sTvu7O+LiZx6GTeexMPIVNg4+bE6O7BzOpXwiT+4bg4lR7+eeiUisvrz7MOz/HYbVpQv3ceWRCD64aFIqjQyOmiTu2Eb5/zCwz7eYLA2+GoXeaoBkgO8Gswpd5BC5/Hobcbj8pbZa93vIO7P8OfEJh5mfQvs/ZXcjT2fMVLLkDBt8Klz3fPPNGCyFalQTUQggh6lRYamHR5kTe/TmOlJxierb3JtS/9nLPTg4KZ0cHnB0VTvZ/i0qt5BabFf5yisrILSqjo587Y3oEc3GPYKLCfCt7kRtwMDWPg2l5TOzT3uQzNyTzKKyabxYi8e4IIx+ExM2wfynYLGb56p5TYM3TYLPCDR9D5MV115V/EpzcwM2nUW1tstwU8A6RBVOEuEBJQC2EEL9ThaUWkrKLSMstpsxqo9SisdhslFltxGcU8vGvCWQXljEsMoD7xnXj4u5Bp51m7owV50D8z+ARCJ1HNE+dhVmw/jnY/DY4usCoP8CIueDiYbbnpcLWDyH2A5PjHNjN5CqX91gLIUQTyUqJQgjRhhSVWtmReIrYhCySc4pqbc8vsZKYVUhSdiEZ+aX11jW+VzvuG9eVIZ2bIZ+3PJf5yGrzSPwNtD19pPtEmPAPaNeraXVbSk16xrpnoSQXBt0C4/4K3u2rl/MOgbHzzMIo8evNYEF3v7M7LyGEOAMSUAshxDlis2m2J55i5Z4UVu0/SanFRnsfVzr4utPex40QX1cy8kvZkpDFnhM5lFk1SkGQlys1+5Pd7NPHXdq7PeEBHozJWEyvw/+hICSGwvAxlHQehw7ogperU8UAwbOSfxK2fWR6hXNPmNc6RMGoh6HrJXBim+lVfvMiGHKbWbzEK7hxdWtt0jh+nG+mq+t6CUx8Ctr3rX8/R2foNv7szksIIZpAUj6EEKKF2GyahMwC8ksslJUP8LNqCkot/HIkg+/3ppKWW4Kzo2JktyACPF1IzSkmNbeY1JxiCkutuDg6MCDMl6GRAQyN8GdIpwB8PepYua+qnYvN3MqhQ6Aw0wzSA7MwSY9JMOJ+8As/8xPSGpK2wOZ3zAwZtjLoMhaiZkDX8bUD5oJMWPcMbHkPnD1g2BzoeRl0HAQOdeRM56fD0Z9g6wdw/FcI7m0C6ZpzPQshRCuRHGohhGhlWmuOZRay8WgmvxzNYNPRTDIL6k6/cHN2YEyPYKb068Alvdvh4+Zcq668Egsujg6NG7BX7sgqM8NF54vgpiVmOevMo/aUjFUQt9YMkBt+n8lFbsygvLIi2L3EpF+k7ARXHxg4E4bObtycyhmHTW/zweWANtPWdb3EBOG+YRC/zrQtZacp72VP4Rh0CzjKjVQhxLkjAbUQQjSDvOIyjmUWUvO/yhKLlROnisyy11lFJGYXEpdeQGpuMQDtfVwZ2TWIYV0CCPJyrZglw8ya4UCP9l54uDRzsJi8HT643CyNfcfyuoPlU4mw+knY/Tl4BsO4x2DQrXUHrlnxEPsebP8EirJNj3HMbDOHs6vXmbevIBPi1pjg/uhqsyIhgHKE8GHQ7RIzU0dIFDg0bqYQIYRoSRJQCyFEE5zMKyY2IZvN8VlsSchif0outgb+mwz2diXc351OAR4MiQhgZNdAIoM8m2/mjMbIiof3JoCTO9z5A/h0qL/8ia3w/eNwfKOZFSOgxowYpflmvmflAL2vgJg50Hlk803/pjWk7TGrFXYabuaTFkKI84wE1EIIUQetNWsPpfPij4fYcyKn1vby4NnN2YFB4f4MjQygTwdvnGr0mDo5KkL93Anz98Dd5QxSMhor/SB8O9ekawREml7ngC4mD9orGKoOS9Q2WPFn04s86wcI7tG4Y2gNB76DTW+aFQOrcnA0KRlDbgff0OY6KyGEuKDItHlCCFHDxqMZPP/DIbYeyybM3527x3TFqcbKfL7uzgzp7E/fjr51rvLX4mw2k6v849/BxQt6XwmnjpkFTPZ8aYLnuji5wa1LGx9Mg+lt7n2leQghhGgyCaiFEBeEEouV45mFHE0vID6jgLj0fI5nFRIe4EFMRADREf610iwsVhuJ2UUcTsvjw40JbDyaSYiPG/+8uh/XDQk/NwFzfXJT4Nv7zEwX3SfBtNfAq13ldkupCa4Ls2rv6xcOPh1br61CCCEqSEAthDivnDhVxOb4TI5lVg72S8oqJCW3uNrAwPK85Z8OnGTJ1iQAgrxcGNLZH6sN4jLyOZ5ZiMWewxHk5cLfrujDTcM6ndmsGa1l/zJY+gBYSuCKF2HIHbXzlZ1cGjerhhBCiFYlAbUQ4pwqLrPyW3wW6w6ms/5wOkdO5gMmlmzv7UZ4gDvDuwYS7u9BZJAnXYI9iQzyxNs+zZzWmqPpBWxJMIMItx3LxsXJgR7tvJnUN4Qu9n36dPBtmVzn5rD1I1j2kJmfefo7ENTtXLdICCHEGZCAWgjR6rTWbDuezSebjrN8dwolFhsuTg4MiwzgxqHhjOwWRJdgT1ydGg6AlVJ0a+dFt3ZezIjp1PyNLS2AtH1mvmTvkMbNcpEVVznvc/J2iLrRLJntVMcKhVvehf89Ct0mwA2fgLNb85+DEEKIFiUBtRCi2cUmZLEj8RQd/cxUcuH+Hvh6OJNfYuHr7SdYuOkYB1Lz8HZ14rroMC7t3Z5hkYHnVw+yzQo7PoWfnoL8VPOak7t9to1I8A2vvdpfaT7ErzcBNYBfZwjpD7+8DEd+gmvegXa9K8tvegtW/h/0mALXf1R3wC2EEOK8JwG1EKLZZBeU8vTy/Xxhz2muytvNCYtVU1RmpW9HH/41vT9Tozri6XqO/hta+wwc3wRdx5nFRNr1qex9ProGfvgbpO2GsKEw+WkzEDAr3gTLmUcgbl3tGTccnSB8OAy7F7qNN8G3UnBgucmP/s8YmPAExNwNm16HHx43M2xc877JjxZCCHFBknmohRBnTWvNl9tO8PTy/eQWlTF7dBdmjYzgZF4JSdmVgwu1hmuGhBEV5tu6i57UdHAlLLoBvNpXrtbn3cHMu1yQDoe/B99OMGEB9J3ePIuZ5J80QfWhlWbFwfT90PdqkzPt6Nzw/kIIIVqdLOwihGhxJRYru5NyeO6Hg2yKy2JwJz+ent6fXiF1LHl9vshLgzdHmCnmZq+GwszKpbCPrjG9zqMfhWH3NH8+s9aw9UP4/q9m9cFpb9S95LcQQojzggTUQohml5RdyNZj2Ww/foodiafYl5xLqdWGt5sT86b0YsbQTjg4nMOe54bYbLDwWrOk9t3rILhnje1WE1C3dI9xWbHJlz6XvfRCCCEaJCslCiHOWlGplU3xmaw/lM66Q+nEpZvlqd2dHekf6svtIyMYGO7HiC6B+HteADnAv71leqIvf6F2MA32QYatMDBSZvIQQog2RQJqIUQ1Wmt+OZLJB7/E8/ORDEotNlydHBjeJZCbhnVmeJcAerb3xsnxDFcZPPA/2PU5TH0F3HzPbF+bDYqywM2v6SkSqbth1XzoeTlEz2paHUIIIUQdJKAWQgBQZrXx3a5k3l4fz/6UXIK8XLl5WGfG9AxmWGTA2a0umJcK39wLxTkmML7py9PPalFWDLs/h/SDlbNqZMeDpRgcnMxUdAFdKh+dhkFIFDjUE+CXFcGXs8E9AKa+KqkWQgghmpUE1EL8DpVabKTlFpOWW0xqbjFHTuazeHMiqbnFdG/nxbPXDmDawI6NWlilUZb/0SypPfYxWPu0Ca6nv1M7CM5Lg8Uz4UQsOLmBf6QJmruNB59QMwNHVpx5HN8EpXlmP48g6HqJmf6u6yWmFzsrrjIgj18P6Qfglq/BM7B5zkkIIYSwk4BaiN+RPSdyuG/hNo5nFdbaNrJbIM9c058xPYLNlHbZCWAtA79OZ7fgyN5vYP8yuPQJGPWwGfC3+gmz6uCkf1aWS90Dn95gerCv+wh6T62/11lr0/Mdv96sSHj0J9OzXRfvjjDhSRNsCyGEEM1MAmohfifScouZ/VEsSsHDl3ang68b7X3c6ODrToivG77uVWa2KMyCNy6CsgJAmVUBA+y9xR0Hmvma/cIbPmhhlumd7jAQRtxvXhv1B8hLgV9fM1PXjZhrFj75crbJrb5jhTlGQ5QCnw4QdYN52GyQuhPi1prUkPKUEP8IcHZvwhUTQgghGkcCaiF+BwpLLcz+KJbc4jKW3HMRfTo2ME/09k9MMD3paSjOrUyz2PcNbP3AlAnuVZli0Xlk3TNXfP9XKMo2qRblgwmVgsnPmN7l7x+DlF2w6zMTRN+4yATJTeHgAB0HmYcQQgjRiiSgFqKNs9k0j3y2kz3JObxzS3TDwbTNClveNUHyiLnVt2ltcpGPrDKLoWx+x/Q0u/vDoFtg6J2mRxjg8CrY+Slc/CcI6V+9HgdHk0P9cQbsWgx9psFVb4GLR7OdtxBCCNFaJKAWoo379w8HWbk3lccv782lfdo3vMORVXDqGEx4ovY2paBdb/O46AEoLYSEn2HHQvj1ddj4KvSYBINvgxV/hqCeJqCui7MbzPwMjv8K3SbUny8thBBCnMckoBaiDfsiNpE31x5lRkwn7hwV2bidNr8N3h2g1xUNl3XxMAF0j0mQc8Isq731Qzi0ElBw5w/1D2h08zH7CiGEEBcwCaiFaGO01uxNzuXLbUl8sukYI7sF8uS0vmbmjoZkHjU91GMfO/Plt31D4ZK/mh7p/UtNb3Z4TNNOQgghhLiASEAtRBuRklPEN9uT+WpbEodP5uPi6MDEviE8fVV/nBu7quGWd8HBGYbc3vSGOLlA/2ubvr8QQghxgZGAWogLnNaa1346wgurDqE1DOnsz1NX9eOKAR3w8zjNaoR1KS2A7QvNAEHvRuRaCyGEEAKQgFqIC5rWmqeX7+edn+OZGtWRRyb0ICLIs2mV7focSnIg5q7mbaQQQgjRxklALcQFymrTPP7NHhZtPs6tIzqz4Mq+ODg0Ik+6LlqbKfBC+kP4sOZtqBBCCNHGSUAtxAWozGrjj1/s5Nsdydw3tit/mtSzcYMOT+f4r3ByL1z5ihlMKIQQQohGk4BaiAtMcZmVBxZt58d9afxpUk/mjuvW+J0TfoH1z4KrT+XS3AGRsOkts+x3/+taruFCCCFEGyUBtRAXkJO5xdy3cBuxx7J5clpfbh0R0bgdLSWw5p/wyytmjmkXTzi4AmxllWVG3C8rFQohhBBNIAG1EBeIrceyufeTreQVW3ht5iCuGNCxcTue3A9f3gVpu2HwrTDpX+DqZZYYz0mCrDjITYbejVjIRQghhBC1SEAtxAXg09+OM3/pHjr4uvPfO2PoFeLT8E5aw29vwY/zwdUbblwEvS6r3O7gCP6dzUMIIYQQTSYBtRDnsRKLlQVL97JocyJjegTz8o0DGz+39M7FsHIedJ8E014Dr3Yt21ghhBDid0oCaiHOU1ab5u6Pt7L2YDpzx3XlkQk9cWzstHhaw8ZXoV1fmPmZzNwhhBBCtKBGrkfcNEqpyUqpg0qpI0qpeacpc71Sap9Saq9S6tOWbI8QF5LnfjjI2oPp/OOqfvxpUq/GB9MAcWvMNHgj5kowLYQQQrSwFuuhVko5Aq8DE4AkYItSaqnWel+VMt2BvwAjtdbZSim5Jy0E8L9dKby59igzYjpxy/Am5Dj/+jp4toP+1zZ/44QQQghRTUv2UMcAR7TWcVrrUmAxMK1GmbuA17XW2QBa65Mt2B4hLggHUnP54xc7GdzJjwVT+5x5BSf3w5FVEDMHnFybv4FCCCGEqKYlA+pQILHK8yT7a1X1AHoopX5RSm1SSk1uwfYIcd47VVjKnP9uxdvNibduHoKrk+OZV/Lr6+DkDtGzmr+BQgghhKilJQcl1pW4qes4fndgLBAG/KyU6qe1PlWtIqXmAHMAOnXq1PwtFeI8YLVpHli0nZScIhbPGUE7H7czryT/JOz6HAbdBJ6Bzd9IIYQQQtTSkj3USUB4ledhQHIdZb7VWpdpreOBg5gAuxqt9dta62itdXRwcHCLNViIc+nZlQf4+XAGT07rx5DO/qcvWHQKTmyte9uWd8FaAsPntkwjhRBCCFFLSwbUW4DuSqlIpZQLcCOwtEaZb4BxAEqpIEwKSFwLtkmI89L7G+L5z/o4bhnemRkxDdyF+eoueOcS+PZ+KMmvfL2syATUPaZAULeWbbAQQgghKrRYQK21tgD3A98D+4HPtdZ7lVJPKqWm2ot9D2QqpfYBa4A/aa0zW6pNQpyPvtl+gie/28fkviEsmNq3/sJx6+DwD9BpBGz/BN4aBYmbzbadi6Ew00yVJ4QQQohWo7SumdZ8fouOjtaxsbHnuhlCNIu1B08y+6NYoiP8+fCOGNyc6xmEaLPB22NMysf9WyB5G3x1N+Qmweg/wr5vwNkd5qyTuaeFEEKIZqCU2qq1jm6oXIsu7CKEOL3tx7O595Nt9Gjvzdu3RtcfTAPs/gJSd8H4v4GzG3S+CO7dAANugPXPQsYhGHG/BNNCCCFEK5Olx4U4B46czGPWh1sI9nblw1lD8XFzrn+HsmL46R/QIQr6VVmsxc0Xrn4LekyGhJ+hz1Ut23AhhBBC1CIBtRCtrLjMyqwPY3F0cODjO2No592I6fE2/wdyEuGqN8ChjhtLfa8yDyGEEEK0OgmohWhlb6w9yvGsQhbdNZzOgZ4N71CYBeufh+4TIfLilm+gEEIIIc6I5FAL0YqOZxby1rqjTI3qyIiujVx4Zf2/oTQPJjzZso0TQgghRJNIQC1EK3ryu704Oyj+ennvxu2QFQeb34FBN0O7Ru4jhBBCiFYlAbUQreSnA2ms2n+SB8d3p31jlhW3lsF3fwBHZxj7WMs3UAghhBBNIjnUQrSC4jIrTyzbR9dgT+4YGdnwDlrD0gcgbi1MfRV8OrR4G4UQQgjRNBJQC9EK3v05jmOZhXx8ZwwuTo24MbT6Sdi5yPRMD7615RsohBBCiCaTlA8hWtiJU0W8tuYIU/qFMLp7cMM7bH4HNrwAQ26HMX9u8fYJIYQQ4uxIQC1EC3vqu30APH5Fn4YL71sKy/8EPS+Dy56XVQ+FEEKIC4AE1EK0oC0JWazYk8rcsd0I9XOvv/CxX+HL2RA2FK55DxwlI0sIIYS4EEhALUQL0Vrz/1YcoJ23K7NHd6m/sM0K39wDvmEw8zNw8WidRgohhBDirElALUQL+enASWKPZfPQpd1xd3Gsv/CRVZCdAJc8Dh4BrdI+IYQQQjQPCaiFaAFWm+bZlQeJDPLk+ujwhnfY/DZ4hUDvK1u+cUIIIYRoVhJQC9ECvtl+goNpeTw6sQfOjg38mmUeNT3U0bPMIi5CCCGEuKBIQC1EMyuxWHnhx0P0D/Xlsn6NWJBly3vg4ARDbmv5xgkhhBCi2UlALUQzW7jpOCdOFfHnyT1xcGhg2rvSAtjxCfSZBt4hrdNAIYQQQjQrCaiFaEZ5xWW8tuYII7sFNm4Rl91fQHEOxMxp+cYJIYT4/+3deXhV1aH38e9KQsIMMsooM4igooiIYx3qgNXr0KrV1mpbq7fWTrdW2/ftvbfDvW3v27nWVm213jq0VasIONR5ZlAQBEHmKSCQMAcyrvePc9QEggbCyU7O+X6eJ0/O2Wfn5Ac7G34s1t5LyggLtXQA3f7iMkp3VPDts0Z89M4xplZF7Dka+h2b+XCSJCkjLNTSAbKypIw7XlzKxNG9OLxv5wZ8wWvw7lsw7ouuiChJUgtmoZYOgO3lVXzx7pm0ys/jprMbMDoNqVvlte4Eoz+Z2XCSJCmjLNRSI9XURL75t9ksWr+NWz59FP26NGCVw23r4O1JMOYzroooSVILZ6GWGulXTy/iiXnv8t2JIzlhaLeGfdHrd6WWGx97dUazSZKkzLNQS43w2Ny1/OrpRVx8dF+uPn5Aw75oy2qY9gcYcjp0HZzRfJIkKfMs1BTGbAcAACAASURBVNJ+envtVr7xtzcZ078zP7pgFKEhFxZW7oK/XgHVlXDmf2U+pCRJyriCpANILdGWnZV88e6ZdGxTwB+uOJqigvyP/qIYYco3oXgWXHovdB+W+aCSJCnjLNTSfvjfV5ezetNOHrxuAj06tm7YF838Y2pVxJNuhBETM5pPkiQ1Had8SPtoV2U1d72ygpOHdefoQw5q2BetnAaP3QRDPw6n3JzZgJIkqUlZqKV9NGl2MRu3l3PNSYMa9gVb18LfPgOd+8GFt0Oep50kSdnEv9mlfRBj5PYXl3Jor45MGNz1o3aGpc/DfZdA+Xa45B5o04AVFCVJUoviHGppHzz3zgYWrd/OLy45Yu939di1Feb8FabfDhsXQpsucNHt0HNk04aVJElNwkIt7YPbX1jKwR1bc+7hvfd8sboKnvr31KItFduh9xj4l1vhsAuhVQMvXJQkSS2OhVpqoLfWbOGVJSXcfPYIWuXXM1tq3kPw6m9h1EUw/svQ9+imDylJkpqchVpqoDteXEq7wnwuHdd/zxdrauDFn0OPkXDhHV54KElSDvFvfakBijfvZPKctVxyTH86tWm15w7vPAYb3oYTvmGZliQpx/g3v9QAd72ynAhcdfyAPV+MEV78GRw0AA67oImTSZKkpFmopY+wbVcl901bydmjDqZfl7Z77rDseVjzOhz/Nch3FpUkSbnGQi19hPunr2JbeRVfPHEvC7m8+DNofzAc+emmDSZJkpoFC7X0IcqrqrnjpaVMGNyVI/rVsyjLqhmw7AWY8BUoKGr6gJIkKXEWaulDPDxrDe9uLee6UwbXv8NLP4c2B8HRn2vSXJIkqfmwUEt7UV0T+cPzSxnVpyMnDOm25w7vzoOFU+HY66CofdMHlCRJzYKFWtqLJ+atY+nGHVx38pD6lxl/6RdQ2B7GfbHpw0mSpGbDWxJI9YgxcutzSxjYrR1njTr4gxfKt8PyF2Hx0/DWg3Dc9dC2S3JBJUlS4izUUj1eXlzC3DVb+PGFo8mvKoMZf4TF/4QVr0JNJbRqByMmwglfTzqqJElKmIVaqsetzy+mR4ciLhjTCx78HCyYDD0Og/HXwZDTof947+ohSZIAC7W0hzdXbeblxSV855wRFL36y1SZPvO/4LgvJx1NkiQ1Q16UKO3m988voWPrAq7o+g488yMY/UkY/69Jx5IkSc2UhVqqZfH67Tw+bx1fGVNA20e/BD1HwSd+DfXd5UOSJAkLtVTH3a8up2N+BVet+i4Q4JL/hcK2SceSJEnNmHOopbRdldU8PGs1dx30Zwo2LoArHoAuA5OOJUmSmjlHqKW0J+e/y9mVT3HUtmfhtO+l7uYhSZL0ESzUUtpDM5bxtVYPE/sc4/2lJUlSgznlQwJWbyqj67JJ9Gq1AU76rRchSpKkBnOEWgIemLmS6/InUdFtJAw7M+k4kiSpBbFQK+fV1ETWT3+QIXnFFJ78TUenJUnSPrFQK+e9sngjl5b/ne3t+sNhFyQdR5IktTAWauW8OS/8g8PzllF08jcgLz/pOJIkqYWxUCunbSmr5OhVf2JLqx60OurypONIkqQWyEKtnPbqc5M5NrxN2djroKAw6TiSJKkFslArp3WZdQtbQkd6fexLSUeRJEktlIVaOWvJnFcYVzmDJYM/C4Xtko4jSZJaqIwW6hDCWSGEhSGExSGEm+p5/XMhhA0hhNnpjy9kMo9U28anf8P22JrB53wt6SiSJKkFy9hKiSGEfOAW4AxgNTAjhDApxjh/t13/GmO8PlM5pPo8O381R25+gRXdT+GwLt2TjiNJklqwTI5QjwMWxxiXxhgrgPuB8zP4/aQG2VJWyYMP/pWDwnaGfcw7e0iSpMbJZKHuA6yq9Xx1etvuLgohzAkhPBBC6JfBPBIA//HoPCZUvEx1QVtaDTsj6TiSJKmFy2Shrm/95rjb80eBATHGw4GngD/X+0YhXBNCmBlCmLlhw4YDHFO55Il563hk1irObz2L/OFnQqs2SUeSJEktXCYL9Wqg9ohzX6C49g4xxpIYY3n66e3A0fW9UYzxthjj2Bjj2O7dne+q/VO6o4Lv/mMuF3dbTbvKUjj0vKQjSZKkLJDJQj0DGBpCGBhCKAQuBSbV3iGE0KvW0/OAtzOYRznue4+8xZadldw04B0oaA1DP550JEmSlAUydpePGGNVCOF64AkgH/hTjHFeCOH7wMwY4yTghhDCeUAVUAp8LlN5lNumzl3L5Dlr+bczhtBl9jdh8GlQ1D7pWJIkKQtkrFADxBinAlN32/a9Wo9vBm7OZAapqrqG/37sbQ7r3ZFrh2yGF4th5H8kHUuSJGUJV0pU1psydy2rSnfytdOHUbDwUchrBcPOTDqWJEnKEhZqZbUYI7c+t4ShPdpz2vDuMH8SDDoF2nROOpokScoSFmpltecWbmDBum1ce/Jg8tbPhc0rYKR395AkSQeOhVpZ7dbnltC7U2vOO7I3zH8EQj4Mn5h0LEmSlEUs1MpaM5eXMn15KV88aRCt8kJquseAE6Bd16SjSZKkLGKhVta69bklHNS2FZcc0w82LICSRU73kCRJB5yFWllpwbqtPL1gPVcdP5C2hQWp0WkCjPhE0tEkSVKWsVArK/3h+aW0Lczns8cdAjs2wvQ/wMCToEPPpKNJkqQsY6FW1llVWsakN4v59Lj+dG5bCI99G3ZthbN/knQ0SZKUhSzUyjq3v7iUvACfP3EgLHwM3noATvoW9Dg06WiSJCkLWaiVVVaWlHH/9FVcdFRfehVVwORvQI/D4ISvJx1NkiRlqYKkA0gH0k8eX0B+XuDrZwyDf34btq+DS/8CBYVJR5MkSVnKEWpljddXlDJl7lq+dPIgepZMh9fvguO+DH2OTjqaJEnKYo5QKyvEGPnB5Lfp2bGIa447GO74FHQZBKd8J+lokiQpy1mo1fJVV/LMazPpuOZ5vndUAW0fvg02LYMrJ0Nh26TTSZKkLGehVstVVQH3X0Zc8iynxWpOKwTeAlq1hZNuhIEnJp1QkiTlAAu1Wq6Xfg6Ln2Jun8u4e3lHrpx4KqNHHwnte0IISaeTJEk5wkKtlund+fDC/6P80Au5fP4FHDusC6MnHJN0KkmSlIO8y4danppqeOTL0LojP8//PGWV1dx0tou2SJKkZFio1fK89jsofoP1J/yAO97YyuXH9mdIj/ZJp5IkSTnKQq2WpWQJPPMjGHY2P1h+KEUFeXzl1KFJp5IkSTnMQq2WI0Z49KuQ34oFY/+TR+es5erjB9K9Q1HSySRJUg7zokS1HK/fBctfhE/8ih+/vIVObVrxxZMGJZ1KkiTlOEeo1TJUlME/vwcDTmT6QZ/guYUbuO6UwXRq0yrpZJIkKcdZqNUyrJ4O5VuJE27gp08spEeHIq48bkDSqSRJkizUaiGWvwwhjxfKBzNzxSa+evpQ2hTmJ51KkiTJQq0WYsXLxF5H8ONnihnQtS2fGtsv6USSJEmAhVotQeUuWD2TJW2P4O21W/n6GcNole+PriRJah5sJWr+Vs+A6nL+uKo3h/bqyCcO7510IkmSpPd52zw1fytepobAlC0D+d3Fh5KXF5JOJEmS9D4LtZq90nnPsLamP5ecOIoThnZLOo4kSVIdTvlQs7a2ZDNtN7zB4rZH8q0zRyQdR5IkaQ8WajVb1TWRW+/9O62pZPyp51FY4I+rJElqfmwoarZ+9+xiOqybDkDPUacmnEaSJKl+zqFWszRzeSm/fHoRUzovJbYfSWjbJelIkiRJ9XKEWs3Otl2VfPX+2fTv1IrhlfMJA05IOpIkSdJeWajV7Nz63BLWbN7JracGQmUZHHJ80pEkSZL2qkGFOoQwOIRQlH58SgjhhhBC58xGUy5as3knf3xpGReM6cOIXXNSGy3UkiSpGWvoCPWDQHUIYQjwR2AgcG/GUiln/c/jCwD41pnDYcXL0G04tO+ecCpJkqS9a2ihrokxVgEXAL+MMX4d6JW5WMpFs1dt5uHZxXzxxEH07tAKVr4GAxydliRJzVtDC3VlCOEy4Epgcnpbq8xEUi6KMfKjKfPp1r6Ia08ZDOvehIrt4AWJkiSpmWtoob4KOA74UYxxWQhhIPCXzMVSrnli3jpmLN/EN84YRvuiAlj+cuqFQyzUkiSpeWvQfahjjPOBGwBCCAcBHWKMP85kMOWOiqoa/vuxBQzr2Z5Pje2b2rjiZeg6BDr0TDacJEnSR2joXT6eCyF0DCF0Ad4E7gwh/Dyz0ZQr7n51OStKyvjuxJEU5OdBdRWseNW7e0iSpBahoVM+OsUYtwIXAnfGGI8GTs9cLOWKTTsq+M0zizlpWHdO7psPL/0SfjMGyrfAEH/EJElS89fQpccLQgi9gE8B381gHuWQGCPfeuBNBla8w2/avAk/ewSqy1Pzps/4ARz6iaQjSpIkfaSGFurvA08AL8cYZ4QQBgGLMhdLueBPLy7mmEW/4EutpsDSdjDmCjjmC9BzZNLRJEmSGqyhFyX+Hfh7redLgYsyFUrZb/aSVQx46hpOK3iDOPbzhNP/HVp3SjqWJEnSPmvoRYl9Qwj/CCGsDyG8G0J4MITQN9PhlJ22rF1Cu7+cy8l5s9l5xk8I5/7cMi1Jklqshl6UeCcwCegN9AEeTW+T9klcNZ1w+6kcXPMuK878M22OvzbpSJIkSY3S0ELdPcZ4Z4yxKv1xF9A9g7mUjVbNoPrOiWyqKuTJCfcw+Ljzkk4kSZLUaA0t1BtDCFeEEPLTH1cAJZkMpuyz6fnfsaO6Fb8a+Hsu/PipSceRJEk6IBpaqK8mdcu8dcBa4GJSy5FLDVO5i9ZLHufpcCz/fslJhBCSTiRJknRANKhQxxhXxhjPizF2jzH2iDH+C6lFXqQGWf/GZNrEMqoPvYBObVslHUeSJOmAaegIdX2+ccBSKOu9++q9lMSOnHym/w6TJEnZpTGF2v+zV4Ns3ryJwZteYmGXj9Gjc/uk40iSJB1QjSnU8YClUFab9uR9tA3l9Dnh8qSjSJIkHXAfulJiCGEb9RfnALTJSCJllYqqGgrffpjNeV04ZMzpSceRJEk64D60UMcYOzRVEGWnx19/hzNr3mDD8MvonJefdBxJkqQDrjFTPqQPFWNk4fN/oyhUOt1DkiRlLQu1MubVpSWM2fYMO1ofTOg7Luk4kiRJGWGhVsbc+9wcTs6fS9ERF0GeP2qSJCk72XKUEYvXb6fN0sdoRRUFh1+UdBxJkqSMyWihDiGcFUJYGEJYHEK46UP2uziEEEMIYzOZR03n9heWcl7+a1R3OgR6H5V0HEmSpIzJWKEOIeQDtwBnAyOBy0III+vZrwNwAzAtU1nUtNZs3smzb8xnQt488kdfBME1gCRJUvbK5Aj1OGBxjHFpjLECuB84v579fgD8FNiVwSxqQrc9v4Sz8qeRTzWMcqlxSZKU3TJZqPsAq2o9X53e9r4QwhigX4xxcgZzqAmt37aL+2as5Np2L0KPw6DnqKQjSZIkZVQmC3V9/8///qqLIYQ84BfANz/yjUK4JoQwM4Qwc8OGDQcwog60O15cxhE1C+i9axGM+6LTPSRJUtbLZKFeDfSr9bwvUFzreQdgFPBcCGE5MB6YVN+FiTHG22KMY2OMY7t3757ByGqM0h0V/OW1FdzU7SUo6gSHfyrpSJIkSRmXyUI9AxgaQhgYQigELgUmvfdijHFLjLFbjHFAjHEA8BpwXoxxZgYzKYPufHkZ7So2ctT252HM5VDYLulIkiRJGZexQh1jrAKuB54A3gb+FmOcF0L4fgjhvEx9XyVjy85K7np5Od/rPYNQUwXHfCHpSJIkSU2iIJNvHmOcCkzdbdv39rLvKZnMosz631eXs7N8F2ftegwGnwZdBycdSZIkqUm4UqIabUd5FX98aRnf6LeIVmXvpi5GlCRJyhEWajXafdNXsqmsks/kPwmd+8PQjycdSZIkqclYqNUoMUbum76SC3tvpsO6aam503n5SceSJElqMhZqNcq84q0s2bCD69o9CwWtYcxnko4kSZLUpCzUapSHZ62hS34ZQ9ZNgVEXQ9suSUeSJElqUhZq7bfqmsikN4u58eA3CJVlMM5b5UmSpNyT0dvmKbu9uqSEjdt28onCR6HvOOg9JulIkiRJTc4Rau23f8xaw3lFs2i3YxUc9+Wk40iSJCXCEWrtl50V1Twxbx2PtnsSCvvDiHOTjiRJkpQIR6i1X556+12GVCxgYNlcGP+vkO+/zSRJUm6yBWm/PDJ7Dde3eZzYqiNhzBVJx5EkSUqMI9TaZ6U7Kli0cD6n1rxGOPpzUNQh6UiSJEmJsVBrn02Zu5bP5D1GCHlw7JeSjiNJkpQoC7X22ZOvv8NlBc/BqAugU9+k40iSJCXKQq19srKkjGHF/6AdOwnj/zXpOJIkSYmzUGufTJq1gqsKnqC8z3joc1TScSRJkhLnXT60T7bPeoi+YSOc+Juko0iSJDULjlCrwTZt3szF2/7Cpjb9YdhZSceRJElqFizUarBtk25iSF4xG078IeT5oyNJkgQWajXUgqn0X3ofd8ZzGTDuE0mnkSRJajYs1Ppo29bBpOtZnDeQl/pfR2GBPzaSJEnvsRnpw9XUwD+uJVaU8aWd/8q4Ib2STiRJktSsWKj14V77HSx9ljcPu5ElsQ8TBndLOpEkSVKzYqHW3q2dA0//JwyfyL1Vp9KpTStG9u6YdCpJkqRmxUKtvZv8dWjTBc77Da8sLWX8oC7k54WkU0mSJDUrFmrVr3w7FL8BR3+OVeVtWL1pp9M9JEmS6mGhVv3WzYFYA32O4pUlGwGYMLhrwqEkSZKaHwu16lc8K/W515G8sqSEbu2LGNKjfbKZJEmSmiELtepXPAs69iG278ErS0qYMLgrITh/WpIkaXcWatWveBb0HsOSDdvZsK3c6R6SJEl7YaHWnnZuhpLF0HsMrywpAfCCREmSpL2wUGtPa99Mfe49hlcWl9Cncxv6dWmTbCZJkqRmykKtPaUvSKw5+EheXVrC8UOcPy1JkrQ3FmrtqfgN6HwI87cUsGVnpdM9JEmSPoSFWnsqnlXn/tPHeUGiJEnSXlmoVdeOEti88v0LEgd3b0fPjq2TTiVJktRsWahV19rU/OnKnkcyfVmp0z0kSZI+goVada1JFeq5NYdQVlHN8UOc7iFJkvRhLNSqq3gWdB3KCysrCAHGD7JQS5IkfRgLtepKr5D4yuISRvXuROe2hUknkiRJatYs1PrAtnWwrZjyHkfwxspNHD/E+dOSJEkfxUKtD6QXdJkXBlNVE50/LUmS1AAWan2geBaEPJ4q7UFhfh5jD+mSdCJJkqRmz0KtDxTPgu4jeG5ZGUcd0pk2hflJJ5IkSWr2LNRKiRHWvEF5j8OZv3YrJzh/WpIkqUEs1ErZshrKNrIofxgAEyzUkiRJDWKhVkr6gsTnd/SlQ1EBh/fplHAgSZKklsFCrZTiNyCvgIeLO3PsoC4U5PujIUmS1BC2JqUUz6Ki6wgWlVYxYbDTPSRJkhrKQi2oroLiWaxqPQKAE4ZaqCVJkhrKQi1Y/iLs2sLz1aPp3qGIoT3aJ51IkiSpxbBQC+Y9RCxszx/fHcqEwV0JISSdSJIkqcWwUOe6qgqYP4lt/U9nzQ443vnTkiRJ+8RCneuWPge7NjOt3ccAON7505IkSfukIOkASti8h6CoEw9uGcqArhX06dwm6USSJEktiiPUuaxyFyyYQtXwc3hp2XZXR5QkSdoPFupctuRpKN/K9LansL28inNH90o6kSRJUovjlI9c9tZD0KYLv1vRl35dKhg/qGvSiSRJklocR6hzVUUZLHyMbYPO5qVlW/jU0f3Iy/N2eZIkSfvKQp2rFj0JlTuYGieQF+DisX2TTiRJktQiOeUjV817iNiuB79a1IOThnWmVyfv7iFJkrQ/HKHOReXb4J0nWNP7DIq3VXLJ2H5JJ5IkSWqxLNS5aOHjULWL+3aMpWu7Qk47tGfSiSRJklqsjBbqEMJZIYSFIYTFIYSb6nn92hDC3BDC7BDCSyGEkZnMo7R5D1Hdvhe3Le/BhUf1obDAf1dJkiTtr4w1qRBCPnALcDYwErisnsJ8b4xxdIzxSOCnwM8zlUdp296FxU8x/6CPUVkTuOQYp3tIkiQ1RiaHJscBi2OMS2OMFcD9wPm1d4gxbq31tB0QM5hHAP/8HhH4n9ITOap/Z4b06JB0IkmSpBYtk4W6D7Cq1vPV6W11hBC+HEJYQmqE+ob63iiEcE0IYWYIYeaGDRsyEjYnrHgV5tzPusO+wAslnRydliRJOgAyWajrWyVkjxHoGOMtMcbBwLeB/1PfG8UYb4sxjo0xju3evfsBjpkjqqtg6regY19+W3U+bQvzmXh476RTSZIktXiZLNSrgdpDoH2B4g/Z/37gXzKYJ7e9fie8O5fy037AP97azLmH96J9kbchlyRJaqxMFuoZwNAQwsAQQiFwKTCp9g4hhKG1nk4EFmUwT+7asRGe+QEMOoUZbU6krKKas0f3SjqVJElSVsjYEGWMsSqEcD3wBJAP/CnGOC+E8H1gZoxxEnB9COF0oBLYBFyZqTw57an/gIodcPZPmTarlPy8wDEDuiSdSpIkKStk9P/8Y4xTgam7bftercdfzeT3F7B6Jsz6X5hwA3QfzrSlrzKqd0ene0iSJB0gruiRzWqqYeq/QYdecPKN7KqsZvaqzYwb6Oi0JEnSgeIwZTZb9CQUz4ILboOiDsxaUkJFdQ3HDuyadDJJkqSs4Qh1Npt9D7TrDqMuBGDashJCgGMcoZYkSTpgLNTZakcJLHwcDr8E8lsBMG1pKYce3JFObVolHE6SJCl7WKiz1dy/Q00lHPlpAMqrqnlj5SaOHeTotCRJ0oFkoc5Ws++BXkdCz8MAmLN6C+VVzp+WJEk60CzU2WjdXFg3B468/P1N05aWAHiHD0mSpAPMQp2NZt8Lea1g9MXvb5q2rJThPTvQpV1hgsEkSZKyj4U621RVwJy/wvCzoW1qNLqyuobXVzh/WpIkKRMs1Nlm0ZNQVgJjrnh/09w1WyirqHb+tCRJUgZYqLPN7HuhXQ8YfNr7m6YtLQWcPy1JkpQJFupssn0DLHoCjrgE8j9YBHP6shIGd29H9w5FCYaTJEnKThbqbDL3b1BTVefuHtU1kZnLN3HsIKd7SJIkZYKFOlvECLPugd5HQY9D3988v3gr28qrONbpHpIkSRlhoc4W6+bA+nnvr4z4nmnLUvefHu8ItSRJUkZYqLPFrHsgvxBGXVRn82tLSxnQtS09O7ZOKJgkSVJ2s1Bng6ry1PzpERPfv/c0QE1NZMbyUm+XJ0mSlEEW6mzwzhOwc1OdixEB5q/dypadlS7oIkmSlEEW6mww+15ofzAM+lidzY+9tZb8vMApw3skFEySJCn7Wahbum3vplZHPOLSOveejjEyZc5aJgzuSpd2hQkGlCRJym4W6pZu7t8gVu9xd4/5a7eyvKSMc0b3SiiYJElSbrBQt2QxpqZ79BkL3YfXeWnKnNR0jzMPOzihcJIkSbnBQt2SFc+C9fNhTN2LEWOMTJnrdA9JkqSmYKFuyWbfC/lFcNiFdTbPK97KipIyJjrdQ5IkKeMs1C1VVTnM/Tscei606VznpSlzne4hSZLUVCzULdXCx2DX5j3uPR1jZGp6usdBTveQJEnKOAt1SzX7HujQGwadUmfze9M9zj3c6R6SJElNwULdEm1bB4ufSt17Oi+/zkvvTff4+Eine0iSJDUFC3VLNPcBiDX1TveYMmctxw/p5nQPSZKkJmKhbokWTIGeo6HbkDqb31qzlZWlZUwc7ei0JElSU7FQtzQ7NsKq12DEOXu8NGXuWgqc7iFJktSkLNQtzTuPp6Z7jJhYZ3NqMZdip3tIkiQ1MQt1S7NgCnTqBwcfXmfznNVbWFW608VcJEmSmpiFuiWpKIMlz8LwcyCEOi/9+ZXltC3MdzEXSZKkJmahbkmWPANVO/eY7rF2y04mvVnMp8b2o1PbVgmFkyRJyk0W6pZk4VRo3QkOmVBn850vLycCnz9hYDK5JEmScpiFuqWorkotNz7sLMj/YBR6665K7p22knNG96Jfl7YJBpQkScpNFuqWYtVrsLM0NX+6lvunr2R7eRXXnDgooWCSJEm5zULdUiyYCvlFMOS09zdVVNXwp5eWc9ygrozu2ynBcJIkSbnLQt0SxAgLJsOgk6Gow/ubJ88pZt3WXVxzsqPTkiRJSbFQtwTr58PmFXXu7hFj5LYXljK8ZwdOGdY9wXCSJEm5zULdEiyYAgQYdvb7m15YtJEF67bxhRMHEna7J7UkSZKajoW6JVgwGfoeAx16vr/p9heW0rNjEecf2SfBYJIkSbJQN3dbVsPaN+tM93hrzRZeWryRq44fSGGBh1CSJClJtrHmLEaYcUfqcbpQl1dVc+MDc+jcthWXjeufYDhJkiQBFCQdQHuxfT1M+gq88ziMOBe6DQXgv6cuYP7ardzx2bF0auMy45IkSUmzUDdHCx+DR66H8m1w1o9h3JcAeGLeOu56ZTlXHz+Q00f2/Ig3kSRJUlOwUDcn5dvhie/AG3+GnqPhykeh50gA1mzeyY0PzGF0n058++zhCQeVJEnSeyzUzUFNDcz5Kzz9fdi2Fo7/Knzsu1BQBEBVdQ033DeL6prIby4bQ1FBfsKBJUmS9B4LddKWv5QalV77JvQeA5+8E/qPr7PLL556h9dXbOJXlx7JgG7tEgoqSZKk+liok7JhYWpEesFk6NgXLrwdRl0MeXVvvPLiog387rklXDK2n/ecliRJaoYs1E2pphreeQKm3wZLn4XC9nDq/4Xjvgyt2uyx+7KNO7j+3lkM69GB/zjvsAQCS5Ik6aNYqA+kTStg8tehqhy6DEx/DILO/WHp8zDzTtiyEjr0ho/9Hzj6c9C+e71vtWVnJZ//8wzyAtz+2bG0KXTeaJW4VQAADkBJREFUtCRJUnNkoT5QVr4G918ONZXQ/dDUSPSO9XX3GXAinPlDGD4R8vf+W19VXcNX7pvFypIy7vnCsfTv2jbD4SVJkrS/LNQHwpv3pxZh6dQPPv3X9xdhoXwblC6DTcuh2zDoMaJBb/dfUxfwwjsb+PGFozl2UNfM5ZYkSVKjWagbo6YGnvkBvPTz1Ojzp+6Gtl0+eL2oA/Q6PPXRQPdPX8mfXl7G1ccP5FKXFpckSWr2LNT7q6YaHrgK5j8CR10JE38G+Y1bCvzVJSX830fe4qRh3fnOOQ0bzZYkSVKyLNT7a8XLqTJ9ynfg5BshhEa93SOz1/CtB+ZwSNd2/PbTYyjIz/voL5IkSVLiLNT7a8EUKGgNE65vVJmuqYn88ulF/PrpRYwb0IXff+ZoOrZu3Ei3JEmSmo6Fen/ECAumwqCPQeH+r1y4s6Kaf3vgTabMWcsnj+7LDy8Y5bLikiRJLYyFen+sm5u6n/TJN+73WxRv3sl1f3mdOWu2cPPZI7jmpEGERk4bkSRJUtOzUO+PBVOAAMPOatDuFVU1vL12K7NXbWb2qs3MWrmJ5SVltC3M57bPjOWMkT0zm1eSJEkZk9FCHUI4C/gVkA/cEWP88W6vfwP4AlAFbACujjGuyGSmA2LhFOg/fq+rHNb2+opNXH/vG6zdsguAHh2KOLJfZz45th9njzqYQd3bZzqtJEmSMihjhTqEkA/cApwBrAZmhBAmxRjn19ptFjA2xlgWQrgO+ClwSaYyHRCbVqSmfJzxgw/dLcbIn19Zzg+nvE3vzm34zWVjOPqQg+jVqbVTOyRJkrJIJkeoxwGLY4xLAUII9wPnA+8X6hjjs7X2fw24IoN5DoyFj6U+j5i41112lFdx80NzmfRmMacf2oOfffJIOrX1zh2SJEnZKJOFug+wqtbz1cCxH7L/54HHMpjnwFgwGbofCl0H1/vy4vXbue4vr7Nkw3a+deZwrjt5MHl5jkhLkiRlq0wW6vpaZKx3xxCuAMYCJ+/l9WuAawD6909wOe6yUljxCpzwtXpf3lJWycW/f4W8ELj76mM5YWi3Jg4oSZKkppbJ5fhWA/1qPe8LFO++UwjhdOC7wHkxxvL63ijGeFuMcWyMcWz37h99IWDGLHoSYvVep3v8ZdoKNpdVcvfV4yzTkiRJOSKThXoGMDSEMDCEUAhcCkyqvUMIYQzwB1Jlen0GsxwYC6ZAh17Qa8weL+2qrObOl5dx8rDujOrTKYFwkiRJSkLGCnWMsQq4HngCeBv4W4xxXgjh+yGE89K7/Q/QHvh7CGF2CGHSXt4ueZW7YPHTMPwcyNvzt+2B11ezcXsF155c/9xqSZIkZaeM3oc6xjgVmLrbtu/Venx6Jr//AbXseajcUe90j+qayO0vLuWIfp0ZP6hLAuEkSZKUlExO+cguCyZDUUcYcOIeLz321lpWlJRxrcuHS5Ik5RwLdUPUVKfuPz30DCgorPNSjJHfP7+Egd3a8fHDDk4ooCRJkpJioW6I1TNhx4bU/OndvLy4hLfWbOWakwaR7/2mJUmSco6FuiG6DISzfpwaod7N759fQvcORVwwpk8CwSRJkpQ0C3VDtO8B46+D1nVvhzd39RZeWryRq48fSOtW+QmFkyRJUpIs1I3w+xeW0KGogMvHJ7h6oyRJkhJlod5P67fu4rG5a/n0sf3p2LpV0nEkSZKUEAv1fnptWSk1Ec49vHfSUSRJkpQgC/V+mr6shHaF+Rzaq0PSUSRJkpQgC/V+mrFsE0cdchAF+f4WSpIk5TLb4H7YXFbBwne3cexAlxmXJEnKdRbq/TBj+SYAjhlgoZYkScp1Fur9MGN5KYX5eRzRr3PSUSRJkpQwC/V+mL6slCP6dXIxF0mSJFmo91VZRRVvrdnidA9JkiQBFup9NmvlZqpqIsd4QaIkSZKwUO+z6ctKCQGOPuSgpKNIkiSpGbBQ76Ppy0oZ2aujy41LkiQJsFDvk4qqGmat2uT8aUmSJL3PQr0P3irewq7KGsY5f1qSJElpFup9MH1ZKeCCLpIkSfqAhXofzFhWyqBu7ejeoSjpKJIkSWomLNQNVFMTmbG81NFpSZIk1WGhbqCF725j664q509LkiSpDgt1A81Ynpo/baGWJElSbRbqBpq+rJSDO7am70Ftko4iSZKkZsRC3QAxRqYvK2XcwC6EEJKOI0mSpGbEQt0AK0vLWL+tnGOc7iFJkqTdWKgbYFNZJaP6dORYC7UkSZJ2U5B0gJbgyH6dmfyVE5OOIUmSpGbIEWpJkiSpESzUkiRJUiNYqCVJkqRGsFBLkiRJjWChliRJkhrBQi1JkiQ1goVakiRJagQLtSRJktQIFmpJkiSpESzUkiRJUiNYqCVJkqRGsFBLkiRJjWChliRJkhrBQi1JkiQ1goVakiRJagQLtSRJktQIFmpJkiSpESzUkiRJUiOEGGPSGfZJCGEDsCLD36YbsDHD30P7x2PTPHlcmiePS/PlsWmePC7NU5LH5ZAYY/eP2qnFFeqmEEKYGWMcm3QO7clj0zx5XJonj0vz5bFpnjwuzVNLOC5O+ZAkSZIawUItSZIkNYKFun63JR1Ae+WxaZ48Ls2Tx6X58tg0Tx6X5qnZHxfnUEuSJEmN4Ai1JEmS1AgW6t2EEM4KISwMISwOIdyUdJ5cFULoF0J4NoTwdghhXgjhq+ntXUII/wwhLEp/PijprLkohJAfQpgVQpicfj4whDAtfVz+GkIoTDpjLgohdA4hPBBCWJA+d47znEleCOHr6T/H3goh3BdCaO05k4wQwp9CCOtDCG/V2lbvORJSfp3uA3NCCEcllzy77eW4/E/6z7I5IYR/hBA613rt5vRxWRhCODOZ1HVZqGsJIeQDtwBnAyOBy0III5NNlbOqgG/GGA8FxgNfTh+Lm4CnY4xDgafTz9X0vgq8Xev5T4BfpI/LJuDziaTSr4DHY4wjgCNIHSPPmQSFEPoANwBjY4yjgHzgUjxnknIXcNZu2/Z2jpwNDE1/XAPc2kQZc9Fd7Hlc/gmMijEeDrwD3AyQ7gKXAoelv+Z36f6WKAt1XeOAxTHGpTHGCuB+4PyEM+WkGOPaGOMb6cfbSBWDPqSOx5/Tu/0Z+JdkEuauEEJfYCJwR/p5AE4FHkjv4nFJQAihI3AS8EeAGGNFjHEznjPNQQHQJoRQALQF1uI5k4gY4wtA6W6b93aOnA/cHVNeAzqHEHo1TdLcUt9xiTE+GWOsSj99Deibfnw+cH+MsTzGuAxYTKq/JcpCXVcfYFWt56vT25SgEMIAYAwwDegZY1wLqdIN9EguWc76JXAjUJN+3hXYXOsPPs+bZAwCNgB3pqfj3BFCaIfnTKJijGuA/wesJFWktwCv4znTnOztHLETNB9XA4+lHzfL42KhrivUs83boCQohNAeeBD4Woxxa9J5cl0I4VxgfYzx9dqb69nV86bpFQBHAbfGGMcAO3B6R+LS83HPBwYCvYF2pKYS7M5zpvnxz7ZmIITwXVLTQO95b1M9uyV+XCzUda0G+tV63hcoTihLzgshtCJVpu+JMT6U3vzue//llv68Pql8Oep44LwQwnJSU6JOJTVi3Tn939ngeZOU1cDqGOO09PMHSBVsz5lknQ4sizFuiDFWAg8BE/CcaU72do7YCRIWQrgSOBe4PH5wn+dmeVws1HXNAIamr74uJDXpfVLCmXJSel7uH4G3Y4w/r/XSJODK9OMrgUeaOlsuizHeHGPsG2McQOr8eCbGeDnwLHBxejePSwJijOuAVSGE4elNpwHz8ZxJ2kpgfAihbfrPtfeOi+dM87G3c2QS8Nn03T7GA1vemxqizAshnAV8GzgvxlhW66VJwKUhhKIQwkBSF41OTyJjbS7sspsQwjmkRtzygT/FGH+UcKScFEI4AXgRmMsHc3W/Q2oe9d+A/qT+ovpkjHH3C0zUBEIIpwD/FmM8N4QwiNSIdRdgFnBFjLE8yXy5KIRwJKmLRQuBpcBVpAZOPGcSFEL4T+ASUv9tPQv4Aqk5n54zTSyEcB9wCtANeBf4d+Bh6jlH0v8A+i2pO0mUAVfFGGcmkTvb7eW43AwUASXp3V6LMV6b3v+7pOZVV5GaEvrY7u/Z1CzUkiRJUiM45UOSJElqBAu1JEmS1AgWakmSJKkRLNSSJElSI1ioJUmSpEawUEtSMxdCqA4hzK71ccBWQAwhDAghvHWg3k+SclHBR+8iSUrYzhjjkUmHkCTVzxFqSWqhQgjLQwg/CSFMT38MSW8/JITwdAhhTvpz//T2niGEf4QQ3kx/TEi/VX4I4fYQwrwQwpMhhDbp/W8IIcxPv8/9Cf0yJanZs1BLUvPXZrcpH5fUem1rjHEcqRXdfpne9lvg7hjj4cA9wK/T238NPB9jPAI4CpiX3j4UuCXGeBiwGbgovf0mYEz6fa7N1C9Oklo6V0qUpGYuhLA9xti+nu3LgVNjjEtDCK2AdTHGriGEjUCvGGNlevvaGGO3EMIGoG/tJa5DCAOAf8YYh6affxtoFWP8YQjhcWA7qaWZH44xbs/wL1WSWiRHqCWpZYt7eby3fepTXutxNR9cXzMRuAU4Gng9hOB1N5JUDwu1JLVsl9T6/Gr68SvApenHlwMvpR8/DVwHEELIDyF03NubhhDygH4xxmeBG4HOwB6j5JIk7/IhSS1BmxDC7FrPH48xvnfrvKIQwjRSAySXpbfdAPwphPAtYANwVXr7V4HbQgifJzUSfR2wdi/fMx/4SwihExCAX8QYNx+wX5EkZRHnUEtSC5WeQz02xrgx6SySlMuc8iFJkiQ1giPUkiRJUiM4Qi1JkiQ1goVakiRJagQLtSRJktQIFmpJkiSpESzUkiRJUiNYqCVJkqRG+P9dZkuTpUM4+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like you can still improve the model by training much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "6500/6500 [==============================] - 0s 42us/step - loss: 16.0427 - accuracy: 0.1400 - val_loss: 15.6799 - val_accuracy: 0.1740\n",
      "Epoch 2/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 15.3781 - accuracy: 0.1803 - val_loss: 15.0273 - val_accuracy: 0.2060\n",
      "Epoch 3/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 14.7348 - accuracy: 0.2015 - val_loss: 14.3940 - val_accuracy: 0.2150\n",
      "Epoch 4/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 14.1097 - accuracy: 0.2117 - val_loss: 13.7783 - val_accuracy: 0.2290\n",
      "Epoch 5/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 13.5010 - accuracy: 0.2168 - val_loss: 13.1788 - val_accuracy: 0.2380\n",
      "Epoch 6/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 12.9072 - accuracy: 0.2271 - val_loss: 12.5944 - val_accuracy: 0.2450\n",
      "Epoch 7/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 12.3275 - accuracy: 0.2395 - val_loss: 12.0241 - val_accuracy: 0.2580\n",
      "Epoch 8/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 11.7622 - accuracy: 0.2574 - val_loss: 11.4682 - val_accuracy: 0.2750\n",
      "Epoch 9/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 11.2114 - accuracy: 0.2780 - val_loss: 10.9280 - val_accuracy: 0.2990\n",
      "Epoch 10/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 10.6756 - accuracy: 0.3008 - val_loss: 10.4016 - val_accuracy: 0.3150\n",
      "Epoch 11/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 10.1556 - accuracy: 0.3271 - val_loss: 9.8911 - val_accuracy: 0.3240\n",
      "Epoch 12/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 9.6512 - accuracy: 0.3498 - val_loss: 9.3969 - val_accuracy: 0.3430\n",
      "Epoch 13/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 9.1626 - accuracy: 0.3772 - val_loss: 8.9187 - val_accuracy: 0.3730\n",
      "Epoch 14/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 8.6899 - accuracy: 0.4011 - val_loss: 8.4577 - val_accuracy: 0.4300\n",
      "Epoch 15/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 8.2334 - accuracy: 0.4335 - val_loss: 8.0114 - val_accuracy: 0.4530\n",
      "Epoch 16/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 7.7931 - accuracy: 0.4545 - val_loss: 7.5810 - val_accuracy: 0.4750\n",
      "Epoch 17/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 7.3690 - accuracy: 0.4743 - val_loss: 7.1665 - val_accuracy: 0.4920\n",
      "Epoch 18/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 6.9614 - accuracy: 0.4991 - val_loss: 6.7689 - val_accuracy: 0.4960\n",
      "Epoch 19/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 6.5706 - accuracy: 0.5106 - val_loss: 6.3887 - val_accuracy: 0.5170\n",
      "Epoch 20/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 6.1967 - accuracy: 0.5315 - val_loss: 6.0250 - val_accuracy: 0.5310\n",
      "Epoch 21/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 5.8401 - accuracy: 0.5466 - val_loss: 5.6784 - val_accuracy: 0.5480\n",
      "Epoch 22/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 5.5006 - accuracy: 0.5605 - val_loss: 5.3487 - val_accuracy: 0.5640\n",
      "Epoch 23/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 5.1780 - accuracy: 0.5766 - val_loss: 5.0369 - val_accuracy: 0.5760\n",
      "Epoch 24/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 4.8725 - accuracy: 0.5852 - val_loss: 4.7408 - val_accuracy: 0.5850\n",
      "Epoch 25/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 4.5835 - accuracy: 0.5974 - val_loss: 4.4614 - val_accuracy: 0.5920\n",
      "Epoch 26/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 4.3115 - accuracy: 0.6045 - val_loss: 4.2003 - val_accuracy: 0.6030\n",
      "Epoch 27/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 4.0571 - accuracy: 0.6132 - val_loss: 3.9544 - val_accuracy: 0.6100\n",
      "Epoch 28/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 3.8193 - accuracy: 0.6212 - val_loss: 3.7278 - val_accuracy: 0.6260\n",
      "Epoch 29/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 3.5983 - accuracy: 0.6318 - val_loss: 3.5148 - val_accuracy: 0.6210\n",
      "Epoch 30/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 3.3945 - accuracy: 0.6366 - val_loss: 3.3200 - val_accuracy: 0.6230\n",
      "Epoch 31/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 3.2070 - accuracy: 0.6389 - val_loss: 3.1439 - val_accuracy: 0.6400\n",
      "Epoch 32/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 3.0356 - accuracy: 0.6438 - val_loss: 2.9792 - val_accuracy: 0.6410\n",
      "Epoch 33/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.8799 - accuracy: 0.6497 - val_loss: 2.8305 - val_accuracy: 0.6250\n",
      "Epoch 34/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.7395 - accuracy: 0.6517 - val_loss: 2.6978 - val_accuracy: 0.6430\n",
      "Epoch 35/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.6145 - accuracy: 0.6595 - val_loss: 2.5810 - val_accuracy: 0.6440\n",
      "Epoch 36/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.5046 - accuracy: 0.6626 - val_loss: 2.4787 - val_accuracy: 0.6450\n",
      "Epoch 37/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.4094 - accuracy: 0.6611 - val_loss: 2.3914 - val_accuracy: 0.6510\n",
      "Epoch 38/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.3285 - accuracy: 0.6620 - val_loss: 2.3169 - val_accuracy: 0.6410\n",
      "Epoch 39/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.2615 - accuracy: 0.6615 - val_loss: 2.2570 - val_accuracy: 0.6460\n",
      "Epoch 40/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.2077 - accuracy: 0.6634 - val_loss: 2.2096 - val_accuracy: 0.6500\n",
      "Epoch 41/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.1650 - accuracy: 0.6634 - val_loss: 2.1711 - val_accuracy: 0.6550\n",
      "Epoch 42/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.1317 - accuracy: 0.6631 - val_loss: 2.1430 - val_accuracy: 0.6500\n",
      "Epoch 43/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.1059 - accuracy: 0.6605 - val_loss: 2.1186 - val_accuracy: 0.6670\n",
      "Epoch 44/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.0832 - accuracy: 0.6666 - val_loss: 2.0969 - val_accuracy: 0.6610\n",
      "Epoch 45/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.0630 - accuracy: 0.6629 - val_loss: 2.0775 - val_accuracy: 0.6670\n",
      "Epoch 46/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 2.0443 - accuracy: 0.6662 - val_loss: 2.0585 - val_accuracy: 0.6630\n",
      "Epoch 47/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.0267 - accuracy: 0.6683 - val_loss: 2.0426 - val_accuracy: 0.6670\n",
      "Epoch 48/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 2.0098 - accuracy: 0.6669 - val_loss: 2.0254 - val_accuracy: 0.6690\n",
      "Epoch 49/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.9942 - accuracy: 0.6700 - val_loss: 2.0092 - val_accuracy: 0.6660\n",
      "Epoch 50/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.9783 - accuracy: 0.6688 - val_loss: 1.9936 - val_accuracy: 0.6710\n",
      "Epoch 51/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.9637 - accuracy: 0.6700 - val_loss: 1.9809 - val_accuracy: 0.6770\n",
      "Epoch 52/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.9492 - accuracy: 0.6717 - val_loss: 1.9654 - val_accuracy: 0.6770\n",
      "Epoch 53/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.9355 - accuracy: 0.6709 - val_loss: 1.9531 - val_accuracy: 0.6720\n",
      "Epoch 54/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.9220 - accuracy: 0.6725 - val_loss: 1.9393 - val_accuracy: 0.6760\n",
      "Epoch 55/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.9089 - accuracy: 0.6742 - val_loss: 1.9247 - val_accuracy: 0.6710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.8961 - accuracy: 0.6758 - val_loss: 1.9133 - val_accuracy: 0.6750\n",
      "Epoch 57/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.8836 - accuracy: 0.6755 - val_loss: 1.8999 - val_accuracy: 0.6710\n",
      "Epoch 58/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.8715 - accuracy: 0.6762 - val_loss: 1.8891 - val_accuracy: 0.6720\n",
      "Epoch 59/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8600 - accuracy: 0.6772 - val_loss: 1.8774 - val_accuracy: 0.6840\n",
      "Epoch 60/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8484 - accuracy: 0.6794 - val_loss: 1.8650 - val_accuracy: 0.6850\n",
      "Epoch 61/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8371 - accuracy: 0.6811 - val_loss: 1.8551 - val_accuracy: 0.6850\n",
      "Epoch 62/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.8266 - accuracy: 0.6769 - val_loss: 1.8451 - val_accuracy: 0.6900\n",
      "Epoch 63/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.8159 - accuracy: 0.6794 - val_loss: 1.8324 - val_accuracy: 0.6690\n",
      "Epoch 64/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.8049 - accuracy: 0.6795 - val_loss: 1.8226 - val_accuracy: 0.6910\n",
      "Epoch 65/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7951 - accuracy: 0.6802 - val_loss: 1.8108 - val_accuracy: 0.6890\n",
      "Epoch 66/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7849 - accuracy: 0.6834 - val_loss: 1.8023 - val_accuracy: 0.6790\n",
      "Epoch 67/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7751 - accuracy: 0.6809 - val_loss: 1.7946 - val_accuracy: 0.6900\n",
      "Epoch 68/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7658 - accuracy: 0.6826 - val_loss: 1.7828 - val_accuracy: 0.6900\n",
      "Epoch 69/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7563 - accuracy: 0.6831 - val_loss: 1.7728 - val_accuracy: 0.6870\n",
      "Epoch 70/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.7468 - accuracy: 0.6835 - val_loss: 1.7622 - val_accuracy: 0.6850\n",
      "Epoch 71/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7381 - accuracy: 0.6846 - val_loss: 1.7551 - val_accuracy: 0.6910\n",
      "Epoch 72/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7292 - accuracy: 0.6842 - val_loss: 1.7467 - val_accuracy: 0.6910\n",
      "Epoch 73/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.7205 - accuracy: 0.6832 - val_loss: 1.7375 - val_accuracy: 0.6930\n",
      "Epoch 74/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.7116 - accuracy: 0.6851 - val_loss: 1.7286 - val_accuracy: 0.6890\n",
      "Epoch 75/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.7033 - accuracy: 0.6862 - val_loss: 1.7198 - val_accuracy: 0.6900\n",
      "Epoch 76/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6956 - accuracy: 0.6883 - val_loss: 1.7124 - val_accuracy: 0.6900\n",
      "Epoch 77/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6881 - accuracy: 0.6855 - val_loss: 1.7014 - val_accuracy: 0.6940\n",
      "Epoch 78/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6794 - accuracy: 0.6860 - val_loss: 1.6953 - val_accuracy: 0.6950\n",
      "Epoch 79/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6720 - accuracy: 0.6880 - val_loss: 1.6867 - val_accuracy: 0.6930\n",
      "Epoch 80/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6643 - accuracy: 0.6875 - val_loss: 1.6800 - val_accuracy: 0.6950\n",
      "Epoch 81/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6566 - accuracy: 0.6880 - val_loss: 1.6723 - val_accuracy: 0.6910\n",
      "Epoch 82/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 1.6499 - accuracy: 0.68 - 0s 27us/step - loss: 1.6490 - accuracy: 0.6888 - val_loss: 1.6629 - val_accuracy: 0.6900\n",
      "Epoch 83/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6421 - accuracy: 0.6892 - val_loss: 1.6572 - val_accuracy: 0.6910\n",
      "Epoch 84/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6350 - accuracy: 0.6908 - val_loss: 1.6498 - val_accuracy: 0.7000\n",
      "Epoch 85/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6278 - accuracy: 0.6906 - val_loss: 1.6467 - val_accuracy: 0.7000\n",
      "Epoch 86/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6209 - accuracy: 0.6922 - val_loss: 1.6361 - val_accuracy: 0.6970\n",
      "Epoch 87/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.6135 - accuracy: 0.6918 - val_loss: 1.6273 - val_accuracy: 0.6980\n",
      "Epoch 88/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.6064 - accuracy: 0.6923 - val_loss: 1.6236 - val_accuracy: 0.7020\n",
      "Epoch 89/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5998 - accuracy: 0.6923 - val_loss: 1.6132 - val_accuracy: 0.7020\n",
      "Epoch 90/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5928 - accuracy: 0.6934 - val_loss: 1.6074 - val_accuracy: 0.6980\n",
      "Epoch 91/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5870 - accuracy: 0.6931 - val_loss: 1.5981 - val_accuracy: 0.6990\n",
      "Epoch 92/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5792 - accuracy: 0.6948 - val_loss: 1.5939 - val_accuracy: 0.6970\n",
      "Epoch 93/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.5734 - accuracy: 0.6940 - val_loss: 1.5869 - val_accuracy: 0.7000\n",
      "Epoch 94/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5664 - accuracy: 0.6957 - val_loss: 1.5804 - val_accuracy: 0.7000\n",
      "Epoch 95/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.5601 - accuracy: 0.6960 - val_loss: 1.5789 - val_accuracy: 0.7020\n",
      "Epoch 96/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.5544 - accuracy: 0.6966 - val_loss: 1.5721 - val_accuracy: 0.6940\n",
      "Epoch 97/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5480 - accuracy: 0.6954 - val_loss: 1.5625 - val_accuracy: 0.7040\n",
      "Epoch 98/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5406 - accuracy: 0.6955 - val_loss: 1.5582 - val_accuracy: 0.6990\n",
      "Epoch 99/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.5354 - accuracy: 0.6951 - val_loss: 1.5462 - val_accuracy: 0.6990\n",
      "Epoch 100/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5284 - accuracy: 0.6975 - val_loss: 1.5439 - val_accuracy: 0.7010\n",
      "Epoch 101/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5233 - accuracy: 0.6983 - val_loss: 1.5371 - val_accuracy: 0.6980\n",
      "Epoch 102/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5167 - accuracy: 0.6978 - val_loss: 1.5311 - val_accuracy: 0.7000\n",
      "Epoch 103/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5104 - accuracy: 0.6977 - val_loss: 1.5252 - val_accuracy: 0.7050\n",
      "Epoch 104/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.5052 - accuracy: 0.6995 - val_loss: 1.5183 - val_accuracy: 0.7060\n",
      "Epoch 105/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4993 - accuracy: 0.6991 - val_loss: 1.5139 - val_accuracy: 0.7060\n",
      "Epoch 106/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4938 - accuracy: 0.6995 - val_loss: 1.5076 - val_accuracy: 0.7030\n",
      "Epoch 107/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4874 - accuracy: 0.7017 - val_loss: 1.4995 - val_accuracy: 0.7070\n",
      "Epoch 108/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4820 - accuracy: 0.7015 - val_loss: 1.4942 - val_accuracy: 0.7030\n",
      "Epoch 109/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4769 - accuracy: 0.7014 - val_loss: 1.4882 - val_accuracy: 0.7070\n",
      "Epoch 110/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4713 - accuracy: 0.7035 - val_loss: 1.4866 - val_accuracy: 0.7030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4657 - accuracy: 0.7018 - val_loss: 1.4780 - val_accuracy: 0.7060\n",
      "Epoch 112/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4599 - accuracy: 0.7037 - val_loss: 1.4769 - val_accuracy: 0.7050\n",
      "Epoch 113/1000\n",
      "6500/6500 [==============================] - 0s 35us/step - loss: 1.4552 - accuracy: 0.7023 - val_loss: 1.4668 - val_accuracy: 0.7060\n",
      "Epoch 114/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4491 - accuracy: 0.7042 - val_loss: 1.4633 - val_accuracy: 0.7070\n",
      "Epoch 115/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4436 - accuracy: 0.7042 - val_loss: 1.4561 - val_accuracy: 0.7100\n",
      "Epoch 116/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4387 - accuracy: 0.7048 - val_loss: 1.4571 - val_accuracy: 0.7140\n",
      "Epoch 117/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4334 - accuracy: 0.7018 - val_loss: 1.4464 - val_accuracy: 0.7070\n",
      "Epoch 118/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4280 - accuracy: 0.7031 - val_loss: 1.4422 - val_accuracy: 0.7090\n",
      "Epoch 119/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4233 - accuracy: 0.7040 - val_loss: 1.4363 - val_accuracy: 0.7090\n",
      "Epoch 120/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4173 - accuracy: 0.7062 - val_loss: 1.4304 - val_accuracy: 0.7100\n",
      "Epoch 121/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4128 - accuracy: 0.7040 - val_loss: 1.4240 - val_accuracy: 0.7110\n",
      "Epoch 122/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.4081 - accuracy: 0.7046 - val_loss: 1.4195 - val_accuracy: 0.7110\n",
      "Epoch 123/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.4026 - accuracy: 0.7075 - val_loss: 1.4138 - val_accuracy: 0.7150\n",
      "Epoch 124/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3979 - accuracy: 0.7055 - val_loss: 1.4179 - val_accuracy: 0.7150\n",
      "Epoch 125/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3939 - accuracy: 0.7066 - val_loss: 1.4063 - val_accuracy: 0.7110\n",
      "Epoch 126/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3885 - accuracy: 0.7077 - val_loss: 1.3986 - val_accuracy: 0.7160\n",
      "Epoch 127/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3835 - accuracy: 0.7071 - val_loss: 1.3954 - val_accuracy: 0.7140\n",
      "Epoch 128/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3790 - accuracy: 0.7088 - val_loss: 1.3947 - val_accuracy: 0.7080\n",
      "Epoch 129/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3746 - accuracy: 0.7086 - val_loss: 1.3861 - val_accuracy: 0.7170\n",
      "Epoch 130/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3708 - accuracy: 0.7114 - val_loss: 1.3803 - val_accuracy: 0.7190\n",
      "Epoch 131/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3652 - accuracy: 0.7109 - val_loss: 1.3757 - val_accuracy: 0.7190\n",
      "Epoch 132/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3608 - accuracy: 0.7071 - val_loss: 1.3799 - val_accuracy: 0.7220\n",
      "Epoch 133/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3564 - accuracy: 0.7100 - val_loss: 1.3663 - val_accuracy: 0.7190\n",
      "Epoch 134/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3518 - accuracy: 0.7106 - val_loss: 1.3607 - val_accuracy: 0.7170\n",
      "Epoch 135/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3473 - accuracy: 0.7105 - val_loss: 1.3585 - val_accuracy: 0.7170\n",
      "Epoch 136/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3427 - accuracy: 0.7105 - val_loss: 1.3546 - val_accuracy: 0.7220\n",
      "Epoch 137/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3384 - accuracy: 0.7117 - val_loss: 1.3488 - val_accuracy: 0.7170\n",
      "Epoch 138/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3340 - accuracy: 0.7125 - val_loss: 1.3470 - val_accuracy: 0.7210\n",
      "Epoch 139/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3305 - accuracy: 0.7114 - val_loss: 1.3535 - val_accuracy: 0.7130\n",
      "Epoch 140/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3261 - accuracy: 0.7155 - val_loss: 1.3362 - val_accuracy: 0.7240\n",
      "Epoch 141/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3213 - accuracy: 0.7129 - val_loss: 1.3312 - val_accuracy: 0.7190\n",
      "Epoch 142/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3170 - accuracy: 0.7125 - val_loss: 1.3283 - val_accuracy: 0.7260\n",
      "Epoch 143/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3138 - accuracy: 0.7137 - val_loss: 1.3256 - val_accuracy: 0.7260\n",
      "Epoch 144/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3096 - accuracy: 0.7142 - val_loss: 1.3250 - val_accuracy: 0.7280\n",
      "Epoch 145/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.3058 - accuracy: 0.7152 - val_loss: 1.3156 - val_accuracy: 0.7260\n",
      "Epoch 146/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.3018 - accuracy: 0.7122 - val_loss: 1.3150 - val_accuracy: 0.7310\n",
      "Epoch 147/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2977 - accuracy: 0.7162 - val_loss: 1.3074 - val_accuracy: 0.7300\n",
      "Epoch 148/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2932 - accuracy: 0.7152 - val_loss: 1.3042 - val_accuracy: 0.7270\n",
      "Epoch 149/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2901 - accuracy: 0.7152 - val_loss: 1.2983 - val_accuracy: 0.7250\n",
      "Epoch 150/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2857 - accuracy: 0.7162 - val_loss: 1.2969 - val_accuracy: 0.7240\n",
      "Epoch 151/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2824 - accuracy: 0.7146 - val_loss: 1.2920 - val_accuracy: 0.7310\n",
      "Epoch 152/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2785 - accuracy: 0.7180 - val_loss: 1.2857 - val_accuracy: 0.7280\n",
      "Epoch 153/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2744 - accuracy: 0.7168 - val_loss: 1.2859 - val_accuracy: 0.7300\n",
      "Epoch 154/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2713 - accuracy: 0.7169 - val_loss: 1.2811 - val_accuracy: 0.7310\n",
      "Epoch 155/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2680 - accuracy: 0.7162 - val_loss: 1.2775 - val_accuracy: 0.7280\n",
      "Epoch 156/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2643 - accuracy: 0.7166 - val_loss: 1.2759 - val_accuracy: 0.7340\n",
      "Epoch 157/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2609 - accuracy: 0.7175 - val_loss: 1.2694 - val_accuracy: 0.7340\n",
      "Epoch 158/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2567 - accuracy: 0.7163 - val_loss: 1.2664 - val_accuracy: 0.7340\n",
      "Epoch 159/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2538 - accuracy: 0.7215 - val_loss: 1.2673 - val_accuracy: 0.7330\n",
      "Epoch 160/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2504 - accuracy: 0.7200 - val_loss: 1.2574 - val_accuracy: 0.7320\n",
      "Epoch 161/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2464 - accuracy: 0.7202 - val_loss: 1.2604 - val_accuracy: 0.7260\n",
      "Epoch 162/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.2435 - accuracy: 0.7180 - val_loss: 1.2553 - val_accuracy: 0.7350\n",
      "Epoch 163/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2406 - accuracy: 0.7174 - val_loss: 1.2484 - val_accuracy: 0.7320\n",
      "Epoch 164/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2366 - accuracy: 0.7202 - val_loss: 1.2448 - val_accuracy: 0.7330\n",
      "Epoch 165/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2340 - accuracy: 0.7209 - val_loss: 1.2434 - val_accuracy: 0.7360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2312 - accuracy: 0.7209 - val_loss: 1.2398 - val_accuracy: 0.7340\n",
      "Epoch 167/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2273 - accuracy: 0.7208 - val_loss: 1.2379 - val_accuracy: 0.7350\n",
      "Epoch 168/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2243 - accuracy: 0.7222 - val_loss: 1.2328 - val_accuracy: 0.7360\n",
      "Epoch 169/1000\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 1.2214 - accuracy: 0.7209 - val_loss: 1.2311 - val_accuracy: 0.7350\n",
      "Epoch 170/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2186 - accuracy: 0.7205 - val_loss: 1.2271 - val_accuracy: 0.7400\n",
      "Epoch 171/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2154 - accuracy: 0.7220 - val_loss: 1.2248 - val_accuracy: 0.7330\n",
      "Epoch 172/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2127 - accuracy: 0.7235 - val_loss: 1.2221 - val_accuracy: 0.7340\n",
      "Epoch 173/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 1.2181 - accuracy: 0.72 - 0s 27us/step - loss: 1.2106 - accuracy: 0.7231 - val_loss: 1.2181 - val_accuracy: 0.7300\n",
      "Epoch 174/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.2065 - accuracy: 0.7231 - val_loss: 1.2148 - val_accuracy: 0.7340\n",
      "Epoch 175/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2034 - accuracy: 0.7245 - val_loss: 1.2155 - val_accuracy: 0.7330\n",
      "Epoch 176/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.2015 - accuracy: 0.7237 - val_loss: 1.2200 - val_accuracy: 0.7380\n",
      "Epoch 177/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1980 - accuracy: 0.7243 - val_loss: 1.2057 - val_accuracy: 0.7400\n",
      "Epoch 178/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1954 - accuracy: 0.7252 - val_loss: 1.2044 - val_accuracy: 0.7400\n",
      "Epoch 179/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1927 - accuracy: 0.7223 - val_loss: 1.2011 - val_accuracy: 0.7380\n",
      "Epoch 180/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1897 - accuracy: 0.7274 - val_loss: 1.1978 - val_accuracy: 0.7370\n",
      "Epoch 181/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1869 - accuracy: 0.7254 - val_loss: 1.1945 - val_accuracy: 0.7420\n",
      "Epoch 182/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1846 - accuracy: 0.7257 - val_loss: 1.1927 - val_accuracy: 0.7430\n",
      "Epoch 183/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1817 - accuracy: 0.7268 - val_loss: 1.1948 - val_accuracy: 0.7350\n",
      "Epoch 184/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1798 - accuracy: 0.7269 - val_loss: 1.1859 - val_accuracy: 0.7430\n",
      "Epoch 185/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1765 - accuracy: 0.7258 - val_loss: 1.1843 - val_accuracy: 0.7370\n",
      "Epoch 186/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.1740 - accuracy: 0.7268 - val_loss: 1.1824 - val_accuracy: 0.7410\n",
      "Epoch 187/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1725 - accuracy: 0.7280 - val_loss: 1.1845 - val_accuracy: 0.7450\n",
      "Epoch 188/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1700 - accuracy: 0.7269 - val_loss: 1.1767 - val_accuracy: 0.7440\n",
      "Epoch 189/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1674 - accuracy: 0.7288 - val_loss: 1.1761 - val_accuracy: 0.7420\n",
      "Epoch 190/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1647 - accuracy: 0.7268 - val_loss: 1.1724 - val_accuracy: 0.7450\n",
      "Epoch 191/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1627 - accuracy: 0.7309 - val_loss: 1.1701 - val_accuracy: 0.7440\n",
      "Epoch 192/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1602 - accuracy: 0.7285 - val_loss: 1.1787 - val_accuracy: 0.7410\n",
      "Epoch 193/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1579 - accuracy: 0.7300 - val_loss: 1.1687 - val_accuracy: 0.7430\n",
      "Epoch 194/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1560 - accuracy: 0.7305 - val_loss: 1.1716 - val_accuracy: 0.7390\n",
      "Epoch 195/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1538 - accuracy: 0.7311 - val_loss: 1.1668 - val_accuracy: 0.7450\n",
      "Epoch 196/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1517 - accuracy: 0.7282 - val_loss: 1.1627 - val_accuracy: 0.7410\n",
      "Epoch 197/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1498 - accuracy: 0.7311 - val_loss: 1.1583 - val_accuracy: 0.7420\n",
      "Epoch 198/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1468 - accuracy: 0.7326 - val_loss: 1.1548 - val_accuracy: 0.7400\n",
      "Epoch 199/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1452 - accuracy: 0.7311 - val_loss: 1.1539 - val_accuracy: 0.7420\n",
      "Epoch 200/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1431 - accuracy: 0.7329 - val_loss: 1.1531 - val_accuracy: 0.7420\n",
      "Epoch 201/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1416 - accuracy: 0.7318 - val_loss: 1.1483 - val_accuracy: 0.7430\n",
      "Epoch 202/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1395 - accuracy: 0.7318 - val_loss: 1.1465 - val_accuracy: 0.7390\n",
      "Epoch 203/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1369 - accuracy: 0.7318 - val_loss: 1.1472 - val_accuracy: 0.7470\n",
      "Epoch 204/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1347 - accuracy: 0.7345 - val_loss: 1.1464 - val_accuracy: 0.7440\n",
      "Epoch 205/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1335 - accuracy: 0.7329 - val_loss: 1.1418 - val_accuracy: 0.7410\n",
      "Epoch 206/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1321 - accuracy: 0.7331 - val_loss: 1.1420 - val_accuracy: 0.7400\n",
      "Epoch 207/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1293 - accuracy: 0.7342 - val_loss: 1.1411 - val_accuracy: 0.7380\n",
      "Epoch 208/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1284 - accuracy: 0.7368 - val_loss: 1.1365 - val_accuracy: 0.7450\n",
      "Epoch 209/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.1269 - accuracy: 0.7354 - val_loss: 1.1366 - val_accuracy: 0.7460\n",
      "Epoch 210/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1250 - accuracy: 0.7354 - val_loss: 1.1309 - val_accuracy: 0.7450\n",
      "Epoch 211/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1232 - accuracy: 0.7343 - val_loss: 1.1327 - val_accuracy: 0.7440\n",
      "Epoch 212/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1221 - accuracy: 0.7340 - val_loss: 1.1301 - val_accuracy: 0.7440\n",
      "Epoch 213/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1194 - accuracy: 0.7346 - val_loss: 1.1317 - val_accuracy: 0.7470\n",
      "Epoch 214/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1185 - accuracy: 0.7372 - val_loss: 1.1315 - val_accuracy: 0.7470\n",
      "Epoch 215/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1169 - accuracy: 0.7380 - val_loss: 1.1315 - val_accuracy: 0.7420\n",
      "Epoch 216/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1151 - accuracy: 0.7378 - val_loss: 1.1322 - val_accuracy: 0.7390\n",
      "Epoch 217/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1139 - accuracy: 0.7349 - val_loss: 1.1216 - val_accuracy: 0.7450\n",
      "Epoch 218/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1127 - accuracy: 0.7351 - val_loss: 1.1283 - val_accuracy: 0.7340\n",
      "Epoch 219/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1109 - accuracy: 0.7380 - val_loss: 1.1240 - val_accuracy: 0.7460\n",
      "Epoch 220/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1095 - accuracy: 0.7378 - val_loss: 1.1186 - val_accuracy: 0.7430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1074 - accuracy: 0.7371 - val_loss: 1.1168 - val_accuracy: 0.7430\n",
      "Epoch 222/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1071 - accuracy: 0.7391 - val_loss: 1.1160 - val_accuracy: 0.7500\n",
      "Epoch 223/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1049 - accuracy: 0.7377 - val_loss: 1.1139 - val_accuracy: 0.7440\n",
      "Epoch 224/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.1035 - accuracy: 0.7383 - val_loss: 1.1109 - val_accuracy: 0.7460\n",
      "Epoch 225/1000\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 1.1020 - accuracy: 0.7386 - val_loss: 1.1140 - val_accuracy: 0.7430\n",
      "Epoch 226/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.1007 - accuracy: 0.7391 - val_loss: 1.1123 - val_accuracy: 0.7440\n",
      "Epoch 227/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0995 - accuracy: 0.7383 - val_loss: 1.1059 - val_accuracy: 0.7490\n",
      "Epoch 228/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0978 - accuracy: 0.7388 - val_loss: 1.1069 - val_accuracy: 0.7440\n",
      "Epoch 229/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0975 - accuracy: 0.7398 - val_loss: 1.1041 - val_accuracy: 0.7470\n",
      "Epoch 230/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0951 - accuracy: 0.7395 - val_loss: 1.1038 - val_accuracy: 0.7520\n",
      "Epoch 231/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0938 - accuracy: 0.7385 - val_loss: 1.1034 - val_accuracy: 0.7490\n",
      "Epoch 232/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0930 - accuracy: 0.7415 - val_loss: 1.1023 - val_accuracy: 0.7480\n",
      "Epoch 233/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0926 - accuracy: 0.7392 - val_loss: 1.1057 - val_accuracy: 0.7590\n",
      "Epoch 234/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0908 - accuracy: 0.7402 - val_loss: 1.1073 - val_accuracy: 0.7490\n",
      "Epoch 235/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0882 - accuracy: 0.7397 - val_loss: 1.0982 - val_accuracy: 0.7500\n",
      "Epoch 236/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0871 - accuracy: 0.7403 - val_loss: 1.1017 - val_accuracy: 0.7450\n",
      "Epoch 237/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0859 - accuracy: 0.7426 - val_loss: 1.0935 - val_accuracy: 0.7500\n",
      "Epoch 238/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0842 - accuracy: 0.7411 - val_loss: 1.0957 - val_accuracy: 0.7520\n",
      "Epoch 239/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0834 - accuracy: 0.7400 - val_loss: 1.0929 - val_accuracy: 0.7480\n",
      "Epoch 240/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0820 - accuracy: 0.7438 - val_loss: 1.0942 - val_accuracy: 0.7500\n",
      "Epoch 241/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0807 - accuracy: 0.7420 - val_loss: 1.0933 - val_accuracy: 0.7490\n",
      "Epoch 242/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0801 - accuracy: 0.7411 - val_loss: 1.0888 - val_accuracy: 0.7530\n",
      "Epoch 243/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0783 - accuracy: 0.7412 - val_loss: 1.0926 - val_accuracy: 0.7430\n",
      "Epoch 244/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0766 - accuracy: 0.7426 - val_loss: 1.0958 - val_accuracy: 0.7510\n",
      "Epoch 245/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0762 - accuracy: 0.7420 - val_loss: 1.0827 - val_accuracy: 0.7520\n",
      "Epoch 246/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0754 - accuracy: 0.7442 - val_loss: 1.0863 - val_accuracy: 0.7530\n",
      "Epoch 247/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0734 - accuracy: 0.7426 - val_loss: 1.0847 - val_accuracy: 0.7490\n",
      "Epoch 248/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0729 - accuracy: 0.7423 - val_loss: 1.0822 - val_accuracy: 0.7510\n",
      "Epoch 249/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0714 - accuracy: 0.7442 - val_loss: 1.0833 - val_accuracy: 0.7570\n",
      "Epoch 250/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0707 - accuracy: 0.7429 - val_loss: 1.0876 - val_accuracy: 0.7470\n",
      "Epoch 251/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0693 - accuracy: 0.7448 - val_loss: 1.0838 - val_accuracy: 0.7610\n",
      "Epoch 252/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0679 - accuracy: 0.7438 - val_loss: 1.0860 - val_accuracy: 0.7560\n",
      "Epoch 253/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0669 - accuracy: 0.7429 - val_loss: 1.0777 - val_accuracy: 0.7570\n",
      "Epoch 254/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0658 - accuracy: 0.7446 - val_loss: 1.0752 - val_accuracy: 0.7560\n",
      "Epoch 255/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0643 - accuracy: 0.7435 - val_loss: 1.0773 - val_accuracy: 0.7600\n",
      "Epoch 256/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0634 - accuracy: 0.7431 - val_loss: 1.0803 - val_accuracy: 0.7520\n",
      "Epoch 257/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0620 - accuracy: 0.7451 - val_loss: 1.0729 - val_accuracy: 0.7550\n",
      "Epoch 258/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0611 - accuracy: 0.7462 - val_loss: 1.0735 - val_accuracy: 0.7560\n",
      "Epoch 259/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0601 - accuracy: 0.7465 - val_loss: 1.0698 - val_accuracy: 0.7520\n",
      "Epoch 260/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0595 - accuracy: 0.7452 - val_loss: 1.0701 - val_accuracy: 0.7540\n",
      "Epoch 261/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0577 - accuracy: 0.7449 - val_loss: 1.0682 - val_accuracy: 0.7530\n",
      "Epoch 262/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0564 - accuracy: 0.7468 - val_loss: 1.0681 - val_accuracy: 0.7520\n",
      "Epoch 263/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0558 - accuracy: 0.7454 - val_loss: 1.0741 - val_accuracy: 0.7550\n",
      "Epoch 264/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0548 - accuracy: 0.7440 - val_loss: 1.0691 - val_accuracy: 0.7450\n",
      "Epoch 265/1000\n",
      "6500/6500 [==============================] - 0s 36us/step - loss: 1.0545 - accuracy: 0.7466 - val_loss: 1.0697 - val_accuracy: 0.7540\n",
      "Epoch 266/1000\n",
      "6500/6500 [==============================] - 0s 41us/step - loss: 1.0526 - accuracy: 0.7477 - val_loss: 1.0640 - val_accuracy: 0.7570\n",
      "Epoch 267/1000\n",
      "6500/6500 [==============================] - 0s 40us/step - loss: 1.0515 - accuracy: 0.7495 - val_loss: 1.0669 - val_accuracy: 0.7490\n",
      "Epoch 268/1000\n",
      "6500/6500 [==============================] - 0s 37us/step - loss: 1.0509 - accuracy: 0.7468 - val_loss: 1.0613 - val_accuracy: 0.7590\n",
      "Epoch 269/1000\n",
      "6500/6500 [==============================] - 0s 35us/step - loss: 1.0497 - accuracy: 0.7483 - val_loss: 1.0610 - val_accuracy: 0.7590\n",
      "Epoch 270/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0484 - accuracy: 0.7469 - val_loss: 1.0593 - val_accuracy: 0.7550\n",
      "Epoch 271/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0474 - accuracy: 0.7489 - val_loss: 1.0616 - val_accuracy: 0.7550\n",
      "Epoch 272/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0468 - accuracy: 0.7486 - val_loss: 1.0590 - val_accuracy: 0.7550\n",
      "Epoch 273/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0462 - accuracy: 0.7474 - val_loss: 1.0584 - val_accuracy: 0.7570\n",
      "Epoch 274/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0452 - accuracy: 0.7486 - val_loss: 1.0594 - val_accuracy: 0.7490\n",
      "Epoch 275/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0445 - accuracy: 0.7482 - val_loss: 1.0565 - val_accuracy: 0.7550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0429 - accuracy: 0.7478 - val_loss: 1.0564 - val_accuracy: 0.7530\n",
      "Epoch 277/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0417 - accuracy: 0.7480 - val_loss: 1.0550 - val_accuracy: 0.7530\n",
      "Epoch 278/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0409 - accuracy: 0.7475 - val_loss: 1.0601 - val_accuracy: 0.7590\n",
      "Epoch 279/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0407 - accuracy: 0.7480 - val_loss: 1.0524 - val_accuracy: 0.7590\n",
      "Epoch 280/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0390 - accuracy: 0.7515 - val_loss: 1.0522 - val_accuracy: 0.7550\n",
      "Epoch 281/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0385 - accuracy: 0.7489 - val_loss: 1.0518 - val_accuracy: 0.7530\n",
      "Epoch 282/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0367 - accuracy: 0.7503 - val_loss: 1.0490 - val_accuracy: 0.7560\n",
      "Epoch 283/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0366 - accuracy: 0.7494 - val_loss: 1.0496 - val_accuracy: 0.7540\n",
      "Epoch 284/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0354 - accuracy: 0.7488 - val_loss: 1.0470 - val_accuracy: 0.7520\n",
      "Epoch 285/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0344 - accuracy: 0.7522 - val_loss: 1.0561 - val_accuracy: 0.7500\n",
      "Epoch 286/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.7494 - val_loss: 1.0457 - val_accuracy: 0.7550\n",
      "Epoch 287/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0332 - accuracy: 0.7498 - val_loss: 1.0466 - val_accuracy: 0.7550\n",
      "Epoch 288/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0318 - accuracy: 0.7514 - val_loss: 1.0478 - val_accuracy: 0.7530\n",
      "Epoch 289/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0314 - accuracy: 0.7511 - val_loss: 1.0430 - val_accuracy: 0.7570\n",
      "Epoch 290/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0301 - accuracy: 0.7491 - val_loss: 1.0450 - val_accuracy: 0.7560\n",
      "Epoch 291/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0296 - accuracy: 0.7509 - val_loss: 1.0434 - val_accuracy: 0.7580\n",
      "Epoch 292/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0290 - accuracy: 0.7526 - val_loss: 1.0423 - val_accuracy: 0.7540\n",
      "Epoch 293/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 1.0277 - accuracy: 0.7523 - val_loss: 1.0456 - val_accuracy: 0.7620\n",
      "Epoch 294/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 1.0268 - accuracy: 0.7517 - val_loss: 1.0418 - val_accuracy: 0.7560\n",
      "Epoch 295/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0256 - accuracy: 0.7534 - val_loss: 1.0484 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0255 - accuracy: 0.7526 - val_loss: 1.0386 - val_accuracy: 0.7570\n",
      "Epoch 297/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0245 - accuracy: 0.7537 - val_loss: 1.0434 - val_accuracy: 0.7650\n",
      "Epoch 298/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0233 - accuracy: 0.7535 - val_loss: 1.0415 - val_accuracy: 0.7610\n",
      "Epoch 299/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0230 - accuracy: 0.7532 - val_loss: 1.0378 - val_accuracy: 0.7610\n",
      "Epoch 300/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0214 - accuracy: 0.7546 - val_loss: 1.0368 - val_accuracy: 0.7550\n",
      "Epoch 301/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0209 - accuracy: 0.7529 - val_loss: 1.0450 - val_accuracy: 0.7530\n",
      "Epoch 302/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0200 - accuracy: 0.7545 - val_loss: 1.0380 - val_accuracy: 0.7600\n",
      "Epoch 303/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0193 - accuracy: 0.7543 - val_loss: 1.0327 - val_accuracy: 0.7560\n",
      "Epoch 304/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0188 - accuracy: 0.7535 - val_loss: 1.0358 - val_accuracy: 0.7590\n",
      "Epoch 305/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0176 - accuracy: 0.7554 - val_loss: 1.0326 - val_accuracy: 0.7580\n",
      "Epoch 306/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0162 - accuracy: 0.7546 - val_loss: 1.0307 - val_accuracy: 0.7580\n",
      "Epoch 307/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0161 - accuracy: 0.7560 - val_loss: 1.0301 - val_accuracy: 0.7550\n",
      "Epoch 308/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0150 - accuracy: 0.7546 - val_loss: 1.0302 - val_accuracy: 0.7590\n",
      "Epoch 309/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0148 - accuracy: 0.7540 - val_loss: 1.0303 - val_accuracy: 0.7650\n",
      "Epoch 310/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0132 - accuracy: 0.7566 - val_loss: 1.0320 - val_accuracy: 0.7600\n",
      "Epoch 311/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0121 - accuracy: 0.7558 - val_loss: 1.0323 - val_accuracy: 0.7560\n",
      "Epoch 312/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0114 - accuracy: 0.7555 - val_loss: 1.0297 - val_accuracy: 0.7580\n",
      "Epoch 313/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0107 - accuracy: 0.7549 - val_loss: 1.0254 - val_accuracy: 0.7580\n",
      "Epoch 314/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0102 - accuracy: 0.7552 - val_loss: 1.0268 - val_accuracy: 0.7530\n",
      "Epoch 315/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0101 - accuracy: 0.7562 - val_loss: 1.0289 - val_accuracy: 0.7620\n",
      "Epoch 316/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0085 - accuracy: 0.7574 - val_loss: 1.0281 - val_accuracy: 0.7520\n",
      "Epoch 317/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0074 - accuracy: 0.7565 - val_loss: 1.0260 - val_accuracy: 0.7580\n",
      "Epoch 318/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0075 - accuracy: 0.7574 - val_loss: 1.0273 - val_accuracy: 0.7620\n",
      "Epoch 319/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0077 - accuracy: 0.7571 - val_loss: 1.0220 - val_accuracy: 0.7610\n",
      "Epoch 320/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0053 - accuracy: 0.7580 - val_loss: 1.0241 - val_accuracy: 0.7620\n",
      "Epoch 321/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0047 - accuracy: 0.7572 - val_loss: 1.0217 - val_accuracy: 0.7550\n",
      "Epoch 322/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0041 - accuracy: 0.7582 - val_loss: 1.0250 - val_accuracy: 0.7540\n",
      "Epoch 323/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 1.0038 - accuracy: 0.7582 - val_loss: 1.0192 - val_accuracy: 0.7590\n",
      "Epoch 324/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0034 - accuracy: 0.7572 - val_loss: 1.0200 - val_accuracy: 0.7560\n",
      "Epoch 325/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0015 - accuracy: 0.7592 - val_loss: 1.0255 - val_accuracy: 0.7540\n",
      "Epoch 326/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 1.0014 - accuracy: 0.7582 - val_loss: 1.0193 - val_accuracy: 0.7630\n",
      "Epoch 327/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 1.0014 - accuracy: 0.7574 - val_loss: 1.0160 - val_accuracy: 0.7600\n",
      "Epoch 328/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9998 - accuracy: 0.7586 - val_loss: 1.0252 - val_accuracy: 0.7560\n",
      "Epoch 329/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9990 - accuracy: 0.7586 - val_loss: 1.0199 - val_accuracy: 0.7610\n",
      "Epoch 330/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9989 - accuracy: 0.7580 - val_loss: 1.0196 - val_accuracy: 0.7610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9978 - accuracy: 0.7591 - val_loss: 1.0177 - val_accuracy: 0.7610\n",
      "Epoch 332/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9964 - accuracy: 0.7572 - val_loss: 1.0151 - val_accuracy: 0.7630\n",
      "Epoch 333/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9963 - accuracy: 0.7609 - val_loss: 1.0192 - val_accuracy: 0.7550\n",
      "Epoch 334/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9959 - accuracy: 0.7577 - val_loss: 1.0149 - val_accuracy: 0.7610\n",
      "Epoch 335/1000\n",
      "6500/6500 [==============================] - 0s 36us/step - loss: 0.9947 - accuracy: 0.7592 - val_loss: 1.0136 - val_accuracy: 0.7610\n",
      "Epoch 336/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9938 - accuracy: 0.7563 - val_loss: 1.0203 - val_accuracy: 0.7580\n",
      "Epoch 337/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9939 - accuracy: 0.7597 - val_loss: 1.0159 - val_accuracy: 0.7630\n",
      "Epoch 338/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9926 - accuracy: 0.7605 - val_loss: 1.0128 - val_accuracy: 0.7580\n",
      "Epoch 339/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9922 - accuracy: 0.7606 - val_loss: 1.0149 - val_accuracy: 0.7580\n",
      "Epoch 340/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9912 - accuracy: 0.7602 - val_loss: 1.0169 - val_accuracy: 0.7560\n",
      "Epoch 341/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9908 - accuracy: 0.7592 - val_loss: 1.0101 - val_accuracy: 0.7630\n",
      "Epoch 342/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9897 - accuracy: 0.7605 - val_loss: 1.0109 - val_accuracy: 0.7570\n",
      "Epoch 343/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9897 - accuracy: 0.7612 - val_loss: 1.0102 - val_accuracy: 0.7610\n",
      "Epoch 344/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9892 - accuracy: 0.7585 - val_loss: 1.0084 - val_accuracy: 0.7610\n",
      "Epoch 345/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9878 - accuracy: 0.7622 - val_loss: 1.0135 - val_accuracy: 0.7510\n",
      "Epoch 346/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9876 - accuracy: 0.7608 - val_loss: 1.0124 - val_accuracy: 0.7580\n",
      "Epoch 347/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9869 - accuracy: 0.7628 - val_loss: 1.0085 - val_accuracy: 0.7630\n",
      "Epoch 348/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9865 - accuracy: 0.7603 - val_loss: 1.0104 - val_accuracy: 0.7620\n",
      "Epoch 349/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9862 - accuracy: 0.7618 - val_loss: 1.0133 - val_accuracy: 0.7560\n",
      "Epoch 350/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9855 - accuracy: 0.7622 - val_loss: 1.0082 - val_accuracy: 0.7630\n",
      "Epoch 351/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9847 - accuracy: 0.7612 - val_loss: 1.0098 - val_accuracy: 0.7640\n",
      "Epoch 352/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9844 - accuracy: 0.7652 - val_loss: 1.0112 - val_accuracy: 0.7540\n",
      "Epoch 353/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9847 - accuracy: 0.7620 - val_loss: 1.0084 - val_accuracy: 0.7610\n",
      "Epoch 354/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9828 - accuracy: 0.7640 - val_loss: 1.0070 - val_accuracy: 0.7610\n",
      "Epoch 355/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9826 - accuracy: 0.7643 - val_loss: 1.0159 - val_accuracy: 0.7530\n",
      "Epoch 356/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9817 - accuracy: 0.7623 - val_loss: 1.0035 - val_accuracy: 0.7630\n",
      "Epoch 357/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9810 - accuracy: 0.7605 - val_loss: 1.0104 - val_accuracy: 0.7550\n",
      "Epoch 358/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9796 - accuracy: 0.7608 - val_loss: 1.0001 - val_accuracy: 0.7580\n",
      "Epoch 359/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9799 - accuracy: 0.7640 - val_loss: 1.0019 - val_accuracy: 0.7610\n",
      "Epoch 360/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9798 - accuracy: 0.7634 - val_loss: 1.0011 - val_accuracy: 0.7640\n",
      "Epoch 361/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9776 - accuracy: 0.7631 - val_loss: 0.9992 - val_accuracy: 0.7630\n",
      "Epoch 362/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9778 - accuracy: 0.7646 - val_loss: 1.0021 - val_accuracy: 0.7580\n",
      "Epoch 363/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9768 - accuracy: 0.7654 - val_loss: 0.9991 - val_accuracy: 0.7640\n",
      "Epoch 364/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9762 - accuracy: 0.7632 - val_loss: 1.0025 - val_accuracy: 0.7580\n",
      "Epoch 365/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9759 - accuracy: 0.7663 - val_loss: 1.0035 - val_accuracy: 0.7580\n",
      "Epoch 366/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9747 - accuracy: 0.7635 - val_loss: 1.0004 - val_accuracy: 0.7600\n",
      "Epoch 367/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9754 - accuracy: 0.7634 - val_loss: 0.9981 - val_accuracy: 0.7630\n",
      "Epoch 368/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.9764 - accuracy: 0.76 - 0s 27us/step - loss: 0.9744 - accuracy: 0.7637 - val_loss: 1.0051 - val_accuracy: 0.7560\n",
      "Epoch 369/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9747 - accuracy: 0.7637 - val_loss: 0.9977 - val_accuracy: 0.7600\n",
      "Epoch 370/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9739 - accuracy: 0.7666 - val_loss: 1.0051 - val_accuracy: 0.7620\n",
      "Epoch 371/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9736 - accuracy: 0.7657 - val_loss: 0.9961 - val_accuracy: 0.7640\n",
      "Epoch 372/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9713 - accuracy: 0.7645 - val_loss: 0.9959 - val_accuracy: 0.7690\n",
      "Epoch 373/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9709 - accuracy: 0.7672 - val_loss: 0.9939 - val_accuracy: 0.7570\n",
      "Epoch 374/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9711 - accuracy: 0.7655 - val_loss: 0.9957 - val_accuracy: 0.7560\n",
      "Epoch 375/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9700 - accuracy: 0.7657 - val_loss: 0.9912 - val_accuracy: 0.7640\n",
      "Epoch 376/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9683 - accuracy: 0.7682 - val_loss: 0.9932 - val_accuracy: 0.7600\n",
      "Epoch 377/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9698 - accuracy: 0.7652 - val_loss: 0.9960 - val_accuracy: 0.7630\n",
      "Epoch 378/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9689 - accuracy: 0.7637 - val_loss: 0.9915 - val_accuracy: 0.7660\n",
      "Epoch 379/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9674 - accuracy: 0.7678 - val_loss: 0.9987 - val_accuracy: 0.7600\n",
      "Epoch 380/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9675 - accuracy: 0.7648 - val_loss: 0.9929 - val_accuracy: 0.7630\n",
      "Epoch 381/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9669 - accuracy: 0.7668 - val_loss: 0.9933 - val_accuracy: 0.7670\n",
      "Epoch 382/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9658 - accuracy: 0.7654 - val_loss: 0.9904 - val_accuracy: 0.7660\n",
      "Epoch 383/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9658 - accuracy: 0.7662 - val_loss: 0.9921 - val_accuracy: 0.7600\n",
      "Epoch 384/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9650 - accuracy: 0.7640 - val_loss: 0.9966 - val_accuracy: 0.7640\n",
      "Epoch 385/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9649 - accuracy: 0.7646 - val_loss: 0.9873 - val_accuracy: 0.7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9639 - accuracy: 0.7680 - val_loss: 0.9894 - val_accuracy: 0.7650\n",
      "Epoch 387/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9642 - accuracy: 0.7662 - val_loss: 0.9934 - val_accuracy: 0.7610\n",
      "Epoch 388/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9636 - accuracy: 0.7655 - val_loss: 0.9927 - val_accuracy: 0.7620\n",
      "Epoch 389/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.9512 - accuracy: 0.76 - 0s 28us/step - loss: 0.9629 - accuracy: 0.7665 - val_loss: 0.9894 - val_accuracy: 0.7630\n",
      "Epoch 390/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9613 - accuracy: 0.7654 - val_loss: 0.9866 - val_accuracy: 0.7600\n",
      "Epoch 391/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9611 - accuracy: 0.7678 - val_loss: 0.9846 - val_accuracy: 0.7590\n",
      "Epoch 392/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9602 - accuracy: 0.7697 - val_loss: 0.9895 - val_accuracy: 0.7690\n",
      "Epoch 393/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9600 - accuracy: 0.7677 - val_loss: 0.9857 - val_accuracy: 0.7670\n",
      "Epoch 394/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9614 - accuracy: 0.7671 - val_loss: 0.9853 - val_accuracy: 0.7670\n",
      "Epoch 395/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9600 - accuracy: 0.7658 - val_loss: 0.9864 - val_accuracy: 0.7650\n",
      "Epoch 396/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9581 - accuracy: 0.7662 - val_loss: 0.9927 - val_accuracy: 0.7570\n",
      "Epoch 397/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9587 - accuracy: 0.7674 - val_loss: 0.9847 - val_accuracy: 0.7680\n",
      "Epoch 398/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9580 - accuracy: 0.7689 - val_loss: 0.9866 - val_accuracy: 0.7640\n",
      "Epoch 399/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9566 - accuracy: 0.7685 - val_loss: 0.9852 - val_accuracy: 0.7640\n",
      "Epoch 400/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9557 - accuracy: 0.7672 - val_loss: 0.9840 - val_accuracy: 0.7630\n",
      "Epoch 401/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9560 - accuracy: 0.7688 - val_loss: 0.9894 - val_accuracy: 0.7630\n",
      "Epoch 402/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9557 - accuracy: 0.7669 - val_loss: 0.9875 - val_accuracy: 0.7620\n",
      "Epoch 403/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9561 - accuracy: 0.7685 - val_loss: 0.9868 - val_accuracy: 0.7620\n",
      "Epoch 404/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.9549 - accuracy: 0.76 - 0s 29us/step - loss: 0.9546 - accuracy: 0.7680 - val_loss: 0.9864 - val_accuracy: 0.7630\n",
      "Epoch 405/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9547 - accuracy: 0.7668 - val_loss: 0.9789 - val_accuracy: 0.7640\n",
      "Epoch 406/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9534 - accuracy: 0.7669 - val_loss: 0.9800 - val_accuracy: 0.7700\n",
      "Epoch 407/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9523 - accuracy: 0.7702 - val_loss: 0.9874 - val_accuracy: 0.7560\n",
      "Epoch 408/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9517 - accuracy: 0.7683 - val_loss: 0.9936 - val_accuracy: 0.7570\n",
      "Epoch 409/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9518 - accuracy: 0.7702 - val_loss: 0.9814 - val_accuracy: 0.7640\n",
      "Epoch 410/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9521 - accuracy: 0.7688 - val_loss: 0.9811 - val_accuracy: 0.7700\n",
      "Epoch 411/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9519 - accuracy: 0.7695 - val_loss: 0.9789 - val_accuracy: 0.7600\n",
      "Epoch 412/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9509 - accuracy: 0.7680 - val_loss: 0.9822 - val_accuracy: 0.7590\n",
      "Epoch 413/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9499 - accuracy: 0.7678 - val_loss: 0.9825 - val_accuracy: 0.7730\n",
      "Epoch 414/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9506 - accuracy: 0.7680 - val_loss: 0.9798 - val_accuracy: 0.7670\n",
      "Epoch 415/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9495 - accuracy: 0.7686 - val_loss: 0.9809 - val_accuracy: 0.7620\n",
      "Epoch 416/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9485 - accuracy: 0.7698 - val_loss: 0.9930 - val_accuracy: 0.7530\n",
      "Epoch 417/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9483 - accuracy: 0.7685 - val_loss: 0.9828 - val_accuracy: 0.7670\n",
      "Epoch 418/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9472 - accuracy: 0.7711 - val_loss: 0.9947 - val_accuracy: 0.7570\n",
      "Epoch 419/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9474 - accuracy: 0.7688 - val_loss: 0.9761 - val_accuracy: 0.7600\n",
      "Epoch 420/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9473 - accuracy: 0.7672 - val_loss: 0.9775 - val_accuracy: 0.7660\n",
      "Epoch 421/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9456 - accuracy: 0.7700 - val_loss: 0.9798 - val_accuracy: 0.7650\n",
      "Epoch 422/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9455 - accuracy: 0.7683 - val_loss: 0.9957 - val_accuracy: 0.7580\n",
      "Epoch 423/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9467 - accuracy: 0.7675 - val_loss: 0.9718 - val_accuracy: 0.7650\n",
      "Epoch 424/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9438 - accuracy: 0.7726 - val_loss: 0.9768 - val_accuracy: 0.7600\n",
      "Epoch 425/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9449 - accuracy: 0.7718 - val_loss: 0.9738 - val_accuracy: 0.7660\n",
      "Epoch 426/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.76 - 0s 27us/step - loss: 0.9436 - accuracy: 0.7677 - val_loss: 0.9843 - val_accuracy: 0.7610\n",
      "Epoch 427/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9440 - accuracy: 0.7709 - val_loss: 0.9839 - val_accuracy: 0.7660\n",
      "Epoch 428/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9445 - accuracy: 0.7698 - val_loss: 0.9823 - val_accuracy: 0.7660\n",
      "Epoch 429/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9433 - accuracy: 0.7708 - val_loss: 0.9738 - val_accuracy: 0.7650\n",
      "Epoch 430/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9421 - accuracy: 0.7709 - val_loss: 0.9716 - val_accuracy: 0.7660\n",
      "Epoch 431/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9412 - accuracy: 0.7725 - val_loss: 0.9755 - val_accuracy: 0.7670\n",
      "Epoch 432/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9413 - accuracy: 0.7700 - val_loss: 0.9771 - val_accuracy: 0.7660\n",
      "Epoch 433/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9409 - accuracy: 0.7706 - val_loss: 0.9798 - val_accuracy: 0.7640\n",
      "Epoch 434/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9400 - accuracy: 0.7712 - val_loss: 0.9737 - val_accuracy: 0.7620\n",
      "Epoch 435/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9414 - accuracy: 0.7705 - val_loss: 0.9689 - val_accuracy: 0.7670\n",
      "Epoch 436/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9381 - accuracy: 0.7717 - val_loss: 0.9724 - val_accuracy: 0.7650\n",
      "Epoch 437/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9390 - accuracy: 0.7717 - val_loss: 0.9688 - val_accuracy: 0.7670\n",
      "Epoch 438/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9375 - accuracy: 0.7729 - val_loss: 0.9725 - val_accuracy: 0.7630\n",
      "Epoch 439/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.9379 - accuracy: 0.7743 - val_loss: 0.9815 - val_accuracy: 0.7550\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9383 - accuracy: 0.7717 - val_loss: 0.9830 - val_accuracy: 0.7590\n",
      "Epoch 441/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9385 - accuracy: 0.7731 - val_loss: 0.9734 - val_accuracy: 0.7640\n",
      "Epoch 442/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9367 - accuracy: 0.7729 - val_loss: 0.9716 - val_accuracy: 0.7680\n",
      "Epoch 443/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9372 - accuracy: 0.7731 - val_loss: 0.9669 - val_accuracy: 0.7620\n",
      "Epoch 444/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9363 - accuracy: 0.7714 - val_loss: 0.9780 - val_accuracy: 0.7670\n",
      "Epoch 445/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9346 - accuracy: 0.7728 - val_loss: 0.9741 - val_accuracy: 0.7630\n",
      "Epoch 446/1000\n",
      "6500/6500 [==============================] - 0s 36us/step - loss: 0.9336 - accuracy: 0.7712 - val_loss: 0.9697 - val_accuracy: 0.7620\n",
      "Epoch 447/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9333 - accuracy: 0.7720 - val_loss: 0.9779 - val_accuracy: 0.7570\n",
      "Epoch 448/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9365 - accuracy: 0.7695 - val_loss: 0.9701 - val_accuracy: 0.7690\n",
      "Epoch 449/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9325 - accuracy: 0.7731 - val_loss: 0.9673 - val_accuracy: 0.7700\n",
      "Epoch 450/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.9324 - accuracy: 0.7712 - val_loss: 0.9650 - val_accuracy: 0.7720\n",
      "Epoch 451/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9321 - accuracy: 0.7712 - val_loss: 0.9822 - val_accuracy: 0.7550\n",
      "Epoch 452/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9322 - accuracy: 0.7731 - val_loss: 0.9649 - val_accuracy: 0.7690\n",
      "Epoch 453/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9328 - accuracy: 0.7735 - val_loss: 0.9713 - val_accuracy: 0.7650\n",
      "Epoch 454/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9310 - accuracy: 0.7720 - val_loss: 0.9679 - val_accuracy: 0.7660\n",
      "Epoch 455/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9303 - accuracy: 0.7714 - val_loss: 0.9625 - val_accuracy: 0.7640\n",
      "Epoch 456/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9299 - accuracy: 0.7726 - val_loss: 0.9645 - val_accuracy: 0.7640\n",
      "Epoch 457/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9306 - accuracy: 0.7745 - val_loss: 0.9607 - val_accuracy: 0.7670\n",
      "Epoch 458/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9291 - accuracy: 0.7732 - val_loss: 0.9609 - val_accuracy: 0.7680\n",
      "Epoch 459/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9298 - accuracy: 0.7737 - val_loss: 0.9766 - val_accuracy: 0.7610\n",
      "Epoch 460/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9285 - accuracy: 0.7777 - val_loss: 0.9615 - val_accuracy: 0.7680\n",
      "Epoch 461/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9293 - accuracy: 0.7728 - val_loss: 0.9679 - val_accuracy: 0.7710\n",
      "Epoch 462/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9290 - accuracy: 0.7732 - val_loss: 0.9662 - val_accuracy: 0.7640\n",
      "Epoch 463/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9271 - accuracy: 0.7742 - val_loss: 0.9676 - val_accuracy: 0.7630\n",
      "Epoch 464/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9273 - accuracy: 0.7755 - val_loss: 0.9621 - val_accuracy: 0.7620\n",
      "Epoch 465/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9265 - accuracy: 0.7763 - val_loss: 0.9609 - val_accuracy: 0.7730\n",
      "Epoch 466/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9265 - accuracy: 0.7749 - val_loss: 0.9670 - val_accuracy: 0.7620\n",
      "Epoch 467/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9264 - accuracy: 0.7757 - val_loss: 0.9633 - val_accuracy: 0.7690\n",
      "Epoch 468/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9269 - accuracy: 0.7758 - val_loss: 0.9621 - val_accuracy: 0.7710\n",
      "Epoch 469/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9252 - accuracy: 0.7726 - val_loss: 0.9622 - val_accuracy: 0.7710\n",
      "Epoch 470/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9247 - accuracy: 0.7754 - val_loss: 0.9713 - val_accuracy: 0.7620\n",
      "Epoch 471/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9256 - accuracy: 0.7740 - val_loss: 0.9715 - val_accuracy: 0.7640\n",
      "Epoch 472/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9241 - accuracy: 0.7752 - val_loss: 0.9582 - val_accuracy: 0.7680\n",
      "Epoch 473/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9223 - accuracy: 0.7752 - val_loss: 0.9610 - val_accuracy: 0.7640\n",
      "Epoch 474/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9226 - accuracy: 0.7768 - val_loss: 0.9681 - val_accuracy: 0.7630\n",
      "Epoch 475/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9232 - accuracy: 0.7757 - val_loss: 0.9595 - val_accuracy: 0.7680\n",
      "Epoch 476/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9236 - accuracy: 0.7726 - val_loss: 0.9622 - val_accuracy: 0.7690\n",
      "Epoch 477/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9212 - accuracy: 0.7754 - val_loss: 0.9599 - val_accuracy: 0.7670\n",
      "Epoch 478/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9210 - accuracy: 0.7755 - val_loss: 0.9593 - val_accuracy: 0.7670\n",
      "Epoch 479/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9213 - accuracy: 0.7754 - val_loss: 0.9650 - val_accuracy: 0.7670\n",
      "Epoch 480/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9210 - accuracy: 0.7792 - val_loss: 0.9660 - val_accuracy: 0.7610\n",
      "Epoch 481/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9200 - accuracy: 0.7751 - val_loss: 0.9605 - val_accuracy: 0.7700\n",
      "Epoch 482/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.9169 - accuracy: 0.77 - 0s 28us/step - loss: 0.9195 - accuracy: 0.7760 - val_loss: 0.9575 - val_accuracy: 0.7670\n",
      "Epoch 483/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9213 - accuracy: 0.7771 - val_loss: 0.9605 - val_accuracy: 0.7670\n",
      "Epoch 484/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9206 - accuracy: 0.7772 - val_loss: 0.9602 - val_accuracy: 0.7650\n",
      "Epoch 485/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9182 - accuracy: 0.7778 - val_loss: 0.9536 - val_accuracy: 0.7660\n",
      "Epoch 486/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9182 - accuracy: 0.7749 - val_loss: 0.9540 - val_accuracy: 0.7690\n",
      "Epoch 487/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9170 - accuracy: 0.7791 - val_loss: 0.9587 - val_accuracy: 0.7660\n",
      "Epoch 488/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9165 - accuracy: 0.7786 - val_loss: 0.9674 - val_accuracy: 0.7630\n",
      "Epoch 489/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9179 - accuracy: 0.7777 - val_loss: 0.9612 - val_accuracy: 0.7650\n",
      "Epoch 490/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9161 - accuracy: 0.7792 - val_loss: 0.9575 - val_accuracy: 0.7710\n",
      "Epoch 491/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9173 - accuracy: 0.7760 - val_loss: 0.9524 - val_accuracy: 0.7650\n",
      "Epoch 492/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9168 - accuracy: 0.7771 - val_loss: 0.9511 - val_accuracy: 0.7670\n",
      "Epoch 493/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9155 - accuracy: 0.7775 - val_loss: 0.9618 - val_accuracy: 0.7670\n",
      "Epoch 494/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9159 - accuracy: 0.7757 - val_loss: 0.9592 - val_accuracy: 0.7630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9150 - accuracy: 0.7806 - val_loss: 0.9555 - val_accuracy: 0.7690\n",
      "Epoch 496/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9154 - accuracy: 0.7769 - val_loss: 0.9617 - val_accuracy: 0.7620\n",
      "Epoch 497/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9141 - accuracy: 0.7800 - val_loss: 0.9622 - val_accuracy: 0.7590\n",
      "Epoch 498/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9157 - accuracy: 0.7768 - val_loss: 0.9597 - val_accuracy: 0.7660\n",
      "Epoch 499/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9128 - accuracy: 0.7800 - val_loss: 0.9622 - val_accuracy: 0.7640\n",
      "Epoch 500/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9143 - accuracy: 0.7772 - val_loss: 0.9665 - val_accuracy: 0.7590\n",
      "Epoch 501/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9136 - accuracy: 0.7786 - val_loss: 0.9568 - val_accuracy: 0.7600\n",
      "Epoch 502/1000\n",
      "6500/6500 [==============================] - 0s 33us/step - loss: 0.9127 - accuracy: 0.7769 - val_loss: 0.9498 - val_accuracy: 0.7690\n",
      "Epoch 503/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9135 - accuracy: 0.7785 - val_loss: 0.9573 - val_accuracy: 0.7660\n",
      "Epoch 504/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9118 - accuracy: 0.7765 - val_loss: 0.9479 - val_accuracy: 0.7640\n",
      "Epoch 505/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9108 - accuracy: 0.7785 - val_loss: 0.9515 - val_accuracy: 0.7680\n",
      "Epoch 506/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9103 - accuracy: 0.7815 - val_loss: 0.9484 - val_accuracy: 0.7650\n",
      "Epoch 507/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9110 - accuracy: 0.7780 - val_loss: 0.9469 - val_accuracy: 0.7700\n",
      "Epoch 508/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9106 - accuracy: 0.7775 - val_loss: 0.9592 - val_accuracy: 0.7640\n",
      "Epoch 509/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9104 - accuracy: 0.7792 - val_loss: 0.9519 - val_accuracy: 0.7650\n",
      "Epoch 510/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9093 - accuracy: 0.7800 - val_loss: 0.9474 - val_accuracy: 0.7650\n",
      "Epoch 511/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9090 - accuracy: 0.7786 - val_loss: 0.9580 - val_accuracy: 0.7690\n",
      "Epoch 512/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9083 - accuracy: 0.7771 - val_loss: 0.9497 - val_accuracy: 0.7690\n",
      "Epoch 513/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9077 - accuracy: 0.7808 - val_loss: 0.9642 - val_accuracy: 0.7580\n",
      "Epoch 514/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9089 - accuracy: 0.7786 - val_loss: 0.9634 - val_accuracy: 0.7640\n",
      "Epoch 515/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9089 - accuracy: 0.7802 - val_loss: 0.9573 - val_accuracy: 0.7620\n",
      "Epoch 516/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9073 - accuracy: 0.7785 - val_loss: 0.9450 - val_accuracy: 0.7720\n",
      "Epoch 517/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9060 - accuracy: 0.7811 - val_loss: 0.9487 - val_accuracy: 0.7650\n",
      "Epoch 518/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9067 - accuracy: 0.7802 - val_loss: 0.9550 - val_accuracy: 0.7680\n",
      "Epoch 519/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9061 - accuracy: 0.7788 - val_loss: 0.9512 - val_accuracy: 0.7650\n",
      "Epoch 520/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.9051 - accuracy: 0.78 - 0s 29us/step - loss: 0.9055 - accuracy: 0.7811 - val_loss: 0.9440 - val_accuracy: 0.7720\n",
      "Epoch 521/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9068 - accuracy: 0.7808 - val_loss: 0.9634 - val_accuracy: 0.7640\n",
      "Epoch 522/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9040 - accuracy: 0.7814 - val_loss: 0.9432 - val_accuracy: 0.7710\n",
      "Epoch 523/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9032 - accuracy: 0.7809 - val_loss: 0.9451 - val_accuracy: 0.7630\n",
      "Epoch 524/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9041 - accuracy: 0.7780 - val_loss: 0.9454 - val_accuracy: 0.7730\n",
      "Epoch 525/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9052 - accuracy: 0.7814 - val_loss: 0.9416 - val_accuracy: 0.7740\n",
      "Epoch 526/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9022 - accuracy: 0.7831 - val_loss: 0.9443 - val_accuracy: 0.7690\n",
      "Epoch 527/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9040 - accuracy: 0.7818 - val_loss: 0.9434 - val_accuracy: 0.7750\n",
      "Epoch 528/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9040 - accuracy: 0.7798 - val_loss: 0.9438 - val_accuracy: 0.7700\n",
      "Epoch 529/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9032 - accuracy: 0.7783 - val_loss: 0.9411 - val_accuracy: 0.7700\n",
      "Epoch 530/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9024 - accuracy: 0.7842 - val_loss: 0.9520 - val_accuracy: 0.7630\n",
      "Epoch 531/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9017 - accuracy: 0.7820 - val_loss: 0.9503 - val_accuracy: 0.7630\n",
      "Epoch 532/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9033 - accuracy: 0.7823 - val_loss: 0.9651 - val_accuracy: 0.7660\n",
      "Epoch 533/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.9011 - accuracy: 0.7802 - val_loss: 0.9417 - val_accuracy: 0.7660\n",
      "Epoch 534/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9006 - accuracy: 0.7811 - val_loss: 0.9465 - val_accuracy: 0.7730\n",
      "Epoch 535/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.9003 - accuracy: 0.7794 - val_loss: 0.9523 - val_accuracy: 0.7620\n",
      "Epoch 536/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.9008 - accuracy: 0.7818 - val_loss: 0.9542 - val_accuracy: 0.7620\n",
      "Epoch 537/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8992 - accuracy: 0.7802 - val_loss: 0.9410 - val_accuracy: 0.7730\n",
      "Epoch 538/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8998 - accuracy: 0.7808 - val_loss: 0.9393 - val_accuracy: 0.7700\n",
      "Epoch 539/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8993 - accuracy: 0.7829 - val_loss: 0.9406 - val_accuracy: 0.7690\n",
      "Epoch 540/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8992 - accuracy: 0.7854 - val_loss: 0.9458 - val_accuracy: 0.7710\n",
      "Epoch 541/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8999 - accuracy: 0.7805 - val_loss: 0.9426 - val_accuracy: 0.7640\n",
      "Epoch 542/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8984 - accuracy: 0.7818 - val_loss: 0.9401 - val_accuracy: 0.7700\n",
      "Epoch 543/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8988 - accuracy: 0.7846 - val_loss: 0.9495 - val_accuracy: 0.7670\n",
      "Epoch 544/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8985 - accuracy: 0.7822 - val_loss: 0.9437 - val_accuracy: 0.7670\n",
      "Epoch 545/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8972 - accuracy: 0.7834 - val_loss: 0.9392 - val_accuracy: 0.7710\n",
      "Epoch 546/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8952 - accuracy: 0.7851 - val_loss: 0.9619 - val_accuracy: 0.7620\n",
      "Epoch 547/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8975 - accuracy: 0.7823 - val_loss: 0.9438 - val_accuracy: 0.7670\n",
      "Epoch 548/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8965 - accuracy: 0.7811 - val_loss: 0.9473 - val_accuracy: 0.7660\n",
      "Epoch 549/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8951 - accuracy: 0.7838 - val_loss: 0.9577 - val_accuracy: 0.7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8958 - accuracy: 0.7842 - val_loss: 0.9584 - val_accuracy: 0.7580\n",
      "Epoch 551/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8965 - accuracy: 0.7814 - val_loss: 0.9359 - val_accuracy: 0.7690\n",
      "Epoch 552/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8950 - accuracy: 0.7806 - val_loss: 0.9375 - val_accuracy: 0.7750\n",
      "Epoch 553/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8948 - accuracy: 0.7825 - val_loss: 0.9435 - val_accuracy: 0.7660\n",
      "Epoch 554/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8953 - accuracy: 0.7829 - val_loss: 0.9368 - val_accuracy: 0.7700\n",
      "Epoch 555/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8941 - accuracy: 0.7815 - val_loss: 0.9369 - val_accuracy: 0.7730\n",
      "Epoch 556/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8934 - accuracy: 0.7855 - val_loss: 0.9348 - val_accuracy: 0.7720\n",
      "Epoch 557/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8924 - accuracy: 0.7815 - val_loss: 0.9386 - val_accuracy: 0.7710\n",
      "Epoch 558/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8959 - accuracy: 0.7840 - val_loss: 0.9377 - val_accuracy: 0.7720\n",
      "Epoch 559/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8941 - accuracy: 0.7820 - val_loss: 0.9445 - val_accuracy: 0.7670\n",
      "Epoch 560/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8950 - accuracy: 0.78 - 0s 29us/step - loss: 0.8920 - accuracy: 0.7826 - val_loss: 0.9386 - val_accuracy: 0.7680\n",
      "Epoch 561/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8932 - accuracy: 0.7825 - val_loss: 0.9382 - val_accuracy: 0.7760\n",
      "Epoch 562/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8911 - accuracy: 0.7868 - val_loss: 0.9473 - val_accuracy: 0.7630\n",
      "Epoch 563/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8925 - accuracy: 0.7826 - val_loss: 0.9535 - val_accuracy: 0.7590\n",
      "Epoch 564/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8925 - accuracy: 0.7842 - val_loss: 0.9479 - val_accuracy: 0.7650\n",
      "Epoch 565/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8921 - accuracy: 0.7822 - val_loss: 0.9404 - val_accuracy: 0.7670\n",
      "Epoch 566/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8904 - accuracy: 0.7814 - val_loss: 0.9510 - val_accuracy: 0.7620\n",
      "Epoch 567/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8919 - accuracy: 0.7837 - val_loss: 0.9356 - val_accuracy: 0.7690\n",
      "Epoch 568/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8888 - accuracy: 0.7854 - val_loss: 0.9399 - val_accuracy: 0.7670\n",
      "Epoch 569/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8895 - accuracy: 0.7822 - val_loss: 0.9377 - val_accuracy: 0.7700\n",
      "Epoch 570/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8893 - accuracy: 0.7845 - val_loss: 0.9375 - val_accuracy: 0.7660\n",
      "Epoch 571/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8877 - accuracy: 0.7818 - val_loss: 0.9395 - val_accuracy: 0.7640\n",
      "Epoch 572/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8869 - accuracy: 0.7852 - val_loss: 0.9408 - val_accuracy: 0.7770\n",
      "Epoch 573/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8880 - accuracy: 0.7835 - val_loss: 0.9350 - val_accuracy: 0.7750\n",
      "Epoch 574/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8864 - accuracy: 0.7854 - val_loss: 0.9422 - val_accuracy: 0.7680\n",
      "Epoch 575/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8869 - accuracy: 0.7838 - val_loss: 0.9470 - val_accuracy: 0.7590\n",
      "Epoch 576/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8876 - accuracy: 0.7858 - val_loss: 0.9426 - val_accuracy: 0.7680\n",
      "Epoch 577/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8899 - accuracy: 0.7817 - val_loss: 0.9324 - val_accuracy: 0.7710\n",
      "Epoch 578/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8846 - accuracy: 0.7871 - val_loss: 0.9490 - val_accuracy: 0.7750\n",
      "Epoch 579/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8864 - accuracy: 0.7834 - val_loss: 0.9335 - val_accuracy: 0.7660\n",
      "Epoch 580/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8865 - accuracy: 0.7828 - val_loss: 0.9347 - val_accuracy: 0.7710\n",
      "Epoch 581/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8866 - accuracy: 0.7834 - val_loss: 0.9424 - val_accuracy: 0.7650\n",
      "Epoch 582/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8858 - accuracy: 0.7858 - val_loss: 0.9490 - val_accuracy: 0.7710\n",
      "Epoch 583/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.8861 - accuracy: 0.7857 - val_loss: 0.9327 - val_accuracy: 0.7700\n",
      "Epoch 584/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.8854 - accuracy: 0.7846 - val_loss: 0.9325 - val_accuracy: 0.7690\n",
      "Epoch 585/1000\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8871 - accuracy: 0.7854 - val_loss: 0.9312 - val_accuracy: 0.7710\n",
      "Epoch 586/1000\n",
      "6500/6500 [==============================] - 0s 41us/step - loss: 0.8834 - accuracy: 0.7857 - val_loss: 0.9391 - val_accuracy: 0.7690\n",
      "Epoch 587/1000\n",
      "6500/6500 [==============================] - 0s 41us/step - loss: 0.8835 - accuracy: 0.7865 - val_loss: 0.9405 - val_accuracy: 0.7660\n",
      "Epoch 588/1000\n",
      "6500/6500 [==============================] - 0s 35us/step - loss: 0.8821 - accuracy: 0.7882 - val_loss: 0.9458 - val_accuracy: 0.7580\n",
      "Epoch 589/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8834 - accuracy: 0.7848 - val_loss: 0.9371 - val_accuracy: 0.7650\n",
      "Epoch 590/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8824 - accuracy: 0.7866 - val_loss: 0.9456 - val_accuracy: 0.7670\n",
      "Epoch 591/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8824 - accuracy: 0.7855 - val_loss: 0.9314 - val_accuracy: 0.7760\n",
      "Epoch 592/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8829 - accuracy: 0.7835 - val_loss: 0.9326 - val_accuracy: 0.7710\n",
      "Epoch 593/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8868 - accuracy: 0.78 - 0s 29us/step - loss: 0.8815 - accuracy: 0.7882 - val_loss: 0.9286 - val_accuracy: 0.7650\n",
      "Epoch 594/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8808 - accuracy: 0.7869 - val_loss: 0.9334 - val_accuracy: 0.7790\n",
      "Epoch 595/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8825 - accuracy: 0.7869 - val_loss: 0.9330 - val_accuracy: 0.7700\n",
      "Epoch 596/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8818 - accuracy: 0.7845 - val_loss: 0.9303 - val_accuracy: 0.7760\n",
      "Epoch 597/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8796 - accuracy: 0.7860 - val_loss: 0.9313 - val_accuracy: 0.7660\n",
      "Epoch 598/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8813 - accuracy: 0.7883 - val_loss: 0.9309 - val_accuracy: 0.7710\n",
      "Epoch 599/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8815 - accuracy: 0.7848 - val_loss: 0.9370 - val_accuracy: 0.7700\n",
      "Epoch 600/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8800 - accuracy: 0.7868 - val_loss: 0.9325 - val_accuracy: 0.7680\n",
      "Epoch 601/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8814 - accuracy: 0.78 - 0s 29us/step - loss: 0.8803 - accuracy: 0.7883 - val_loss: 0.9338 - val_accuracy: 0.7750\n",
      "Epoch 602/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8811 - accuracy: 0.7852 - val_loss: 0.9279 - val_accuracy: 0.7740\n",
      "Epoch 603/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8801 - accuracy: 0.7834 - val_loss: 0.9459 - val_accuracy: 0.7600\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8784 - accuracy: 0.7863 - val_loss: 0.9459 - val_accuracy: 0.7650\n",
      "Epoch 605/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8788 - accuracy: 0.7888 - val_loss: 0.9362 - val_accuracy: 0.7740\n",
      "Epoch 606/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8784 - accuracy: 0.7860 - val_loss: 0.9269 - val_accuracy: 0.7730\n",
      "Epoch 607/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8769 - accuracy: 0.7865 - val_loss: 0.9330 - val_accuracy: 0.7670\n",
      "Epoch 608/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8760 - accuracy: 0.7894 - val_loss: 0.9287 - val_accuracy: 0.7760\n",
      "Epoch 609/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8777 - accuracy: 0.7886 - val_loss: 0.9343 - val_accuracy: 0.7700\n",
      "Epoch 610/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8776 - accuracy: 0.7863 - val_loss: 0.9249 - val_accuracy: 0.7710\n",
      "Epoch 611/1000\n",
      "6500/6500 [==============================] - 0s 35us/step - loss: 0.8787 - accuracy: 0.7883 - val_loss: 0.9362 - val_accuracy: 0.7730\n",
      "Epoch 612/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8769 - accuracy: 0.7869 - val_loss: 0.9250 - val_accuracy: 0.7640\n",
      "Epoch 613/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8766 - accuracy: 0.7895 - val_loss: 0.9240 - val_accuracy: 0.7710\n",
      "Epoch 614/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8752 - accuracy: 0.7914 - val_loss: 0.9259 - val_accuracy: 0.7680\n",
      "Epoch 615/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8764 - accuracy: 0.7886 - val_loss: 0.9261 - val_accuracy: 0.7660\n",
      "Epoch 616/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8753 - accuracy: 0.7883 - val_loss: 0.9223 - val_accuracy: 0.7700\n",
      "Epoch 617/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8766 - accuracy: 0.7865 - val_loss: 0.9401 - val_accuracy: 0.7690\n",
      "Epoch 618/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8760 - accuracy: 0.7877 - val_loss: 0.9328 - val_accuracy: 0.7700\n",
      "Epoch 619/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8748 - accuracy: 0.7862 - val_loss: 0.9323 - val_accuracy: 0.7660\n",
      "Epoch 620/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8742 - accuracy: 0.7886 - val_loss: 0.9321 - val_accuracy: 0.7650\n",
      "Epoch 621/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8739 - accuracy: 0.7871 - val_loss: 0.9350 - val_accuracy: 0.7670\n",
      "Epoch 622/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8733 - accuracy: 0.7889 - val_loss: 0.9232 - val_accuracy: 0.7680\n",
      "Epoch 623/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8741 - accuracy: 0.7885 - val_loss: 0.9261 - val_accuracy: 0.7720\n",
      "Epoch 624/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8728 - accuracy: 0.7902 - val_loss: 0.9452 - val_accuracy: 0.7610\n",
      "Epoch 625/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8749 - accuracy: 0.7898 - val_loss: 0.9528 - val_accuracy: 0.7630\n",
      "Epoch 626/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8731 - accuracy: 0.7892 - val_loss: 0.9283 - val_accuracy: 0.7790\n",
      "Epoch 627/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8712 - accuracy: 0.7892 - val_loss: 0.9286 - val_accuracy: 0.7680\n",
      "Epoch 628/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8730 - accuracy: 0.7849 - val_loss: 0.9274 - val_accuracy: 0.7670\n",
      "Epoch 629/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8724 - accuracy: 0.7880 - val_loss: 0.9235 - val_accuracy: 0.7710\n",
      "Epoch 630/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8728 - accuracy: 0.7895 - val_loss: 0.9697 - val_accuracy: 0.7500\n",
      "Epoch 631/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8748 - accuracy: 0.7898 - val_loss: 0.9245 - val_accuracy: 0.7670\n",
      "Epoch 632/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8713 - accuracy: 0.7905 - val_loss: 0.9761 - val_accuracy: 0.7470\n",
      "Epoch 633/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8734 - accuracy: 0.7932 - val_loss: 0.9226 - val_accuracy: 0.7690\n",
      "Epoch 634/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8715 - accuracy: 0.7875 - val_loss: 0.9319 - val_accuracy: 0.7640\n",
      "Epoch 635/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8698 - accuracy: 0.7883 - val_loss: 0.9491 - val_accuracy: 0.7660\n",
      "Epoch 636/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8711 - accuracy: 0.7925 - val_loss: 0.9214 - val_accuracy: 0.7720\n",
      "Epoch 637/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8710 - accuracy: 0.7878 - val_loss: 0.9318 - val_accuracy: 0.7570\n",
      "Epoch 638/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8691 - accuracy: 0.7902 - val_loss: 0.9573 - val_accuracy: 0.7560\n",
      "Epoch 639/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8724 - accuracy: 0.7883 - val_loss: 0.9298 - val_accuracy: 0.7660\n",
      "Epoch 640/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8680 - accuracy: 0.7900 - val_loss: 0.9371 - val_accuracy: 0.7640\n",
      "Epoch 641/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8684 - accuracy: 0.7902 - val_loss: 0.9239 - val_accuracy: 0.7750\n",
      "Epoch 642/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8694 - accuracy: 0.7920 - val_loss: 0.9206 - val_accuracy: 0.7700\n",
      "Epoch 643/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8695 - accuracy: 0.7905 - val_loss: 0.9245 - val_accuracy: 0.7650\n",
      "Epoch 644/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8681 - accuracy: 0.7911 - val_loss: 0.9435 - val_accuracy: 0.7590\n",
      "Epoch 645/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8701 - accuracy: 0.7906 - val_loss: 0.9352 - val_accuracy: 0.7730\n",
      "Epoch 646/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8682 - accuracy: 0.7898 - val_loss: 0.9222 - val_accuracy: 0.7690\n",
      "Epoch 647/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8685 - accuracy: 0.7917 - val_loss: 0.9387 - val_accuracy: 0.7680\n",
      "Epoch 648/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8670 - accuracy: 0.7920 - val_loss: 0.9237 - val_accuracy: 0.7800\n",
      "Epoch 649/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8697 - accuracy: 0.7892 - val_loss: 0.9225 - val_accuracy: 0.7730\n",
      "Epoch 650/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8673 - accuracy: 0.7932 - val_loss: 0.9349 - val_accuracy: 0.7590\n",
      "Epoch 651/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8696 - accuracy: 0.7915 - val_loss: 0.9313 - val_accuracy: 0.7680\n",
      "Epoch 652/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8659 - accuracy: 0.7915 - val_loss: 0.9571 - val_accuracy: 0.7570\n",
      "Epoch 653/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8679 - accuracy: 0.7915 - val_loss: 0.9324 - val_accuracy: 0.7710\n",
      "Epoch 654/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8659 - accuracy: 0.7917 - val_loss: 0.9144 - val_accuracy: 0.7680\n",
      "Epoch 655/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8662 - accuracy: 0.7922 - val_loss: 0.9326 - val_accuracy: 0.7610\n",
      "Epoch 656/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8655 - accuracy: 0.7903 - val_loss: 0.9379 - val_accuracy: 0.7570\n",
      "Epoch 657/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8649 - accuracy: 0.7925 - val_loss: 0.9304 - val_accuracy: 0.7620\n",
      "Epoch 658/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8648 - accuracy: 0.7920 - val_loss: 0.9295 - val_accuracy: 0.7670\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8653 - accuracy: 0.7914 - val_loss: 0.9326 - val_accuracy: 0.7660\n",
      "Epoch 660/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8658 - accuracy: 0.7888 - val_loss: 0.9209 - val_accuracy: 0.7800\n",
      "Epoch 661/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8653 - accuracy: 0.7900 - val_loss: 0.9201 - val_accuracy: 0.7760\n",
      "Epoch 662/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8627 - accuracy: 0.7922 - val_loss: 0.9340 - val_accuracy: 0.7640\n",
      "Epoch 663/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8658 - accuracy: 0.7892 - val_loss: 0.9536 - val_accuracy: 0.7530\n",
      "Epoch 664/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8659 - accuracy: 0.7912 - val_loss: 0.9305 - val_accuracy: 0.7620\n",
      "Epoch 665/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8640 - accuracy: 0.7925 - val_loss: 0.9205 - val_accuracy: 0.7740\n",
      "Epoch 666/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.8645 - accuracy: 0.7912 - val_loss: 0.9212 - val_accuracy: 0.7720\n",
      "Epoch 667/1000\n",
      "6500/6500 [==============================] - 0s 38us/step - loss: 0.8630 - accuracy: 0.7908 - val_loss: 0.9189 - val_accuracy: 0.7740\n",
      "Epoch 668/1000\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.8608 - accuracy: 0.7949 - val_loss: 0.9480 - val_accuracy: 0.7570\n",
      "Epoch 669/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8657 - accuracy: 0.7895 - val_loss: 0.9239 - val_accuracy: 0.7640\n",
      "Epoch 670/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8613 - accuracy: 0.7945 - val_loss: 0.9229 - val_accuracy: 0.7750\n",
      "Epoch 671/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.8611 - accuracy: 0.7923 - val_loss: 0.9192 - val_accuracy: 0.7660\n",
      "Epoch 672/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8627 - accuracy: 0.7914 - val_loss: 0.9267 - val_accuracy: 0.7610\n",
      "Epoch 673/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8615 - accuracy: 0.7920 - val_loss: 0.9183 - val_accuracy: 0.7790\n",
      "Epoch 674/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8616 - accuracy: 0.7932 - val_loss: 0.9223 - val_accuracy: 0.7630\n",
      "Epoch 675/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8611 - accuracy: 0.7946 - val_loss: 0.9475 - val_accuracy: 0.7580\n",
      "Epoch 676/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8605 - accuracy: 0.7960 - val_loss: 0.9355 - val_accuracy: 0.7630\n",
      "Epoch 677/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8590 - accuracy: 0.7937 - val_loss: 0.9243 - val_accuracy: 0.7790\n",
      "Epoch 678/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8600 - accuracy: 0.7972 - val_loss: 0.9269 - val_accuracy: 0.7680\n",
      "Epoch 679/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8623 - accuracy: 0.7918 - val_loss: 0.9259 - val_accuracy: 0.7680\n",
      "Epoch 680/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8615 - accuracy: 0.7923 - val_loss: 0.9323 - val_accuracy: 0.7700\n",
      "Epoch 681/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8610 - accuracy: 0.7917 - val_loss: 0.9435 - val_accuracy: 0.7540\n",
      "Epoch 682/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8627 - accuracy: 0.7926 - val_loss: 0.9284 - val_accuracy: 0.7690\n",
      "Epoch 683/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8599 - accuracy: 0.7932 - val_loss: 0.9222 - val_accuracy: 0.7700\n",
      "Epoch 684/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8589 - accuracy: 0.7915 - val_loss: 0.9161 - val_accuracy: 0.7800\n",
      "Epoch 685/1000\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8577 - accuracy: 0.7963 - val_loss: 0.9361 - val_accuracy: 0.7480\n",
      "Epoch 686/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8574 - accuracy: 0.7952 - val_loss: 0.9263 - val_accuracy: 0.7650\n",
      "Epoch 687/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8580 - accuracy: 0.7943 - val_loss: 0.9155 - val_accuracy: 0.7760\n",
      "Epoch 688/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8580 - accuracy: 0.7958 - val_loss: 0.9304 - val_accuracy: 0.7610\n",
      "Epoch 689/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8567 - accuracy: 0.7931 - val_loss: 0.9379 - val_accuracy: 0.7620\n",
      "Epoch 690/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8592 - accuracy: 0.7925 - val_loss: 0.9152 - val_accuracy: 0.7700\n",
      "Epoch 691/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8582 - accuracy: 0.7908 - val_loss: 0.9221 - val_accuracy: 0.7660\n",
      "Epoch 692/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8595 - accuracy: 0.7934 - val_loss: 0.9244 - val_accuracy: 0.7600\n",
      "Epoch 693/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8570 - accuracy: 0.7952 - val_loss: 0.9405 - val_accuracy: 0.7570\n",
      "Epoch 694/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8576 - accuracy: 0.7965 - val_loss: 0.9228 - val_accuracy: 0.7650\n",
      "Epoch 695/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.79 - 0s 28us/step - loss: 0.8555 - accuracy: 0.7949 - val_loss: 0.9216 - val_accuracy: 0.7720\n",
      "Epoch 696/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8605 - accuracy: 0.7940 - val_loss: 0.9160 - val_accuracy: 0.7710\n",
      "Epoch 697/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8558 - accuracy: 0.7943 - val_loss: 0.9156 - val_accuracy: 0.7750\n",
      "Epoch 698/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8552 - accuracy: 0.7960 - val_loss: 0.9118 - val_accuracy: 0.7740\n",
      "Epoch 699/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8563 - accuracy: 0.7945 - val_loss: 0.9251 - val_accuracy: 0.7670\n",
      "Epoch 700/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8535 - accuracy: 0.7952 - val_loss: 0.9345 - val_accuracy: 0.7620\n",
      "Epoch 701/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8551 - accuracy: 0.7912 - val_loss: 0.9388 - val_accuracy: 0.7640\n",
      "Epoch 702/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8549 - accuracy: 0.7925 - val_loss: 0.9177 - val_accuracy: 0.7700\n",
      "Epoch 703/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8566 - accuracy: 0.7963 - val_loss: 0.9270 - val_accuracy: 0.7670\n",
      "Epoch 704/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8553 - accuracy: 0.7957 - val_loss: 0.9213 - val_accuracy: 0.7690\n",
      "Epoch 705/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8555 - accuracy: 0.7911 - val_loss: 0.9360 - val_accuracy: 0.7660\n",
      "Epoch 706/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8536 - accuracy: 0.80 - 0s 27us/step - loss: 0.8546 - accuracy: 0.7968 - val_loss: 0.9141 - val_accuracy: 0.7730\n",
      "Epoch 707/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8514 - accuracy: 0.7962 - val_loss: 0.9300 - val_accuracy: 0.7730\n",
      "Epoch 708/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8567 - accuracy: 0.7954 - val_loss: 0.9343 - val_accuracy: 0.7690\n",
      "Epoch 709/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8519 - accuracy: 0.7948 - val_loss: 0.9379 - val_accuracy: 0.7560\n",
      "Epoch 710/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8531 - accuracy: 0.7975 - val_loss: 0.9149 - val_accuracy: 0.7720\n",
      "Epoch 711/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8531 - accuracy: 0.7922 - val_loss: 0.9151 - val_accuracy: 0.7730\n",
      "Epoch 712/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8507 - accuracy: 0.7938 - val_loss: 0.9373 - val_accuracy: 0.7580\n",
      "Epoch 713/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8529 - accuracy: 0.7969 - val_loss: 0.9121 - val_accuracy: 0.7730\n",
      "Epoch 714/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8566 - accuracy: 0.7954 - val_loss: 0.9172 - val_accuracy: 0.7770\n",
      "Epoch 715/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8520 - accuracy: 0.7955 - val_loss: 0.9501 - val_accuracy: 0.7600\n",
      "Epoch 716/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8535 - accuracy: 0.7951 - val_loss: 0.9210 - val_accuracy: 0.7710\n",
      "Epoch 717/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8537 - accuracy: 0.7937 - val_loss: 0.9172 - val_accuracy: 0.7770\n",
      "Epoch 718/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8515 - accuracy: 0.7975 - val_loss: 0.9220 - val_accuracy: 0.7760\n",
      "Epoch 719/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8546 - accuracy: 0.7952 - val_loss: 0.9178 - val_accuracy: 0.7680\n",
      "Epoch 720/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8503 - accuracy: 0.7977 - val_loss: 0.9270 - val_accuracy: 0.7650\n",
      "Epoch 721/1000\n",
      "6500/6500 [==============================] - 0s 35us/step - loss: 0.8489 - accuracy: 0.8014 - val_loss: 0.9167 - val_accuracy: 0.7700\n",
      "Epoch 722/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8507 - accuracy: 0.7972 - val_loss: 0.9185 - val_accuracy: 0.7710\n",
      "Epoch 723/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8484 - accuracy: 0.7992 - val_loss: 0.9227 - val_accuracy: 0.7660\n",
      "Epoch 724/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8482 - accuracy: 0.7965 - val_loss: 0.9235 - val_accuracy: 0.7620\n",
      "Epoch 725/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8500 - accuracy: 0.7949 - val_loss: 0.9484 - val_accuracy: 0.7500\n",
      "Epoch 726/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8507 - accuracy: 0.7974 - val_loss: 0.9278 - val_accuracy: 0.7710\n",
      "Epoch 727/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8494 - accuracy: 0.7966 - val_loss: 0.9331 - val_accuracy: 0.7660\n",
      "Epoch 728/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8490 - accuracy: 0.8002 - val_loss: 0.9110 - val_accuracy: 0.7640\n",
      "Epoch 729/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8477 - accuracy: 0.7974 - val_loss: 0.9149 - val_accuracy: 0.7680\n",
      "Epoch 730/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8463 - accuracy: 0.8003 - val_loss: 0.9130 - val_accuracy: 0.7720\n",
      "Epoch 731/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8510 - accuracy: 0.7975 - val_loss: 0.9536 - val_accuracy: 0.7480\n",
      "Epoch 732/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8488 - accuracy: 0.7983 - val_loss: 0.9169 - val_accuracy: 0.7730\n",
      "Epoch 733/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8483 - accuracy: 0.7971 - val_loss: 0.9265 - val_accuracy: 0.7670\n",
      "Epoch 734/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8484 - accuracy: 0.7997 - val_loss: 0.9112 - val_accuracy: 0.7790\n",
      "Epoch 735/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8452 - accuracy: 0.8000 - val_loss: 0.9101 - val_accuracy: 0.7720\n",
      "Epoch 736/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8453 - accuracy: 0.7974 - val_loss: 0.9067 - val_accuracy: 0.7720\n",
      "Epoch 737/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8493 - accuracy: 0.7966 - val_loss: 0.9579 - val_accuracy: 0.7550\n",
      "Epoch 738/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8502 - accuracy: 0.8000 - val_loss: 0.9174 - val_accuracy: 0.7660\n",
      "Epoch 739/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.80 - 0s 28us/step - loss: 0.8445 - accuracy: 0.8000 - val_loss: 0.9146 - val_accuracy: 0.7740\n",
      "Epoch 740/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8499 - accuracy: 0.7980 - val_loss: 0.9148 - val_accuracy: 0.7750\n",
      "Epoch 741/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8467 - accuracy: 0.8008 - val_loss: 0.9372 - val_accuracy: 0.7590\n",
      "Epoch 742/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8459 - accuracy: 0.7954 - val_loss: 0.9185 - val_accuracy: 0.7730\n",
      "Epoch 743/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8470 - accuracy: 0.7992 - val_loss: 0.9306 - val_accuracy: 0.7550\n",
      "Epoch 744/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8465 - accuracy: 0.7974 - val_loss: 0.9173 - val_accuracy: 0.7720\n",
      "Epoch 745/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8458 - accuracy: 0.8006 - val_loss: 0.9123 - val_accuracy: 0.7710\n",
      "Epoch 746/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8432 - accuracy: 0.7989 - val_loss: 0.9204 - val_accuracy: 0.7720\n",
      "Epoch 747/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8454 - accuracy: 0.7957 - val_loss: 0.9177 - val_accuracy: 0.7660\n",
      "Epoch 748/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8428 - accuracy: 0.8025 - val_loss: 0.9175 - val_accuracy: 0.7750\n",
      "Epoch 749/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8427 - accuracy: 0.7988 - val_loss: 0.9295 - val_accuracy: 0.7630\n",
      "Epoch 750/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8457 - accuracy: 0.7971 - val_loss: 0.9113 - val_accuracy: 0.7710\n",
      "Epoch 751/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8447 - accuracy: 0.7997 - val_loss: 0.9146 - val_accuracy: 0.7760\n",
      "Epoch 752/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8437 - accuracy: 0.7994 - val_loss: 0.9196 - val_accuracy: 0.7770\n",
      "Epoch 753/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8419 - accuracy: 0.7985 - val_loss: 0.9092 - val_accuracy: 0.7830\n",
      "Epoch 754/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8435 - accuracy: 0.8015 - val_loss: 0.9486 - val_accuracy: 0.7490\n",
      "Epoch 755/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8482 - accuracy: 0.7975 - val_loss: 0.9225 - val_accuracy: 0.7710\n",
      "Epoch 756/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8435 - accuracy: 0.8018 - val_loss: 0.9147 - val_accuracy: 0.7720\n",
      "Epoch 757/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8415 - accuracy: 0.8009 - val_loss: 0.9222 - val_accuracy: 0.7680\n",
      "Epoch 758/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8405 - accuracy: 0.8011 - val_loss: 0.9124 - val_accuracy: 0.7660\n",
      "Epoch 759/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8405 - accuracy: 0.7972 - val_loss: 0.9105 - val_accuracy: 0.7710\n",
      "Epoch 760/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8414 - accuracy: 0.8035 - val_loss: 0.9212 - val_accuracy: 0.7650\n",
      "Epoch 761/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8425 - accuracy: 0.7978 - val_loss: 0.9127 - val_accuracy: 0.7730\n",
      "Epoch 762/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8405 - accuracy: 0.8026 - val_loss: 0.9080 - val_accuracy: 0.7720\n",
      "Epoch 763/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8411 - accuracy: 0.7994 - val_loss: 0.9116 - val_accuracy: 0.7660\n",
      "Epoch 764/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8407 - accuracy: 0.8032 - val_loss: 0.9078 - val_accuracy: 0.7800\n",
      "Epoch 765/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8441 - accuracy: 0.7980 - val_loss: 0.9182 - val_accuracy: 0.7700\n",
      "Epoch 766/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8389 - accuracy: 0.8008 - val_loss: 0.9254 - val_accuracy: 0.7660\n",
      "Epoch 767/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8402 - accuracy: 0.8023 - val_loss: 0.9061 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8420 - accuracy: 0.8035 - val_loss: 0.9146 - val_accuracy: 0.7670\n",
      "Epoch 769/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8401 - accuracy: 0.8005 - val_loss: 0.9191 - val_accuracy: 0.7690\n",
      "Epoch 770/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8396 - accuracy: 0.8008 - val_loss: 0.9108 - val_accuracy: 0.7740\n",
      "Epoch 771/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8402 - accuracy: 0.7986 - val_loss: 0.9397 - val_accuracy: 0.7570\n",
      "Epoch 772/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8435 - accuracy: 0.7998 - val_loss: 0.9116 - val_accuracy: 0.7770\n",
      "Epoch 773/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8401 - accuracy: 0.8005 - val_loss: 0.9092 - val_accuracy: 0.7780\n",
      "Epoch 774/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8401 - accuracy: 0.8005 - val_loss: 0.9080 - val_accuracy: 0.7670\n",
      "Epoch 775/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8377 - accuracy: 0.8046 - val_loss: 0.9170 - val_accuracy: 0.7690\n",
      "Epoch 776/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8388 - accuracy: 0.8006 - val_loss: 0.9130 - val_accuracy: 0.7750\n",
      "Epoch 777/1000\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.8383 - accuracy: 0.8052 - val_loss: 0.9149 - val_accuracy: 0.7650\n",
      "Epoch 778/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8408 - accuracy: 0.8002 - val_loss: 0.9067 - val_accuracy: 0.7740\n",
      "Epoch 779/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8381 - accuracy: 0.8009 - val_loss: 0.9104 - val_accuracy: 0.7810\n",
      "Epoch 780/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8365 - accuracy: 0.8037 - val_loss: 0.9294 - val_accuracy: 0.7690\n",
      "Epoch 781/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8392 - accuracy: 0.8003 - val_loss: 0.9340 - val_accuracy: 0.7520\n",
      "Epoch 782/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8421 - accuracy: 0.8012 - val_loss: 0.9056 - val_accuracy: 0.7790\n",
      "Epoch 783/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8377 - accuracy: 0.8029 - val_loss: 0.9097 - val_accuracy: 0.7780\n",
      "Epoch 784/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8369 - accuracy: 0.8032 - val_loss: 0.9050 - val_accuracy: 0.7700\n",
      "Epoch 785/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8397 - accuracy: 0.8014 - val_loss: 0.9094 - val_accuracy: 0.7680\n",
      "Epoch 786/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8354 - accuracy: 0.8040 - val_loss: 0.9131 - val_accuracy: 0.7650\n",
      "Epoch 787/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8379 - accuracy: 0.8026 - val_loss: 0.9198 - val_accuracy: 0.7770\n",
      "Epoch 788/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8374 - accuracy: 0.8034 - val_loss: 0.9355 - val_accuracy: 0.7600\n",
      "Epoch 789/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8368 - accuracy: 0.8042 - val_loss: 0.9061 - val_accuracy: 0.7680\n",
      "Epoch 790/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8376 - accuracy: 0.8012 - val_loss: 0.9167 - val_accuracy: 0.7700\n",
      "Epoch 791/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8375 - accuracy: 0.8009 - val_loss: 0.9589 - val_accuracy: 0.7500\n",
      "Epoch 792/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8389 - accuracy: 0.8028 - val_loss: 0.9147 - val_accuracy: 0.7740\n",
      "Epoch 793/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8338 - accuracy: 0.8028 - val_loss: 0.9383 - val_accuracy: 0.7600\n",
      "Epoch 794/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8364 - accuracy: 0.8065 - val_loss: 0.9384 - val_accuracy: 0.7540\n",
      "Epoch 795/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8352 - accuracy: 0.8015 - val_loss: 0.9187 - val_accuracy: 0.7620\n",
      "Epoch 796/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8379 - accuracy: 0.8063 - val_loss: 0.9090 - val_accuracy: 0.7780\n",
      "Epoch 797/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8327 - accuracy: 0.8052 - val_loss: 0.9442 - val_accuracy: 0.7540\n",
      "Epoch 798/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8353 - accuracy: 0.8055 - val_loss: 0.9162 - val_accuracy: 0.7700\n",
      "Epoch 799/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8322 - accuracy: 0.8068 - val_loss: 0.9376 - val_accuracy: 0.7610\n",
      "Epoch 800/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8339 - accuracy: 0.8012 - val_loss: 0.9227 - val_accuracy: 0.7610\n",
      "Epoch 801/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8342 - accuracy: 0.8035 - val_loss: 0.9202 - val_accuracy: 0.7690\n",
      "Epoch 802/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8364 - accuracy: 0.8012 - val_loss: 0.9399 - val_accuracy: 0.7600\n",
      "Epoch 803/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8342 - accuracy: 0.8003 - val_loss: 0.9471 - val_accuracy: 0.7550\n",
      "Epoch 804/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8348 - accuracy: 0.8046 - val_loss: 0.9081 - val_accuracy: 0.7790\n",
      "Epoch 805/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8303 - accuracy: 0.8055 - val_loss: 0.9571 - val_accuracy: 0.7580\n",
      "Epoch 806/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8372 - accuracy: 0.8043 - val_loss: 0.9407 - val_accuracy: 0.7560\n",
      "Epoch 807/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8342 - accuracy: 0.8031 - val_loss: 0.9105 - val_accuracy: 0.7680\n",
      "Epoch 808/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8366 - accuracy: 0.8049 - val_loss: 0.9101 - val_accuracy: 0.7740\n",
      "Epoch 809/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8325 - accuracy: 0.8052 - val_loss: 0.9346 - val_accuracy: 0.7590\n",
      "Epoch 810/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8326 - accuracy: 0.8068 - val_loss: 0.9175 - val_accuracy: 0.7670\n",
      "Epoch 811/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8312 - accuracy: 0.8046 - val_loss: 0.9569 - val_accuracy: 0.7510\n",
      "Epoch 812/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8330 - accuracy: 0.8045 - val_loss: 0.9049 - val_accuracy: 0.7770\n",
      "Epoch 813/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8356 - accuracy: 0.8043 - val_loss: 0.9101 - val_accuracy: 0.7720\n",
      "Epoch 814/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8340 - accuracy: 0.8029 - val_loss: 0.9446 - val_accuracy: 0.7630\n",
      "Epoch 815/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8304 - accuracy: 0.8071 - val_loss: 0.9083 - val_accuracy: 0.7790\n",
      "Epoch 816/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8318 - accuracy: 0.8037 - val_loss: 0.9389 - val_accuracy: 0.7620\n",
      "Epoch 817/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8343 - accuracy: 0.8034 - val_loss: 0.9107 - val_accuracy: 0.7800\n",
      "Epoch 818/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8293 - accuracy: 0.8051 - val_loss: 0.9492 - val_accuracy: 0.7550\n",
      "Epoch 819/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8321 - accuracy: 0.8043 - val_loss: 0.9067 - val_accuracy: 0.7740\n",
      "Epoch 820/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8326 - accuracy: 0.8025 - val_loss: 0.9076 - val_accuracy: 0.7730\n",
      "Epoch 821/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8302 - accuracy: 0.8052 - val_loss: 0.9042 - val_accuracy: 0.7720\n",
      "Epoch 822/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8293 - accuracy: 0.8062 - val_loss: 0.9097 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8295 - accuracy: 0.8028 - val_loss: 0.9157 - val_accuracy: 0.7670\n",
      "Epoch 824/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8290 - accuracy: 0.8077 - val_loss: 0.9085 - val_accuracy: 0.7730\n",
      "Epoch 825/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8329 - accuracy: 0.8032 - val_loss: 0.9276 - val_accuracy: 0.7750\n",
      "Epoch 826/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8308 - accuracy: 0.80 - 0s 28us/step - loss: 0.8331 - accuracy: 0.8017 - val_loss: 0.9044 - val_accuracy: 0.7680\n",
      "Epoch 827/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8284 - accuracy: 0.8054 - val_loss: 0.9068 - val_accuracy: 0.7780\n",
      "Epoch 828/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8296 - accuracy: 0.8062 - val_loss: 0.9100 - val_accuracy: 0.7720\n",
      "Epoch 829/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8289 - accuracy: 0.8062 - val_loss: 0.9088 - val_accuracy: 0.7800\n",
      "Epoch 830/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8293 - accuracy: 0.8068 - val_loss: 0.9093 - val_accuracy: 0.7690\n",
      "Epoch 831/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8304 - accuracy: 0.8075 - val_loss: 0.9056 - val_accuracy: 0.7820\n",
      "Epoch 832/1000\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.8319 - accuracy: 0.8066 - val_loss: 0.9251 - val_accuracy: 0.7580\n",
      "Epoch 833/1000\n",
      "6500/6500 [==============================] - 0s 31us/step - loss: 0.8289 - accuracy: 0.8045 - val_loss: 0.9053 - val_accuracy: 0.7780\n",
      "Epoch 834/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8276 - accuracy: 0.8085 - val_loss: 0.9232 - val_accuracy: 0.7670\n",
      "Epoch 835/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8270 - accuracy: 0.8068 - val_loss: 0.9043 - val_accuracy: 0.7720\n",
      "Epoch 836/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8261 - accuracy: 0.8058 - val_loss: 0.9258 - val_accuracy: 0.7670\n",
      "Epoch 837/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8302 - accuracy: 0.8051 - val_loss: 0.9966 - val_accuracy: 0.7410\n",
      "Epoch 838/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8329 - accuracy: 0.8062 - val_loss: 0.9111 - val_accuracy: 0.7740\n",
      "Epoch 839/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8306 - accuracy: 0.8049 - val_loss: 0.9231 - val_accuracy: 0.7640\n",
      "Epoch 840/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8306 - accuracy: 0.8071 - val_loss: 0.9131 - val_accuracy: 0.7810\n",
      "Epoch 841/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8275 - accuracy: 0.8089 - val_loss: 0.9166 - val_accuracy: 0.7720\n",
      "Epoch 842/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8273 - accuracy: 0.8068 - val_loss: 0.9112 - val_accuracy: 0.7680\n",
      "Epoch 843/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8333 - accuracy: 0.8020 - val_loss: 0.9434 - val_accuracy: 0.7560\n",
      "Epoch 844/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8285 - accuracy: 0.8063 - val_loss: 0.9062 - val_accuracy: 0.7730\n",
      "Epoch 845/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8250 - accuracy: 0.8071 - val_loss: 0.9016 - val_accuracy: 0.7700\n",
      "Epoch 846/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8287 - accuracy: 0.8048 - val_loss: 0.9421 - val_accuracy: 0.7540\n",
      "Epoch 847/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8305 - accuracy: 0.8055 - val_loss: 0.9126 - val_accuracy: 0.7800\n",
      "Epoch 848/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8275 - accuracy: 0.8085 - val_loss: 0.9689 - val_accuracy: 0.7430\n",
      "Epoch 849/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8258 - accuracy: 0.8069 - val_loss: 0.9338 - val_accuracy: 0.7600\n",
      "Epoch 850/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8275 - accuracy: 0.8074 - val_loss: 0.9170 - val_accuracy: 0.7700\n",
      "Epoch 851/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8245 - accuracy: 0.8083 - val_loss: 0.9230 - val_accuracy: 0.7710\n",
      "Epoch 852/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8255 - accuracy: 0.8085 - val_loss: 0.9217 - val_accuracy: 0.7730\n",
      "Epoch 853/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8234 - accuracy: 0.8082 - val_loss: 0.9094 - val_accuracy: 0.7810\n",
      "Epoch 854/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8284 - accuracy: 0.8069 - val_loss: 0.9301 - val_accuracy: 0.7720\n",
      "Epoch 855/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8286 - accuracy: 0.8031 - val_loss: 0.9035 - val_accuracy: 0.7780\n",
      "Epoch 856/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8249 - accuracy: 0.8103 - val_loss: 0.9233 - val_accuracy: 0.7640\n",
      "Epoch 857/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8249 - accuracy: 0.8054 - val_loss: 0.9080 - val_accuracy: 0.7770\n",
      "Epoch 858/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8241 - accuracy: 0.8092 - val_loss: 0.9055 - val_accuracy: 0.7710\n",
      "Epoch 859/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8225 - accuracy: 0.8106 - val_loss: 0.9118 - val_accuracy: 0.7640\n",
      "Epoch 860/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8261 - accuracy: 0.8077 - val_loss: 0.9159 - val_accuracy: 0.7660\n",
      "Epoch 861/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8216 - accuracy: 0.8103 - val_loss: 0.9187 - val_accuracy: 0.7790\n",
      "Epoch 862/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8248 - accuracy: 0.8075 - val_loss: 0.9147 - val_accuracy: 0.7710\n",
      "Epoch 863/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8221 - accuracy: 0.8111 - val_loss: 0.9157 - val_accuracy: 0.7720\n",
      "Epoch 864/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8197 - accuracy: 0.8094 - val_loss: 0.9059 - val_accuracy: 0.7780\n",
      "Epoch 865/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8244 - accuracy: 0.8105 - val_loss: 0.9112 - val_accuracy: 0.7790\n",
      "Epoch 866/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8225 - accuracy: 0.8063 - val_loss: 0.9149 - val_accuracy: 0.7680\n",
      "Epoch 867/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8218 - accuracy: 0.8080 - val_loss: 0.9091 - val_accuracy: 0.7760\n",
      "Epoch 868/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8207 - accuracy: 0.8089 - val_loss: 0.9382 - val_accuracy: 0.7680\n",
      "Epoch 869/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8228 - accuracy: 0.8078 - val_loss: 0.9039 - val_accuracy: 0.7720\n",
      "Epoch 870/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8239 - accuracy: 0.8065 - val_loss: 0.9326 - val_accuracy: 0.7790\n",
      "Epoch 871/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8310 - accuracy: 0.8062 - val_loss: 0.9541 - val_accuracy: 0.7560\n",
      "Epoch 872/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8202 - accuracy: 0.8135 - val_loss: 0.9218 - val_accuracy: 0.7670\n",
      "Epoch 873/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8216 - accuracy: 0.8112 - val_loss: 0.9299 - val_accuracy: 0.7630\n",
      "Epoch 874/1000\n",
      "6500/6500 [==============================] - 0s 30us/step - loss: 0.8200 - accuracy: 0.8080 - val_loss: 0.9204 - val_accuracy: 0.7800\n",
      "Epoch 875/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8211 - accuracy: 0.8092 - val_loss: 0.9856 - val_accuracy: 0.7440\n",
      "Epoch 876/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8234 - accuracy: 0.8086 - val_loss: 0.9087 - val_accuracy: 0.7830\n",
      "Epoch 877/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8225 - accuracy: 0.8091 - val_loss: 0.9118 - val_accuracy: 0.7740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 878/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8162 - accuracy: 0.8122 - val_loss: 0.9104 - val_accuracy: 0.7730\n",
      "Epoch 879/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8234 - accuracy: 0.8100 - val_loss: 0.9059 - val_accuracy: 0.7820\n",
      "Epoch 880/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8224 - accuracy: 0.8109 - val_loss: 0.9127 - val_accuracy: 0.7840\n",
      "Epoch 881/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8176 - accuracy: 0.8085 - val_loss: 0.9053 - val_accuracy: 0.7810\n",
      "Epoch 882/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8214 - accuracy: 0.8102 - val_loss: 0.9266 - val_accuracy: 0.7650\n",
      "Epoch 883/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8242 - accuracy: 0.8054 - val_loss: 0.9174 - val_accuracy: 0.7800\n",
      "Epoch 884/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8219 - accuracy: 0.8034 - val_loss: 0.9246 - val_accuracy: 0.7650\n",
      "Epoch 885/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8212 - accuracy: 0.8083 - val_loss: 0.9060 - val_accuracy: 0.7790\n",
      "Epoch 886/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8188 - accuracy: 0.8091 - val_loss: 0.9328 - val_accuracy: 0.7620\n",
      "Epoch 887/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8238 - accuracy: 0.8078 - val_loss: 0.9160 - val_accuracy: 0.7760\n",
      "Epoch 888/1000\n",
      "6500/6500 [==============================] - 0s 37us/step - loss: 0.8211 - accuracy: 0.8071 - val_loss: 0.9152 - val_accuracy: 0.7850\n",
      "Epoch 889/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8219 - accuracy: 0.8088 - val_loss: 0.9045 - val_accuracy: 0.7790\n",
      "Epoch 890/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8187 - accuracy: 0.8126 - val_loss: 0.9166 - val_accuracy: 0.7700\n",
      "Epoch 891/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8272 - accuracy: 0.8072 - val_loss: 0.9149 - val_accuracy: 0.7780\n",
      "Epoch 892/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8194 - accuracy: 0.8086 - val_loss: 1.0154 - val_accuracy: 0.7500\n",
      "Epoch 893/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8296 - accuracy: 0.8057 - val_loss: 0.9338 - val_accuracy: 0.7520\n",
      "Epoch 894/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8226 - accuracy: 0.8115 - val_loss: 0.9672 - val_accuracy: 0.7510\n",
      "Epoch 895/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8167 - accuracy: 0.8157 - val_loss: 0.9116 - val_accuracy: 0.7710\n",
      "Epoch 896/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8186 - accuracy: 0.8108 - val_loss: 0.9176 - val_accuracy: 0.7660\n",
      "Epoch 897/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8150 - accuracy: 0.8134 - val_loss: 0.9028 - val_accuracy: 0.7730\n",
      "Epoch 898/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8165 - accuracy: 0.8128 - val_loss: 0.9834 - val_accuracy: 0.7360\n",
      "Epoch 899/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8208 - accuracy: 0.8100 - val_loss: 0.9533 - val_accuracy: 0.7650\n",
      "Epoch 900/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8184 - accuracy: 0.8109 - val_loss: 0.9099 - val_accuracy: 0.7800\n",
      "Epoch 901/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8231 - accuracy: 0.8032 - val_loss: 0.9520 - val_accuracy: 0.7520\n",
      "Epoch 902/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8141 - accuracy: 0.8129 - val_loss: 0.9368 - val_accuracy: 0.7710\n",
      "Epoch 903/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8188 - accuracy: 0.8097 - val_loss: 0.9436 - val_accuracy: 0.7740\n",
      "Epoch 904/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8191 - accuracy: 0.8109 - val_loss: 0.9138 - val_accuracy: 0.7760\n",
      "Epoch 905/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8239 - accuracy: 0.8062 - val_loss: 0.9513 - val_accuracy: 0.7560\n",
      "Epoch 906/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8298 - accuracy: 0.8052 - val_loss: 0.9057 - val_accuracy: 0.7740\n",
      "Epoch 907/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8090 - accuracy: 0.81 - 0s 27us/step - loss: 0.8214 - accuracy: 0.8098 - val_loss: 0.9213 - val_accuracy: 0.7760\n",
      "Epoch 908/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8165 - accuracy: 0.8098 - val_loss: 0.9076 - val_accuracy: 0.7810\n",
      "Epoch 909/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8134 - accuracy: 0.8122 - val_loss: 0.9104 - val_accuracy: 0.7870\n",
      "Epoch 910/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8186 - accuracy: 0.8097 - val_loss: 0.9625 - val_accuracy: 0.7560\n",
      "Epoch 911/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8226 - accuracy: 0.8048 - val_loss: 0.9299 - val_accuracy: 0.7590\n",
      "Epoch 912/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8149 - accuracy: 0.8129 - val_loss: 0.9351 - val_accuracy: 0.7660\n",
      "Epoch 913/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8259 - accuracy: 0.8045 - val_loss: 0.9110 - val_accuracy: 0.7710\n",
      "Epoch 914/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8204 - accuracy: 0.8083 - val_loss: 0.9149 - val_accuracy: 0.7730\n",
      "Epoch 915/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8198 - accuracy: 0.8062 - val_loss: 0.9068 - val_accuracy: 0.7800\n",
      "Epoch 916/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8136 - accuracy: 0.8123 - val_loss: 0.9096 - val_accuracy: 0.7790\n",
      "Epoch 917/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8139 - accuracy: 0.8160 - val_loss: 0.9199 - val_accuracy: 0.7680\n",
      "Epoch 918/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8212 - accuracy: 0.8129 - val_loss: 0.9114 - val_accuracy: 0.7820\n",
      "Epoch 919/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8134 - accuracy: 0.8132 - val_loss: 0.9108 - val_accuracy: 0.7790\n",
      "Epoch 920/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8139 - accuracy: 0.8163 - val_loss: 0.9066 - val_accuracy: 0.7900\n",
      "Epoch 921/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8118 - accuracy: 0.8158 - val_loss: 0.9139 - val_accuracy: 0.7690\n",
      "Epoch 922/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8194 - accuracy: 0.8115 - val_loss: 0.9201 - val_accuracy: 0.7850\n",
      "Epoch 923/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8115 - accuracy: 0.8125 - val_loss: 0.9333 - val_accuracy: 0.7810\n",
      "Epoch 924/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8137 - accuracy: 0.8140 - val_loss: 0.9390 - val_accuracy: 0.7620\n",
      "Epoch 925/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8198 - accuracy: 0.8095 - val_loss: 0.9168 - val_accuracy: 0.7680\n",
      "Epoch 926/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8184 - accuracy: 0.8103 - val_loss: 0.9304 - val_accuracy: 0.7810\n",
      "Epoch 927/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8141 - accuracy: 0.8135 - val_loss: 0.9092 - val_accuracy: 0.7790\n",
      "Epoch 928/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8122 - accuracy: 0.8143 - val_loss: 0.9038 - val_accuracy: 0.7940\n",
      "Epoch 929/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8101 - accuracy: 0.8138 - val_loss: 0.9107 - val_accuracy: 0.7820\n",
      "Epoch 930/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8119 - accuracy: 0.8122 - val_loss: 0.9116 - val_accuracy: 0.7880\n",
      "Epoch 931/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8091 - accuracy: 0.8157 - val_loss: 0.9946 - val_accuracy: 0.7250\n",
      "Epoch 932/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8186 - accuracy: 0.8069 - val_loss: 0.9205 - val_accuracy: 0.7740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 933/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8100 - accuracy: 0.8157 - val_loss: 0.9159 - val_accuracy: 0.7720\n",
      "Epoch 934/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8162 - accuracy: 0.8097 - val_loss: 0.9135 - val_accuracy: 0.7840\n",
      "Epoch 935/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8199 - accuracy: 0.8106 - val_loss: 0.9061 - val_accuracy: 0.7820\n",
      "Epoch 936/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8104 - accuracy: 0.8137 - val_loss: 0.9219 - val_accuracy: 0.7800\n",
      "Epoch 937/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8136 - accuracy: 0.8129 - val_loss: 0.9031 - val_accuracy: 0.7790\n",
      "Epoch 938/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8058 - accuracy: 0.8142 - val_loss: 0.9515 - val_accuracy: 0.7550\n",
      "Epoch 939/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8210 - accuracy: 0.8102 - val_loss: 0.9363 - val_accuracy: 0.7700\n",
      "Epoch 940/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8191 - accuracy: 0.8108 - val_loss: 0.9103 - val_accuracy: 0.7820\n",
      "Epoch 941/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8111 - accuracy: 0.8125 - val_loss: 0.9261 - val_accuracy: 0.7840\n",
      "Epoch 942/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8104 - accuracy: 0.8146 - val_loss: 0.9181 - val_accuracy: 0.7880\n",
      "Epoch 943/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8155 - accuracy: 0.8146 - val_loss: 0.9201 - val_accuracy: 0.7710\n",
      "Epoch 944/1000\n",
      "6500/6500 [==============================] - 0s 36us/step - loss: 0.8114 - accuracy: 0.8140 - val_loss: 0.9111 - val_accuracy: 0.7710\n",
      "Epoch 945/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8129 - accuracy: 0.8135 - val_loss: 0.9507 - val_accuracy: 0.7550\n",
      "Epoch 946/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8155 - accuracy: 0.8117 - val_loss: 0.9170 - val_accuracy: 0.7820\n",
      "Epoch 947/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8090 - accuracy: 0.81 - 0s 27us/step - loss: 0.8097 - accuracy: 0.8140 - val_loss: 0.9916 - val_accuracy: 0.7450\n",
      "Epoch 948/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8166 - accuracy: 0.8102 - val_loss: 0.9003 - val_accuracy: 0.7860\n",
      "Epoch 949/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8162 - accuracy: 0.8129 - val_loss: 0.9280 - val_accuracy: 0.7750\n",
      "Epoch 950/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8137 - accuracy: 0.8152 - val_loss: 0.9587 - val_accuracy: 0.7630\n",
      "Epoch 951/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8155 - accuracy: 0.8115 - val_loss: 0.9234 - val_accuracy: 0.7580\n",
      "Epoch 952/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8132 - accuracy: 0.8132 - val_loss: 0.9083 - val_accuracy: 0.7830\n",
      "Epoch 953/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8103 - accuracy: 0.8129 - val_loss: 0.9274 - val_accuracy: 0.7630\n",
      "Epoch 954/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8087 - accuracy: 0.8158 - val_loss: 0.9276 - val_accuracy: 0.7720\n",
      "Epoch 955/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8114 - accuracy: 0.8126 - val_loss: 0.9225 - val_accuracy: 0.7810\n",
      "Epoch 956/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8130 - accuracy: 0.8129 - val_loss: 0.9177 - val_accuracy: 0.7700\n",
      "Epoch 957/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8046 - accuracy: 0.8186 - val_loss: 0.9257 - val_accuracy: 0.7630\n",
      "Epoch 958/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8106 - accuracy: 0.8146 - val_loss: 0.9100 - val_accuracy: 0.7840\n",
      "Epoch 959/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8131 - accuracy: 0.8131 - val_loss: 0.9013 - val_accuracy: 0.7850\n",
      "Epoch 960/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8023 - accuracy: 0.8169 - val_loss: 0.9162 - val_accuracy: 0.7780\n",
      "Epoch 961/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8066 - accuracy: 0.8192 - val_loss: 0.9306 - val_accuracy: 0.7560\n",
      "Epoch 962/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8069 - accuracy: 0.8158 - val_loss: 0.9631 - val_accuracy: 0.7590\n",
      "Epoch 963/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8098 - accuracy: 0.8138 - val_loss: 0.9218 - val_accuracy: 0.7770\n",
      "Epoch 964/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8098 - accuracy: 0.8172 - val_loss: 0.9358 - val_accuracy: 0.7610\n",
      "Epoch 965/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8108 - accuracy: 0.8171 - val_loss: 0.9294 - val_accuracy: 0.7640\n",
      "Epoch 966/1000\n",
      "6500/6500 [==============================] - 0s 29us/step - loss: 0.8183 - accuracy: 0.8155 - val_loss: 0.9120 - val_accuracy: 0.7740\n",
      "Epoch 967/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8113 - accuracy: 0.8160 - val_loss: 0.9463 - val_accuracy: 0.7630\n",
      "Epoch 968/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8082 - accuracy: 0.8118 - val_loss: 0.9521 - val_accuracy: 0.7720\n",
      "Epoch 969/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8073 - accuracy: 0.8186 - val_loss: 0.9012 - val_accuracy: 0.7830\n",
      "Epoch 970/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8163 - accuracy: 0.8125 - val_loss: 0.9316 - val_accuracy: 0.7740\n",
      "Epoch 971/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8107 - accuracy: 0.8151 - val_loss: 0.9279 - val_accuracy: 0.7720\n",
      "Epoch 972/1000\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.8191 - accuracy: 0.81 - 0s 28us/step - loss: 0.8151 - accuracy: 0.8105 - val_loss: 0.9253 - val_accuracy: 0.7740\n",
      "Epoch 973/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8028 - accuracy: 0.8158 - val_loss: 0.9023 - val_accuracy: 0.7780\n",
      "Epoch 974/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8060 - accuracy: 0.8145 - val_loss: 0.9429 - val_accuracy: 0.7620\n",
      "Epoch 975/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8088 - accuracy: 0.8152 - val_loss: 0.9243 - val_accuracy: 0.7630\n",
      "Epoch 976/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8174 - accuracy: 0.8118 - val_loss: 0.9220 - val_accuracy: 0.7720\n",
      "Epoch 977/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8066 - accuracy: 0.8171 - val_loss: 0.9061 - val_accuracy: 0.7730\n",
      "Epoch 978/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8050 - accuracy: 0.8171 - val_loss: 0.9025 - val_accuracy: 0.7850\n",
      "Epoch 979/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8116 - accuracy: 0.8128 - val_loss: 0.9504 - val_accuracy: 0.7590\n",
      "Epoch 980/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8023 - accuracy: 0.8157 - val_loss: 0.9084 - val_accuracy: 0.7790\n",
      "Epoch 981/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8077 - accuracy: 0.8183 - val_loss: 0.9403 - val_accuracy: 0.7640\n",
      "Epoch 982/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8143 - accuracy: 0.8157 - val_loss: 0.9489 - val_accuracy: 0.7670\n",
      "Epoch 983/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8163 - accuracy: 0.8108 - val_loss: 0.9106 - val_accuracy: 0.7810\n",
      "Epoch 984/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8121 - accuracy: 0.8112 - val_loss: 0.9090 - val_accuracy: 0.7800\n",
      "Epoch 985/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8012 - accuracy: 0.8151 - val_loss: 0.9481 - val_accuracy: 0.7530\n",
      "Epoch 986/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8049 - accuracy: 0.8177 - val_loss: 0.9160 - val_accuracy: 0.7720\n",
      "Epoch 987/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8051 - accuracy: 0.8168 - val_loss: 0.9212 - val_accuracy: 0.7740\n",
      "Epoch 988/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.7994 - accuracy: 0.8195 - val_loss: 0.9894 - val_accuracy: 0.7570\n",
      "Epoch 989/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8020 - accuracy: 0.8197 - val_loss: 0.9286 - val_accuracy: 0.7560\n",
      "Epoch 990/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8241 - accuracy: 0.8098 - val_loss: 0.9867 - val_accuracy: 0.7450\n",
      "Epoch 991/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8058 - accuracy: 0.8182 - val_loss: 0.9142 - val_accuracy: 0.7840\n",
      "Epoch 992/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8044 - accuracy: 0.8180 - val_loss: 0.9200 - val_accuracy: 0.7830\n",
      "Epoch 993/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8095 - accuracy: 0.8138 - val_loss: 0.9261 - val_accuracy: 0.7630\n",
      "Epoch 994/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8110 - accuracy: 0.8142 - val_loss: 0.9400 - val_accuracy: 0.7730\n",
      "Epoch 995/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8012 - accuracy: 0.8177 - val_loss: 0.9204 - val_accuracy: 0.7680\n",
      "Epoch 996/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.7998 - accuracy: 0.8172 - val_loss: 0.9317 - val_accuracy: 0.7670\n",
      "Epoch 997/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8091 - accuracy: 0.8185 - val_loss: 0.9066 - val_accuracy: 0.7760\n",
      "Epoch 998/1000\n",
      "6500/6500 [==============================] - 0s 27us/step - loss: 0.8073 - accuracy: 0.8154 - val_loss: 0.9503 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "6500/6500 [==============================] - 0s 28us/step - loss: 0.8048 - accuracy: 0.8149 - val_loss: 0.9400 - val_accuracy: 0.7700\n",
      "Epoch 1000/1000\n",
      "6500/6500 [==============================] - 0s 32us/step - loss: 0.8052 - accuracy: 0.8168 - val_loss: 0.9491 - val_accuracy: 0.7680\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_final,\n",
    "                    y_train_final,\n",
    "                    epochs=1000,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 25us/step\n",
      "Training Loss: 0.835 Training Accuracy: 0.808\n",
      "2500/2500 [==============================] - 0s 24us/step\n",
      "Testing Loss: 1.01 Testing Accuracy: 0.736\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_final, y_train_final)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best result you've achieved so far, but you were training for quite a while! Next, experiment with dropout regularization to see if it offers any advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok, y_train_lb = X_train_final, y_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6500 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "6500/6500 [==============================] - 0s 61us/step - loss: 1.9973 - accuracy: 0.1531 - val_loss: 1.9330 - val_accuracy: 0.1490\n",
      "Epoch 2/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.9581 - accuracy: 0.1612 - val_loss: 1.9205 - val_accuracy: 0.1770\n",
      "Epoch 3/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.9422 - accuracy: 0.1709 - val_loss: 1.9119 - val_accuracy: 0.2120\n",
      "Epoch 4/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.9297 - accuracy: 0.1751 - val_loss: 1.9035 - val_accuracy: 0.2350\n",
      "Epoch 5/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.9208 - accuracy: 0.1828 - val_loss: 1.8946 - val_accuracy: 0.2550\n",
      "Epoch 6/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.9160 - accuracy: 0.1854 - val_loss: 1.8866 - val_accuracy: 0.2710\n",
      "Epoch 7/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.9021 - accuracy: 0.1917 - val_loss: 1.8766 - val_accuracy: 0.2740\n",
      "Epoch 8/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.8948 - accuracy: 0.1994 - val_loss: 1.8680 - val_accuracy: 0.2850\n",
      "Epoch 9/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.8909 - accuracy: 0.2038 - val_loss: 1.8576 - val_accuracy: 0.2870\n",
      "Epoch 10/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.8809 - accuracy: 0.2208 - val_loss: 1.8462 - val_accuracy: 0.2890\n",
      "Epoch 11/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.8699 - accuracy: 0.2225 - val_loss: 1.8348 - val_accuracy: 0.2990\n",
      "Epoch 12/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.8539 - accuracy: 0.2278 - val_loss: 1.8219 - val_accuracy: 0.3000\n",
      "Epoch 13/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.8513 - accuracy: 0.2398 - val_loss: 1.8073 - val_accuracy: 0.3020\n",
      "Epoch 14/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.8405 - accuracy: 0.2432 - val_loss: 1.7930 - val_accuracy: 0.3130\n",
      "Epoch 15/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.8290 - accuracy: 0.2451 - val_loss: 1.7792 - val_accuracy: 0.3230\n",
      "Epoch 16/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.8141 - accuracy: 0.2449 - val_loss: 1.7634 - val_accuracy: 0.3290\n",
      "Epoch 17/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.8055 - accuracy: 0.2646 - val_loss: 1.7477 - val_accuracy: 0.3380\n",
      "Epoch 18/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.7938 - accuracy: 0.2762 - val_loss: 1.7312 - val_accuracy: 0.3480\n",
      "Epoch 19/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.7866 - accuracy: 0.2765 - val_loss: 1.7139 - val_accuracy: 0.3710\n",
      "Epoch 20/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.7643 - accuracy: 0.2955 - val_loss: 1.6950 - val_accuracy: 0.3810\n",
      "Epoch 21/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.7545 - accuracy: 0.2902 - val_loss: 1.6753 - val_accuracy: 0.3840\n",
      "Epoch 22/200\n",
      "6500/6500 [==============================] - 0s 56us/step - loss: 1.7456 - accuracy: 0.2969 - val_loss: 1.6571 - val_accuracy: 0.3960\n",
      "Epoch 23/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 1.7253 - accuracy: 0.3125 - val_loss: 1.6370 - val_accuracy: 0.4010\n",
      "Epoch 24/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.7094 - accuracy: 0.3114 - val_loss: 1.6153 - val_accuracy: 0.4080\n",
      "Epoch 25/200\n",
      "6500/6500 [==============================] - 0s 50us/step - loss: 1.6965 - accuracy: 0.3251 - val_loss: 1.5972 - val_accuracy: 0.4180\n",
      "Epoch 26/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.6786 - accuracy: 0.3255 - val_loss: 1.5767 - val_accuracy: 0.4310\n",
      "Epoch 27/200\n",
      "6500/6500 [==============================] - 0s 49us/step - loss: 1.6643 - accuracy: 0.3383 - val_loss: 1.5592 - val_accuracy: 0.4370\n",
      "Epoch 28/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 1.6529 - accuracy: 0.3382 - val_loss: 1.5387 - val_accuracy: 0.4500\n",
      "Epoch 29/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.6321 - accuracy: 0.3566 - val_loss: 1.5174 - val_accuracy: 0.4590\n",
      "Epoch 30/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 1.6235 - accuracy: 0.3571 - val_loss: 1.4989 - val_accuracy: 0.4670\n",
      "Epoch 31/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.6096 - accuracy: 0.3665 - val_loss: 1.4793 - val_accuracy: 0.4760\n",
      "Epoch 32/200\n",
      "6500/6500 [==============================] - 0s 49us/step - loss: 1.5892 - accuracy: 0.3798 - val_loss: 1.4610 - val_accuracy: 0.4880\n",
      "Epoch 33/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 1.5718 - accuracy: 0.3795 - val_loss: 1.4427 - val_accuracy: 0.4980\n",
      "Epoch 34/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 1.5487 - accuracy: 0.3971 - val_loss: 1.4201 - val_accuracy: 0.5130\n",
      "Epoch 35/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.5449 - accuracy: 0.3968 - val_loss: 1.4004 - val_accuracy: 0.5260\n",
      "Epoch 36/200\n",
      "6500/6500 [==============================] - 0s 49us/step - loss: 1.5277 - accuracy: 0.4131 - val_loss: 1.3788 - val_accuracy: 0.5430\n",
      "Epoch 37/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.5180 - accuracy: 0.4109 - val_loss: 1.3611 - val_accuracy: 0.5490\n",
      "Epoch 38/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.5105 - accuracy: 0.4129 - val_loss: 1.3447 - val_accuracy: 0.5570\n",
      "Epoch 39/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.4927 - accuracy: 0.4186 - val_loss: 1.3271 - val_accuracy: 0.5720\n",
      "Epoch 40/200\n",
      "6500/6500 [==============================] - 0s 49us/step - loss: 1.4749 - accuracy: 0.4277 - val_loss: 1.3090 - val_accuracy: 0.5820\n",
      "Epoch 41/200\n",
      "6500/6500 [==============================] - 0s 50us/step - loss: 1.4609 - accuracy: 0.4374 - val_loss: 1.2938 - val_accuracy: 0.5890\n",
      "Epoch 42/200\n",
      "6500/6500 [==============================] - 0s 49us/step - loss: 1.4435 - accuracy: 0.4458 - val_loss: 1.2743 - val_accuracy: 0.6000\n",
      "Epoch 43/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.4467 - accuracy: 0.4391 - val_loss: 1.2630 - val_accuracy: 0.5980\n",
      "Epoch 44/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.4228 - accuracy: 0.4609 - val_loss: 1.2439 - val_accuracy: 0.6000\n",
      "Epoch 45/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.4110 - accuracy: 0.4557 - val_loss: 1.2280 - val_accuracy: 0.6040\n",
      "Epoch 46/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.3867 - accuracy: 0.4695 - val_loss: 1.2104 - val_accuracy: 0.6100\n",
      "Epoch 47/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.3843 - accuracy: 0.4728 - val_loss: 1.1945 - val_accuracy: 0.6240\n",
      "Epoch 48/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.3753 - accuracy: 0.4715 - val_loss: 1.1787 - val_accuracy: 0.6230\n",
      "Epoch 49/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.3442 - accuracy: 0.4880 - val_loss: 1.1611 - val_accuracy: 0.6310\n",
      "Epoch 50/200\n",
      "6500/6500 [==============================] - 0s 50us/step - loss: 1.3386 - accuracy: 0.4926 - val_loss: 1.1487 - val_accuracy: 0.6370\n",
      "Epoch 51/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.3203 - accuracy: 0.5042 - val_loss: 1.1328 - val_accuracy: 0.6370\n",
      "Epoch 52/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.3229 - accuracy: 0.4926 - val_loss: 1.1215 - val_accuracy: 0.6370\n",
      "Epoch 53/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.3135 - accuracy: 0.5018 - val_loss: 1.1043 - val_accuracy: 0.6510\n",
      "Epoch 54/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.2927 - accuracy: 0.5066 - val_loss: 1.0944 - val_accuracy: 0.6520\n",
      "Epoch 55/200\n",
      "6500/6500 [==============================] - 0s 52us/step - loss: 1.3012 - accuracy: 0.5086 - val_loss: 1.0877 - val_accuracy: 0.6470\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.2739 - accuracy: 0.5189 - val_loss: 1.0742 - val_accuracy: 0.6590\n",
      "Epoch 57/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.2801 - accuracy: 0.5111 - val_loss: 1.0615 - val_accuracy: 0.6640\n",
      "Epoch 58/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.2501 - accuracy: 0.5302 - val_loss: 1.0525 - val_accuracy: 0.6680\n",
      "Epoch 59/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.2544 - accuracy: 0.5237 - val_loss: 1.0435 - val_accuracy: 0.6630\n",
      "Epoch 60/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.2464 - accuracy: 0.5248 - val_loss: 1.0329 - val_accuracy: 0.6690\n",
      "Epoch 61/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.2230 - accuracy: 0.5372 - val_loss: 1.0224 - val_accuracy: 0.6690\n",
      "Epoch 62/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.2300 - accuracy: 0.5348 - val_loss: 1.0119 - val_accuracy: 0.6750\n",
      "Epoch 63/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.2090 - accuracy: 0.5397 - val_loss: 0.9994 - val_accuracy: 0.6750\n",
      "Epoch 64/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.2053 - accuracy: 0.5491 - val_loss: 0.9889 - val_accuracy: 0.6860\n",
      "Epoch 65/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1935 - accuracy: 0.5577 - val_loss: 0.9804 - val_accuracy: 0.6910\n",
      "Epoch 66/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.2038 - accuracy: 0.5429 - val_loss: 0.9768 - val_accuracy: 0.6890\n",
      "Epoch 67/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1785 - accuracy: 0.5546 - val_loss: 0.9651 - val_accuracy: 0.6940\n",
      "Epoch 68/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1738 - accuracy: 0.5574 - val_loss: 0.9560 - val_accuracy: 0.7010\n",
      "Epoch 69/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1764 - accuracy: 0.5554 - val_loss: 0.9496 - val_accuracy: 0.6970\n",
      "Epoch 70/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1770 - accuracy: 0.5540 - val_loss: 0.9438 - val_accuracy: 0.7020\n",
      "Epoch 71/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1551 - accuracy: 0.5642 - val_loss: 0.9368 - val_accuracy: 0.7020\n",
      "Epoch 72/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1441 - accuracy: 0.5688 - val_loss: 0.9298 - val_accuracy: 0.7010\n",
      "Epoch 73/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.1308 - accuracy: 0.5794 - val_loss: 0.9187 - val_accuracy: 0.7050\n",
      "Epoch 74/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1401 - accuracy: 0.5760 - val_loss: 0.9137 - val_accuracy: 0.7050\n",
      "Epoch 75/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.1282 - accuracy: 0.5818 - val_loss: 0.9073 - val_accuracy: 0.7060\n",
      "Epoch 76/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.1116 - accuracy: 0.5851 - val_loss: 0.8994 - val_accuracy: 0.7080\n",
      "Epoch 77/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.1201 - accuracy: 0.5783 - val_loss: 0.8973 - val_accuracy: 0.7060\n",
      "Epoch 78/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.1084 - accuracy: 0.5871 - val_loss: 0.8897 - val_accuracy: 0.7140\n",
      "Epoch 79/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1116 - accuracy: 0.5857 - val_loss: 0.8856 - val_accuracy: 0.7110\n",
      "Epoch 80/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.1127 - accuracy: 0.5831 - val_loss: 0.8791 - val_accuracy: 0.7190\n",
      "Epoch 81/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.0955 - accuracy: 0.5854 - val_loss: 0.8743 - val_accuracy: 0.7170\n",
      "Epoch 82/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.0853 - accuracy: 0.5958 - val_loss: 0.8657 - val_accuracy: 0.7210\n",
      "Epoch 83/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.0620 - accuracy: 0.5992 - val_loss: 0.8576 - val_accuracy: 0.7240\n",
      "Epoch 84/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.0800 - accuracy: 0.5894 - val_loss: 0.8550 - val_accuracy: 0.7260\n",
      "Epoch 85/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.0719 - accuracy: 0.6002 - val_loss: 0.8488 - val_accuracy: 0.7240\n",
      "Epoch 86/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.0745 - accuracy: 0.6029 - val_loss: 0.8449 - val_accuracy: 0.7240\n",
      "Epoch 87/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.0534 - accuracy: 0.6111 - val_loss: 0.8383 - val_accuracy: 0.7290\n",
      "Epoch 88/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 1.0504 - accuracy: 0.6049 - val_loss: 0.8317 - val_accuracy: 0.7290\n",
      "Epoch 89/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.0369 - accuracy: 0.6165 - val_loss: 0.8251 - val_accuracy: 0.7330\n",
      "Epoch 90/200\n",
      "6500/6500 [==============================] - 0s 51us/step - loss: 1.0496 - accuracy: 0.6035 - val_loss: 0.8238 - val_accuracy: 0.7310\n",
      "Epoch 91/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.0420 - accuracy: 0.6088 - val_loss: 0.8164 - val_accuracy: 0.7360\n",
      "Epoch 92/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.0276 - accuracy: 0.6200 - val_loss: 0.8116 - val_accuracy: 0.7350\n",
      "Epoch 93/200\n",
      "6500/6500 [==============================] - 0s 43us/step - loss: 1.0161 - accuracy: 0.6228 - val_loss: 0.8055 - val_accuracy: 0.7380\n",
      "Epoch 94/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.0189 - accuracy: 0.6252 - val_loss: 0.8016 - val_accuracy: 0.7380\n",
      "Epoch 95/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.0185 - accuracy: 0.6177 - val_loss: 0.7987 - val_accuracy: 0.7400\n",
      "Epoch 96/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 1.0137 - accuracy: 0.6237 - val_loss: 0.7969 - val_accuracy: 0.7380\n",
      "Epoch 97/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 1.0117 - accuracy: 0.6240 - val_loss: 0.7918 - val_accuracy: 0.7390\n",
      "Epoch 98/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 1.0066 - accuracy: 0.6191 - val_loss: 0.7903 - val_accuracy: 0.7370\n",
      "Epoch 99/200\n",
      "6500/6500 [==============================] - 0s 50us/step - loss: 1.0066 - accuracy: 0.6242 - val_loss: 0.7883 - val_accuracy: 0.7410\n",
      "Epoch 100/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9975 - accuracy: 0.6300 - val_loss: 0.7810 - val_accuracy: 0.7430\n",
      "Epoch 101/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9796 - accuracy: 0.6345 - val_loss: 0.7769 - val_accuracy: 0.7450\n",
      "Epoch 102/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 0.9762 - accuracy: 0.6326 - val_loss: 0.7737 - val_accuracy: 0.7490\n",
      "Epoch 103/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9858 - accuracy: 0.6329 - val_loss: 0.7730 - val_accuracy: 0.7410\n",
      "Epoch 104/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9664 - accuracy: 0.6412 - val_loss: 0.7690 - val_accuracy: 0.7480\n",
      "Epoch 105/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9885 - accuracy: 0.6300 - val_loss: 0.7673 - val_accuracy: 0.7420\n",
      "Epoch 106/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9753 - accuracy: 0.6386 - val_loss: 0.7632 - val_accuracy: 0.7550\n",
      "Epoch 107/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9760 - accuracy: 0.6303 - val_loss: 0.7583 - val_accuracy: 0.7520\n",
      "Epoch 108/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9668 - accuracy: 0.6386 - val_loss: 0.7547 - val_accuracy: 0.7470\n",
      "Epoch 109/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9686 - accuracy: 0.6369 - val_loss: 0.7523 - val_accuracy: 0.7510\n",
      "Epoch 110/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9727 - accuracy: 0.6397 - val_loss: 0.7508 - val_accuracy: 0.7530\n",
      "Epoch 111/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9467 - accuracy: 0.6460 - val_loss: 0.7461 - val_accuracy: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 0.9591 - accuracy: 0.6377 - val_loss: 0.7442 - val_accuracy: 0.7560\n",
      "Epoch 113/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 0.9552 - accuracy: 0.6383 - val_loss: 0.7424 - val_accuracy: 0.7530\n",
      "Epoch 114/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9350 - accuracy: 0.6532 - val_loss: 0.7397 - val_accuracy: 0.7530\n",
      "Epoch 115/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 0.9528 - accuracy: 0.6389 - val_loss: 0.7362 - val_accuracy: 0.7570\n",
      "Epoch 116/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 0.9398 - accuracy: 0.6502 - val_loss: 0.7322 - val_accuracy: 0.7570\n",
      "Epoch 117/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9336 - accuracy: 0.6526 - val_loss: 0.7294 - val_accuracy: 0.7550\n",
      "Epoch 118/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9391 - accuracy: 0.6531 - val_loss: 0.7291 - val_accuracy: 0.7550\n",
      "Epoch 119/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9382 - accuracy: 0.6557 - val_loss: 0.7260 - val_accuracy: 0.7570\n",
      "Epoch 120/200\n",
      "6500/6500 [==============================] - 0s 44us/step - loss: 0.9203 - accuracy: 0.6591 - val_loss: 0.7245 - val_accuracy: 0.7590\n",
      "Epoch 121/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9243 - accuracy: 0.6542 - val_loss: 0.7216 - val_accuracy: 0.7570\n",
      "Epoch 122/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9403 - accuracy: 0.6526 - val_loss: 0.7183 - val_accuracy: 0.7610\n",
      "Epoch 123/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.9206 - accuracy: 0.6628 - val_loss: 0.7161 - val_accuracy: 0.7660\n",
      "Epoch 124/200\n",
      "6500/6500 [==============================] - 0s 58us/step - loss: 0.9147 - accuracy: 0.6638 - val_loss: 0.7123 - val_accuracy: 0.7620\n",
      "Epoch 125/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8930 - accuracy: 0.6638 - val_loss: 0.7088 - val_accuracy: 0.7610\n",
      "Epoch 126/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8920 - accuracy: 0.6697 - val_loss: 0.7064 - val_accuracy: 0.7620\n",
      "Epoch 127/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9065 - accuracy: 0.6549 - val_loss: 0.7064 - val_accuracy: 0.7620\n",
      "Epoch 128/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.9099 - accuracy: 0.6614 - val_loss: 0.7048 - val_accuracy: 0.7640\n",
      "Epoch 129/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8967 - accuracy: 0.6689 - val_loss: 0.7011 - val_accuracy: 0.7670\n",
      "Epoch 130/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8830 - accuracy: 0.6746 - val_loss: 0.6983 - val_accuracy: 0.7650\n",
      "Epoch 131/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 0.9038 - accuracy: 0.6655 - val_loss: 0.6995 - val_accuracy: 0.7630\n",
      "Epoch 132/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8901 - accuracy: 0.6640 - val_loss: 0.6969 - val_accuracy: 0.7660\n",
      "Epoch 133/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8905 - accuracy: 0.6702 - val_loss: 0.6955 - val_accuracy: 0.7640\n",
      "Epoch 134/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8952 - accuracy: 0.6648 - val_loss: 0.6939 - val_accuracy: 0.7650\n",
      "Epoch 135/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8881 - accuracy: 0.6708 - val_loss: 0.6922 - val_accuracy: 0.7650\n",
      "Epoch 136/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8752 - accuracy: 0.6785 - val_loss: 0.6889 - val_accuracy: 0.7650\n",
      "Epoch 137/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8650 - accuracy: 0.6829 - val_loss: 0.6872 - val_accuracy: 0.7660\n",
      "Epoch 138/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8896 - accuracy: 0.6623 - val_loss: 0.6849 - val_accuracy: 0.7650\n",
      "Epoch 139/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8776 - accuracy: 0.6805 - val_loss: 0.6847 - val_accuracy: 0.7670\n",
      "Epoch 140/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8874 - accuracy: 0.6726 - val_loss: 0.6826 - val_accuracy: 0.7680\n",
      "Epoch 141/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8738 - accuracy: 0.6782 - val_loss: 0.6803 - val_accuracy: 0.7650\n",
      "Epoch 142/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8633 - accuracy: 0.6715 - val_loss: 0.6773 - val_accuracy: 0.7690\n",
      "Epoch 143/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.8672 - accuracy: 0.6852 - val_loss: 0.6770 - val_accuracy: 0.7690\n",
      "Epoch 144/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8640 - accuracy: 0.6791 - val_loss: 0.6761 - val_accuracy: 0.7690\n",
      "Epoch 145/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8598 - accuracy: 0.6843 - val_loss: 0.6739 - val_accuracy: 0.7660\n",
      "Epoch 146/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8564 - accuracy: 0.6771 - val_loss: 0.6737 - val_accuracy: 0.7660\n",
      "Epoch 147/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8573 - accuracy: 0.6809 - val_loss: 0.6700 - val_accuracy: 0.7680\n",
      "Epoch 148/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8588 - accuracy: 0.6783 - val_loss: 0.6682 - val_accuracy: 0.7720\n",
      "Epoch 149/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8390 - accuracy: 0.6883 - val_loss: 0.6671 - val_accuracy: 0.7670\n",
      "Epoch 150/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 0.8480 - accuracy: 0.6834 - val_loss: 0.6658 - val_accuracy: 0.7710\n",
      "Epoch 151/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 0.8500 - accuracy: 0.6892 - val_loss: 0.6664 - val_accuracy: 0.7710\n",
      "Epoch 152/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 0.8480 - accuracy: 0.6823 - val_loss: 0.6659 - val_accuracy: 0.7730\n",
      "Epoch 153/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8328 - accuracy: 0.6908 - val_loss: 0.6618 - val_accuracy: 0.7710\n",
      "Epoch 154/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8302 - accuracy: 0.6895 - val_loss: 0.6609 - val_accuracy: 0.7700\n",
      "Epoch 155/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.8352 - accuracy: 0.6922 - val_loss: 0.6599 - val_accuracy: 0.7680\n",
      "Epoch 156/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8256 - accuracy: 0.6897 - val_loss: 0.6559 - val_accuracy: 0.7700\n",
      "Epoch 157/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8424 - accuracy: 0.6815 - val_loss: 0.6563 - val_accuracy: 0.7690\n",
      "Epoch 158/200\n",
      "6500/6500 [==============================] - 0s 54us/step - loss: 0.8255 - accuracy: 0.6895 - val_loss: 0.6548 - val_accuracy: 0.7710\n",
      "Epoch 159/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8222 - accuracy: 0.6928 - val_loss: 0.6544 - val_accuracy: 0.7710\n",
      "Epoch 160/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8267 - accuracy: 0.6948 - val_loss: 0.6539 - val_accuracy: 0.7680\n",
      "Epoch 161/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8256 - accuracy: 0.6954 - val_loss: 0.6498 - val_accuracy: 0.7710\n",
      "Epoch 162/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8371 - accuracy: 0.6874 - val_loss: 0.6524 - val_accuracy: 0.7670\n",
      "Epoch 163/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8287 - accuracy: 0.6922 - val_loss: 0.6516 - val_accuracy: 0.7720\n",
      "Epoch 164/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8156 - accuracy: 0.6966 - val_loss: 0.6489 - val_accuracy: 0.7700\n",
      "Epoch 165/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8226 - accuracy: 0.6925 - val_loss: 0.6511 - val_accuracy: 0.7670\n",
      "Epoch 166/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8204 - accuracy: 0.6892 - val_loss: 0.6481 - val_accuracy: 0.7630\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8166 - accuracy: 0.6954 - val_loss: 0.6448 - val_accuracy: 0.7660\n",
      "Epoch 168/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8092 - accuracy: 0.7000 - val_loss: 0.6453 - val_accuracy: 0.7740\n",
      "Epoch 169/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8196 - accuracy: 0.6966 - val_loss: 0.6450 - val_accuracy: 0.7710\n",
      "Epoch 170/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8098 - accuracy: 0.6966 - val_loss: 0.6421 - val_accuracy: 0.7770\n",
      "Epoch 171/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8228 - accuracy: 0.6952 - val_loss: 0.6435 - val_accuracy: 0.7720\n",
      "Epoch 172/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7998 - accuracy: 0.6985 - val_loss: 0.6401 - val_accuracy: 0.7730\n",
      "Epoch 173/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8073 - accuracy: 0.6934 - val_loss: 0.6394 - val_accuracy: 0.7700\n",
      "Epoch 174/200\n",
      "6500/6500 [==============================] - 0s 45us/step - loss: 0.8035 - accuracy: 0.6975 - val_loss: 0.6382 - val_accuracy: 0.7750\n",
      "Epoch 175/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8046 - accuracy: 0.7022 - val_loss: 0.6380 - val_accuracy: 0.7750\n",
      "Epoch 176/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.8083 - accuracy: 0.6994 - val_loss: 0.6370 - val_accuracy: 0.7720\n",
      "Epoch 177/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.8104 - accuracy: 0.6988 - val_loss: 0.6366 - val_accuracy: 0.7740\n",
      "Epoch 178/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7985 - accuracy: 0.7026 - val_loss: 0.6345 - val_accuracy: 0.7770\n",
      "Epoch 179/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7902 - accuracy: 0.7102 - val_loss: 0.6338 - val_accuracy: 0.7780\n",
      "Epoch 180/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.7894 - accuracy: 0.7085 - val_loss: 0.6329 - val_accuracy: 0.7730\n",
      "Epoch 181/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.7942 - accuracy: 0.7043 - val_loss: 0.6325 - val_accuracy: 0.7800\n",
      "Epoch 182/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7726 - accuracy: 0.7115 - val_loss: 0.6298 - val_accuracy: 0.7740\n",
      "Epoch 183/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7856 - accuracy: 0.7015 - val_loss: 0.6288 - val_accuracy: 0.7760\n",
      "Epoch 184/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7964 - accuracy: 0.7022 - val_loss: 0.6283 - val_accuracy: 0.7800\n",
      "Epoch 185/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7779 - accuracy: 0.7100 - val_loss: 0.6269 - val_accuracy: 0.7780\n",
      "Epoch 186/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7855 - accuracy: 0.7089 - val_loss: 0.6280 - val_accuracy: 0.7790\n",
      "Epoch 187/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.7663 - accuracy: 0.7218 - val_loss: 0.6264 - val_accuracy: 0.7760\n",
      "Epoch 188/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7681 - accuracy: 0.7111 - val_loss: 0.6255 - val_accuracy: 0.7760\n",
      "Epoch 189/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7772 - accuracy: 0.7083 - val_loss: 0.6259 - val_accuracy: 0.7750\n",
      "Epoch 190/200\n",
      "6500/6500 [==============================] - ETA: 0s - loss: 0.7912 - accuracy: 0.70 - 0s 47us/step - loss: 0.7915 - accuracy: 0.7009 - val_loss: 0.6268 - val_accuracy: 0.7770\n",
      "Epoch 191/200\n",
      "6500/6500 [==============================] - 0s 54us/step - loss: 0.7734 - accuracy: 0.7120 - val_loss: 0.6243 - val_accuracy: 0.7730\n",
      "Epoch 192/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7686 - accuracy: 0.7078 - val_loss: 0.6224 - val_accuracy: 0.7770\n",
      "Epoch 193/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7737 - accuracy: 0.7166 - val_loss: 0.6222 - val_accuracy: 0.7810\n",
      "Epoch 194/200\n",
      "6500/6500 [==============================] - 0s 48us/step - loss: 0.7669 - accuracy: 0.7106 - val_loss: 0.6204 - val_accuracy: 0.7790\n",
      "Epoch 195/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7729 - accuracy: 0.7108 - val_loss: 0.6214 - val_accuracy: 0.7770\n",
      "Epoch 196/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.7474 - accuracy: 0.7229 - val_loss: 0.6177 - val_accuracy: 0.7820\n",
      "Epoch 197/200\n",
      "6500/6500 [==============================] - 0s 49us/step - loss: 0.7642 - accuracy: 0.7112 - val_loss: 0.6173 - val_accuracy: 0.7790\n",
      "Epoch 198/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.7575 - accuracy: 0.7177 - val_loss: 0.6179 - val_accuracy: 0.7740\n",
      "Epoch 199/200\n",
      "6500/6500 [==============================] - 0s 46us/step - loss: 0.7540 - accuracy: 0.7175 - val_loss: 0.6153 - val_accuracy: 0.7740\n",
      "Epoch 200/200\n",
      "6500/6500 [==============================] - 0s 47us/step - loss: 0.7516 - accuracy: 0.7217 - val_loss: 0.6156 - val_accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "from keras import layers\n",
    "random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "model.add(layers.Dense(50, activation='relu')) #2 hidden layers\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/6500 [==============================] - 0s 26us/step\n",
      "Training Loss: 0.475 Training Accuracy: 0.83\n",
      "2500/2500 [==============================] - 0s 24us/step\n",
      "Testing Loss: 0.645 Testing Accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! The variance did become higher again compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, one of the solutions to high variance was just getting more data. You actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple your data set, and see what happens. Note that you are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df[\"Consumer complaint narrative\"]\n",
    "y = df[\"Product\"]\n",
    "\n",
    "# train test split\n",
    "X_train_lrg, X_test_lrg, y_train_lrg, y_test_lrg = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#Validation set\n",
    "X_train_final_lrg, X_val_lrg, y_train_final_lrg, y_val_lrg = train_test_split(X_train_lrg, y_train_lrg, random_state=123)\n",
    "\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_lrg)\n",
    "\n",
    "X_train_tok_lrg = tokenizer.texts_to_matrix(X_train_final_lrg, mode='binary')\n",
    "X_val_lrg = tokenizer.texts_to_matrix(X_val_lrg, mode='binary')\n",
    "X_test_lrg = tokenizer.texts_to_matrix(X_test_lrg, mode='binary')\n",
    "\n",
    "#one-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_lrg)\n",
    "\n",
    "y_train_lb_lrg = to_categorical(lb.transform(y_train_final_lrg))[:, :, 1]\n",
    "y_val_lrg = to_categorical(lb.transform(y_val_lrg))[:, :, 1]\n",
    "y_test_lrg = to_categorical(lb.transform(y_test_lrg))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 7500 samples\n",
      "Epoch 1/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 1.9187 - accuracy: 0.1964 - val_loss: 1.8816 - val_accuracy: 0.2256\n",
      "Epoch 2/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 1.8450 - accuracy: 0.2499 - val_loss: 1.7990 - val_accuracy: 0.2853\n",
      "Epoch 3/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 1.7439 - accuracy: 0.3236 - val_loss: 1.6844 - val_accuracy: 0.3660\n",
      "Epoch 4/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 1.6134 - accuracy: 0.4134 - val_loss: 1.5455 - val_accuracy: 0.4555\n",
      "Epoch 5/120\n",
      "22500/22500 [==============================] - 1s 33us/step - loss: 1.4705 - accuracy: 0.4992 - val_loss: 1.4046 - val_accuracy: 0.5369\n",
      "Epoch 6/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 1.3331 - accuracy: 0.5694 - val_loss: 1.2738 - val_accuracy: 0.6064\n",
      "Epoch 7/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 1.2086 - accuracy: 0.6268 - val_loss: 1.1571 - val_accuracy: 0.6449\n",
      "Epoch 8/120\n",
      "22500/22500 [==============================] - 1s 33us/step - loss: 1.0992 - accuracy: 0.6623 - val_loss: 1.0581 - val_accuracy: 0.6767\n",
      "Epoch 9/120\n",
      "22500/22500 [==============================] - 1s 33us/step - loss: 1.0061 - accuracy: 0.6861 - val_loss: 0.9745 - val_accuracy: 0.6987\n",
      "Epoch 10/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.9297 - accuracy: 0.7058 - val_loss: 0.9083 - val_accuracy: 0.7113\n",
      "Epoch 11/120\n",
      "22500/22500 [==============================] - 1s 33us/step - loss: 0.8678 - accuracy: 0.7189 - val_loss: 0.8543 - val_accuracy: 0.7233\n",
      "Epoch 12/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.8179 - accuracy: 0.7313 - val_loss: 0.8130 - val_accuracy: 0.7309\n",
      "Epoch 13/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 0.7777 - accuracy: 0.7386 - val_loss: 0.7801 - val_accuracy: 0.7369\n",
      "Epoch 14/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.7451 - accuracy: 0.7468 - val_loss: 0.7537 - val_accuracy: 0.7420\n",
      "Epoch 15/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.7180 - accuracy: 0.7544 - val_loss: 0.7312 - val_accuracy: 0.7448\n",
      "Epoch 16/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.6954 - accuracy: 0.7608 - val_loss: 0.7151 - val_accuracy: 0.7468\n",
      "Epoch 17/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.6757 - accuracy: 0.7664 - val_loss: 0.6988 - val_accuracy: 0.7508\n",
      "Epoch 18/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.6593 - accuracy: 0.7705 - val_loss: 0.6868 - val_accuracy: 0.7572\n",
      "Epoch 19/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.6442 - accuracy: 0.7745 - val_loss: 0.6758 - val_accuracy: 0.7605\n",
      "Epoch 20/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.6310 - accuracy: 0.7807 - val_loss: 0.6674 - val_accuracy: 0.7583\n",
      "Epoch 21/120\n",
      "22500/22500 [==============================] - 1s 33us/step - loss: 0.6188 - accuracy: 0.7834 - val_loss: 0.6587 - val_accuracy: 0.7633\n",
      "Epoch 22/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.6079 - accuracy: 0.7864 - val_loss: 0.6511 - val_accuracy: 0.7645\n",
      "Epoch 23/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5981 - accuracy: 0.7897 - val_loss: 0.6447 - val_accuracy: 0.7657\n",
      "Epoch 24/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5886 - accuracy: 0.7924 - val_loss: 0.6386 - val_accuracy: 0.7669\n",
      "Epoch 25/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.5799 - accuracy: 0.7968 - val_loss: 0.6351 - val_accuracy: 0.7697\n",
      "Epoch 26/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5712 - accuracy: 0.7988 - val_loss: 0.6322 - val_accuracy: 0.7701\n",
      "Epoch 27/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 0.5637 - accuracy: 0.8000 - val_loss: 0.6234 - val_accuracy: 0.7713\n",
      "Epoch 28/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 0.5562 - accuracy: 0.8039 - val_loss: 0.6203 - val_accuracy: 0.7717\n",
      "Epoch 29/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5490 - accuracy: 0.8063 - val_loss: 0.6173 - val_accuracy: 0.7760\n",
      "Epoch 30/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5425 - accuracy: 0.8084 - val_loss: 0.6134 - val_accuracy: 0.7763\n",
      "Epoch 31/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5358 - accuracy: 0.8100 - val_loss: 0.6127 - val_accuracy: 0.7763\n",
      "Epoch 32/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5299 - accuracy: 0.8119 - val_loss: 0.6070 - val_accuracy: 0.7796\n",
      "Epoch 33/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 0.5238 - accuracy: 0.8142 - val_loss: 0.6043 - val_accuracy: 0.7813\n",
      "Epoch 34/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5182 - accuracy: 0.8162 - val_loss: 0.6029 - val_accuracy: 0.7804\n",
      "Epoch 35/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5126 - accuracy: 0.8180 - val_loss: 0.5987 - val_accuracy: 0.7823\n",
      "Epoch 36/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.5068 - accuracy: 0.8199 - val_loss: 0.5961 - val_accuracy: 0.7844\n",
      "Epoch 37/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.5019 - accuracy: 0.8225 - val_loss: 0.5957 - val_accuracy: 0.7844\n",
      "Epoch 38/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4968 - accuracy: 0.8240 - val_loss: 0.5937 - val_accuracy: 0.7861\n",
      "Epoch 39/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4918 - accuracy: 0.8260 - val_loss: 0.5924 - val_accuracy: 0.7841\n",
      "Epoch 40/120\n",
      "22500/22500 [==============================] - 1s 32us/step - loss: 0.4875 - accuracy: 0.8286 - val_loss: 0.5895 - val_accuracy: 0.7865\n",
      "Epoch 41/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4825 - accuracy: 0.8293 - val_loss: 0.5888 - val_accuracy: 0.7849\n",
      "Epoch 42/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4782 - accuracy: 0.8304 - val_loss: 0.5884 - val_accuracy: 0.7857\n",
      "Epoch 43/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4741 - accuracy: 0.8331 - val_loss: 0.5856 - val_accuracy: 0.7901\n",
      "Epoch 44/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4697 - accuracy: 0.8337 - val_loss: 0.5879 - val_accuracy: 0.7871\n",
      "Epoch 45/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4655 - accuracy: 0.8349 - val_loss: 0.5835 - val_accuracy: 0.7883\n",
      "Epoch 46/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4613 - accuracy: 0.8373 - val_loss: 0.5836 - val_accuracy: 0.7883\n",
      "Epoch 47/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4572 - accuracy: 0.8392 - val_loss: 0.5824 - val_accuracy: 0.7892\n",
      "Epoch 48/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4538 - accuracy: 0.8403 - val_loss: 0.5807 - val_accuracy: 0.7893\n",
      "Epoch 49/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4500 - accuracy: 0.8422 - val_loss: 0.5826 - val_accuracy: 0.7885\n",
      "Epoch 50/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4463 - accuracy: 0.8431 - val_loss: 0.5789 - val_accuracy: 0.7899\n",
      "Epoch 51/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4428 - accuracy: 0.8448 - val_loss: 0.5777 - val_accuracy: 0.7920\n",
      "Epoch 52/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4390 - accuracy: 0.8458 - val_loss: 0.5782 - val_accuracy: 0.7897\n",
      "Epoch 53/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4357 - accuracy: 0.8465 - val_loss: 0.5773 - val_accuracy: 0.7924\n",
      "Epoch 54/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4322 - accuracy: 0.8483 - val_loss: 0.5773 - val_accuracy: 0.7956\n",
      "Epoch 55/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4290 - accuracy: 0.8500 - val_loss: 0.5785 - val_accuracy: 0.7901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 0.4258 - accuracy: 0.8517 - val_loss: 0.5765 - val_accuracy: 0.7911\n",
      "Epoch 57/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4230 - accuracy: 0.8522 - val_loss: 0.5761 - val_accuracy: 0.7897\n",
      "Epoch 58/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4194 - accuracy: 0.8537 - val_loss: 0.5764 - val_accuracy: 0.7905\n",
      "Epoch 59/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4166 - accuracy: 0.8546 - val_loss: 0.5765 - val_accuracy: 0.7919\n",
      "Epoch 60/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4135 - accuracy: 0.8564 - val_loss: 0.5772 - val_accuracy: 0.7904\n",
      "Epoch 61/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.4103 - accuracy: 0.8568 - val_loss: 0.5752 - val_accuracy: 0.7936\n",
      "Epoch 62/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4078 - accuracy: 0.8576 - val_loss: 0.5767 - val_accuracy: 0.7917\n",
      "Epoch 63/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.4047 - accuracy: 0.8601 - val_loss: 0.5756 - val_accuracy: 0.7907\n",
      "Epoch 64/120\n",
      "22500/22500 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.86 - 1s 30us/step - loss: 0.4018 - accuracy: 0.8610 - val_loss: 0.5766 - val_accuracy: 0.7943\n",
      "Epoch 65/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.3994 - accuracy: 0.8608 - val_loss: 0.5746 - val_accuracy: 0.7948\n",
      "Epoch 66/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.3968 - accuracy: 0.8637 - val_loss: 0.5762 - val_accuracy: 0.7939\n",
      "Epoch 67/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.3940 - accuracy: 0.8640 - val_loss: 0.5767 - val_accuracy: 0.7921\n",
      "Epoch 68/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3911 - accuracy: 0.8645 - val_loss: 0.5775 - val_accuracy: 0.7931\n",
      "Epoch 69/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3886 - accuracy: 0.8654 - val_loss: 0.5766 - val_accuracy: 0.7944\n",
      "Epoch 70/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3860 - accuracy: 0.8664 - val_loss: 0.5779 - val_accuracy: 0.7944\n",
      "Epoch 71/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.3836 - accuracy: 0.8674 - val_loss: 0.5799 - val_accuracy: 0.7936\n",
      "Epoch 72/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3817 - accuracy: 0.8680 - val_loss: 0.5761 - val_accuracy: 0.7937\n",
      "Epoch 73/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3786 - accuracy: 0.8691 - val_loss: 0.5791 - val_accuracy: 0.7933\n",
      "Epoch 74/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3762 - accuracy: 0.8710 - val_loss: 0.5773 - val_accuracy: 0.7951\n",
      "Epoch 75/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3740 - accuracy: 0.8719 - val_loss: 0.5795 - val_accuracy: 0.7944\n",
      "Epoch 76/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3717 - accuracy: 0.8722 - val_loss: 0.5786 - val_accuracy: 0.7949\n",
      "Epoch 77/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3695 - accuracy: 0.8725 - val_loss: 0.5784 - val_accuracy: 0.7953\n",
      "Epoch 78/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3668 - accuracy: 0.8736 - val_loss: 0.5799 - val_accuracy: 0.7944\n",
      "Epoch 79/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3648 - accuracy: 0.8748 - val_loss: 0.5810 - val_accuracy: 0.7952\n",
      "Epoch 80/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3628 - accuracy: 0.8757 - val_loss: 0.5808 - val_accuracy: 0.7951\n",
      "Epoch 81/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3604 - accuracy: 0.8770 - val_loss: 0.5823 - val_accuracy: 0.7935\n",
      "Epoch 82/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3581 - accuracy: 0.8763 - val_loss: 0.5826 - val_accuracy: 0.7936\n",
      "Epoch 83/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3560 - accuracy: 0.8786 - val_loss: 0.5827 - val_accuracy: 0.7937\n",
      "Epoch 84/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3538 - accuracy: 0.8804 - val_loss: 0.5835 - val_accuracy: 0.7939\n",
      "Epoch 85/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3520 - accuracy: 0.8799 - val_loss: 0.5832 - val_accuracy: 0.7935\n",
      "Epoch 86/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.3495 - accuracy: 0.8818 - val_loss: 0.5855 - val_accuracy: 0.7931\n",
      "Epoch 87/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3478 - accuracy: 0.8812 - val_loss: 0.5843 - val_accuracy: 0.7945\n",
      "Epoch 88/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3458 - accuracy: 0.8828 - val_loss: 0.5869 - val_accuracy: 0.7941\n",
      "Epoch 89/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3440 - accuracy: 0.8826 - val_loss: 0.5859 - val_accuracy: 0.7933\n",
      "Epoch 90/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3419 - accuracy: 0.8844 - val_loss: 0.5865 - val_accuracy: 0.7939\n",
      "Epoch 91/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3399 - accuracy: 0.8838 - val_loss: 0.5878 - val_accuracy: 0.7939\n",
      "Epoch 92/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3381 - accuracy: 0.8840 - val_loss: 0.5894 - val_accuracy: 0.7955\n",
      "Epoch 93/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3363 - accuracy: 0.8860 - val_loss: 0.5900 - val_accuracy: 0.7947\n",
      "Epoch 94/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3345 - accuracy: 0.8863 - val_loss: 0.5903 - val_accuracy: 0.7948\n",
      "Epoch 95/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3324 - accuracy: 0.8876 - val_loss: 0.5919 - val_accuracy: 0.7953\n",
      "Epoch 96/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3304 - accuracy: 0.8883 - val_loss: 0.5919 - val_accuracy: 0.7952\n",
      "Epoch 97/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3286 - accuracy: 0.8891 - val_loss: 0.5927 - val_accuracy: 0.7935\n",
      "Epoch 98/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3268 - accuracy: 0.8896 - val_loss: 0.5958 - val_accuracy: 0.7936\n",
      "Epoch 99/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3249 - accuracy: 0.8898 - val_loss: 0.5940 - val_accuracy: 0.7945\n",
      "Epoch 100/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3232 - accuracy: 0.8910 - val_loss: 0.5962 - val_accuracy: 0.7939\n",
      "Epoch 101/120\n",
      "22500/22500 [==============================] - 1s 30us/step - loss: 0.3216 - accuracy: 0.8914 - val_loss: 0.5992 - val_accuracy: 0.7940\n",
      "Epoch 102/120\n",
      "22500/22500 [==============================] - 1s 33us/step - loss: 0.3201 - accuracy: 0.8919 - val_loss: 0.5993 - val_accuracy: 0.7940\n",
      "Epoch 103/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3184 - accuracy: 0.8935 - val_loss: 0.5978 - val_accuracy: 0.7945\n",
      "Epoch 104/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3163 - accuracy: 0.8924 - val_loss: 0.5992 - val_accuracy: 0.7940\n",
      "Epoch 105/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3149 - accuracy: 0.8938 - val_loss: 0.6015 - val_accuracy: 0.7960\n",
      "Epoch 106/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3130 - accuracy: 0.8956 - val_loss: 0.6010 - val_accuracy: 0.7940\n",
      "Epoch 107/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3115 - accuracy: 0.8949 - val_loss: 0.6036 - val_accuracy: 0.7937\n",
      "Epoch 108/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3095 - accuracy: 0.8955 - val_loss: 0.6040 - val_accuracy: 0.7931\n",
      "Epoch 109/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3081 - accuracy: 0.8964 - val_loss: 0.6041 - val_accuracy: 0.7939\n",
      "Epoch 110/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3069 - accuracy: 0.8970 - val_loss: 0.6062 - val_accuracy: 0.7935\n",
      "Epoch 111/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3046 - accuracy: 0.8992 - val_loss: 0.6082 - val_accuracy: 0.7935\n",
      "Epoch 112/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3036 - accuracy: 0.8990 - val_loss: 0.6070 - val_accuracy: 0.7925\n",
      "Epoch 113/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3017 - accuracy: 0.8989 - val_loss: 0.6106 - val_accuracy: 0.7968\n",
      "Epoch 114/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.3005 - accuracy: 0.8987 - val_loss: 0.6179 - val_accuracy: 0.7940\n",
      "Epoch 115/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.2987 - accuracy: 0.8999 - val_loss: 0.6109 - val_accuracy: 0.7948\n",
      "Epoch 116/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.2975 - accuracy: 0.9009 - val_loss: 0.6115 - val_accuracy: 0.7935\n",
      "Epoch 117/120\n",
      "22500/22500 [==============================] - 1s 31us/step - loss: 0.2957 - accuracy: 0.9002 - val_loss: 0.6137 - val_accuracy: 0.7953\n",
      "Epoch 118/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.2943 - accuracy: 0.9015 - val_loss: 0.6167 - val_accuracy: 0.7917\n",
      "Epoch 119/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.2927 - accuracy: 0.9020 - val_loss: 0.6151 - val_accuracy: 0.7943\n",
      "Epoch 120/120\n",
      "22500/22500 [==============================] - 1s 29us/step - loss: 0.2911 - accuracy: 0.9022 - val_loss: 0.6165 - val_accuracy: 0.7928\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_model = model.fit(X_train_tok_lrg,\n",
    "                    y_train_lb_lrg,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_lrg, y_val_lrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 0s 21us/step\n",
      "Training Loss: 0.286 Training Accuracy: 0.905\n",
      "10000/10000 [==============================] - 0s 20us/step\n",
      "Testing Loss: 0.616 Testing Accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok_lrg, y_train_lb_lrg)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_lrg, y_test_lrg)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, you were able to get a fairly similar validation accuracy of 89.67 (compared to 88.45 in obtained in the first model in this lab). Your test set accuracy went up from 75.8 to 79.2% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lesson, you not only built an initial deep-learning model, you then used a validation set to tune your model using various types of regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
